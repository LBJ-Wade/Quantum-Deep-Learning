{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# Code adapted from QizGloria team, Qiskit Camp Europe 2019, updated by \n",
    "# Team Ube Pancake, Qiskit Summer Jam 2020\n",
    "#\n",
    "# WORKS for Quantum Circuit with variable number of qubits! Now supports running on GPU (CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda:0\")\n",
    "#     print(\"Running on the GPU\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     print(\"Running on the CPU\")\n",
    "    \n",
    "# torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import execute\n",
    "from qiskit.circuit import Parameter,ControlledGate\n",
    "from qiskit import Aer\n",
    "import qiskit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "\n",
    "NUM_QUBITS = 3\n",
    "NUM_SHOTS = 1000\n",
    "SHIFT = np.pi/4\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "SIMULATOR = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '001', '010', '011', '100', '101', '110', '111']\n"
     ]
    }
   ],
   "source": [
    "# create list of all possible outputs of quantum circuit (2**NUM_QUBITS possible)\n",
    "import itertools\n",
    "def create_QC_OUTPUTS():\n",
    "    measurements = list(itertools.product([0, 1], repeat=NUM_QUBITS))\n",
    "    return [''.join([str(bit) for bit in measurement]) for measurement in measurements]\n",
    "\n",
    "QC_OUTPUTS = create_QC_OUTPUTS()\n",
    "print(QC_OUTPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to translate Q-Circuit parameters from pytorch back to QISKIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Contruct QuantumCircuit QFT Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:09:30.598730Z",
     "start_time": "2019-10-01T16:09:30.567861Z"
    }
   },
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self.circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        self.n_qubits = n_qubits\n",
    "        self.thetas ={k : Parameter('Theta'+str(k))for k in range(self.n_qubits)}\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.circuit.h(all_qubits)\n",
    "        self.circuit.barrier()\n",
    "        for k in range(n_qubits):\n",
    "            self.circuit.ry(self.thetas[k], k)\n",
    "        \n",
    "#         # Apply controlled-unitary\n",
    "# #         uc=ry(self.theta4, 4).to_gate().control(4)\n",
    "# #         self.circuit.append(uc, [0,1,2,3,4])\n",
    "#         self.circuit.ry(self.theta4, 4).to_gate().control(4)\n",
    "    \n",
    "        self.circuit.barrier()\n",
    "        self.circuit.measure_all()\n",
    "        # ---------------------------\n",
    "        \n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects  \n",
    "    \n",
    "    def run(self, i):\n",
    "        params = i\n",
    "#         print('params = {}'.format(len(params)))\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        try:\n",
    "            job_sim = execute(self.circuit,\n",
    "                              self.backend,\n",
    "                              shots=self.shots,\n",
    "                              parameter_binds = [{self.thetas[k] : params[k] for k in range(NUM_QUBITS)}])\n",
    "        except:\n",
    "            job_sim = execute(self.circuit,\n",
    "                              self.backend,\n",
    "                              shots=self.shots,\n",
    "                              parameter_binds = [{self.thetas[k] : params[k].item() for k in range(NUM_QUBITS)}])\n",
    "        \n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,NUM_QUBITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value for rotation [pi/4]: [0.748 0.692 0.742]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 659.792x264.88 with 1 Axes>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit = QiskitCircuit(NUM_QUBITS, SIMULATOR, NUM_SHOTS)\n",
    "print('Expected value for rotation [pi/4]: {}'.format(circuit.run(torch.Tensor([np.pi/4]*NUM_QUBITS))))\n",
    "circuit.circuit.draw(output='mpl') #, filename='Figures/{}-qubit circuit ryN.jpg'.format(NUM_QUBITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchCircuit()\n",
    "\n",
    "A pytorch layer always has two functions. One for the forward pass and one for the backward pass. The forward pass simply takes the Quantum Circuits variational parameters from the previous pytorch layer and runs the circuit on the defined hardware (defined in `QiskitCircuit.run()`) and returns the measurements from the quantum hardware.\n",
    "These measurements will be the inputs of the next pytorch layer.\n",
    "\n",
    "The backward pass returns the gradients of the quantum circuit. In this case here it is finite difference.\n",
    "\n",
    "the `forward_tensor` is saved from the forward pass. So we just have to do one evaluation of the Q-Circuit in the backpass for the finite difference.\n",
    "\n",
    "The `gradient` variable here is as well hard coded to 3 parameters. This should be updated in the future and made more general.\n",
    "\n",
    "The loop `for k in range(len(input_numbers)):` goes through all the parameters (in this case 3), and shifts them by a small $\\epsilon$. Then it runs the circuit and takes the diefferences of the ouput for the parameters $\\Theta$ and $\\Theta + \\epsilon$. This is the finite difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(NUM_QUBITS, SIMULATOR, shots=NUM_SHOTS)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i)\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors\n",
    "#         print('forward_tensor = {}'.format(forward_tensor))\n",
    "        input_numbers = i\n",
    "#         print('input_numbers = {}'.format(input_numbers))\n",
    "        gradients = torch.Tensor()\n",
    "        \n",
    "        for k in range(NUM_QUBITS):\n",
    "            shift_right = input_numbers.detach().clone()\n",
    "            shift_right[k] = shift_right[k] + SHIFT\n",
    "            shift_left = input_numbers.detach().clone()\n",
    "            shift_left[k] = shift_left[k] - SHIFT\n",
    "            \n",
    "#             print('shift_right = {}, shift_left = {}'.format(shift_right, shift_left))\n",
    "            \n",
    "            expectation_right = ctx.QiskitCirc.run(shift_right)\n",
    "            expectation_left  = ctx.QiskitCirc.run(shift_left)\n",
    "#             print('expectation_right = {}, \\nexpectation_left = {}'.format(expectation_right, expectation_left))\n",
    "            \n",
    "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "            # rescale gradient\n",
    "#             gradient = gradient / torch.norm(gradient)\n",
    "#             print('gradient for k={}: {}'.format(k, gradient))\n",
    "            gradients = torch.cat((gradients, gradient.float()))\n",
    "            \n",
    "        result = torch.Tensor(gradients)\n",
    "#         print('gradients = {}'.format(result))\n",
    "#         print('grad_output = {}'.format(grad_output))\n",
    "\n",
    "        return (result.float() * grad_output.float()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 after quantum layer: tensor([[0.6740, 0.7100, 0.7020]], dtype=torch.float64,\n",
      "       grad_fn=<TorchCircuitBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 3], m2: [8 x 1] at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\TH/generic/THTensorMath.cpp:41",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6878c8b5a540>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y1 after quantum layer: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mNUM_QUBITS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x.grad = {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1608\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1611\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 3], m2: [8 x 1] at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\TH/generic/THTensorMath.cpp:41"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([np.pi/4]*NUM_QUBITS, requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "print('y1 after quantum layer: {}'.format(y1))\n",
    "y1 = nn.Linear(2**NUM_QUBITS,1)(y1.float())\n",
    "y1.backward()\n",
    "print('x.grad = {}'.format(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Quantum Circuit's Gradient Descent\n",
    "\n",
    "First, we want the \"neural net\" consisting of just the quantum circuit (with its 4 inputs and 4 outputs) and a linear layer (from 4 inputs to 1 output) that scales measurement 1 by 1, measurement 2 by 2, etc., until it converges to a target value (-1). So, we define a cost function where the cost is defined as the square distance from the target value.\n",
    "\n",
    "`x` is the initialization of the parameters. Here, every angle in the quantum circuit starts at $\\pi/4$. We should see that the loss eventually goes down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-154ebe7cbc88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# for i in range(num_epoch):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-154ebe7cbc88>\u001b[0m in \u001b[0;36mcost\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# simple linear layer: average all outputs of quantum layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#     print(expval)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexpval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mNUM_QUBITS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mNUM_QUBITS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#     print(val)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-154ebe7cbc88>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# simple linear layer: average all outputs of quantum layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#     print(expval)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexpval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mNUM_QUBITS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mNUM_QUBITS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#     print(val)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)[0]\n",
    "    # simple linear layer: average all outputs of quantum layer\n",
    "#     print(expval)\n",
    "    val = sum([(i+1)*expval[i] for i in range(2**NUM_QUBITS)]) / 2**NUM_QUBITS\n",
    "#     print(val)\n",
    "    return torch.abs(val - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([-np.pi/4]*NUM_QUBITS, requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval)\n",
    "\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST (0-1) Dataset\n",
    "\n",
    "**Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Concentrating on the first 100 samples\n",
    "n_samples = 200\n",
    "\n",
    "X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "X_train.data, X_train.targets = X_train.data[:n_samples], X_train.targets[:n_samples]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples_show = 6\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "while n_samples_show > 0:\n",
    "    images, targets = data_iter.__next__()\n",
    "\n",
    "    axes[n_samples_show - 1].imshow(images[0].numpy().squeeze(), cmap='gray')\n",
    "    axes[n_samples_show - 1].set_xticks([])\n",
    "    axes[n_samples_show - 1].set_yticks([])\n",
    "    axes[n_samples_show - 1].set_title(\"Labeled: {}\".format(targets.item()))\n",
    "    \n",
    "    n_samples_show -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    "\n",
    "X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                        transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "X_test.data, X_test.targets = X_test.data[:n_samples], X_test.targets[:n_samples]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network with Q-node\n",
    "\n",
    "This NN is  2 layers of ConvNN and a fully connected layer, with a Q-Node as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(20, 60, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, NUM_QUBITS)\n",
    "        self.qc = TorchCircuit.apply\n",
    "        self.fc3 = nn.Linear(2**NUM_QUBITS, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = np.pi*torch.tanh(x)\n",
    "        \n",
    "#         print('params to QC: {}'.format(x))\n",
    "\n",
    "        x = qc(x[0]) # QUANTUM LAYER\n",
    "            \n",
    "        print('output of QC = {}'.format(x))\n",
    "        \n",
    "        # softmax rather than sigmoid\n",
    "        x = self.fc3(x.float())\n",
    "        x = F.softmax(x, 1)\n",
    "#         print(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        # apply softmax\n",
    "        pred = self.forward(x)\n",
    "#         print(pred)\n",
    "        ans = torch.argmax(pred[0]).item()\n",
    "        return torch.tensor(ans)\n",
    "    \n",
    "network = Net()#.to(device)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of QC = tensor([[0.0840, 0.3510, 0.0690, 0.2290, 0.0330, 0.1220, 0.0260, 0.0860]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0750, 0.3460, 0.0470, 0.1960, 0.0460, 0.1770, 0.0300, 0.0830]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0780, 0.3900, 0.0420, 0.1430, 0.0480, 0.1850, 0.0230, 0.0910]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1530, 0.2940, 0.1150, 0.2420, 0.0420, 0.0740, 0.0280, 0.0520]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1380, 0.2040, 0.1110, 0.1570, 0.0890, 0.1260, 0.0640, 0.1110]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0840, 0.4390, 0.0260, 0.1310, 0.0440, 0.2020, 0.0110, 0.0630]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0260, 0.1770, 0.0110, 0.0630, 0.0870, 0.4600, 0.0290, 0.1470]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1020, 0.1810, 0.1370, 0.2300, 0.0480, 0.0970, 0.0720, 0.1330]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0080, 0.2800, 0.0110, 0.2190, 0.0090, 0.2670, 0.0040, 0.2020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0870, 0.2700, 0.1080, 0.2890, 0.0280, 0.0930, 0.0240, 0.1010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0150, 0.1310, 0.0200, 0.2280, 0.0160, 0.1920, 0.0320, 0.3660]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0270, 0.0790, 0.0040, 0.0210, 0.1780, 0.5390, 0.0430, 0.1090]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1060, 0.3820, 0.0910, 0.3500, 0.0090, 0.0250, 0.0040, 0.0330]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0150, 0.5020, 0.0110, 0.3050, 0.0030, 0.1030, 0.0010, 0.0600]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1020, 0.3780, 0.0620, 0.2180, 0.0420, 0.1010, 0.0240, 0.0730]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0370, 0.5500, 0.0240, 0.2880, 0.0050, 0.0550, 0.0030, 0.0380]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3230, 0.4100, 0.0650, 0.0900, 0.0420, 0.0500, 0.0060, 0.0140]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1120, 0.8310, 0.0070, 0.0380, 0.0010, 0.0090, 0.0000, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1610, 0.3270, 0.1300, 0.2950, 0.0130, 0.0310, 0.0100, 0.0330]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2050, 0.5020, 0.0700, 0.1990, 0.0070, 0.0110, 0.0000, 0.0060]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2010, 0.5230, 0.0400, 0.1280, 0.0250, 0.0660, 0.0050, 0.0120]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0910, 0.4600, 0.0630, 0.3440, 0.0070, 0.0190, 0.0030, 0.0130]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1360, 0.3850, 0.0550, 0.1560, 0.0540, 0.1360, 0.0160, 0.0620]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0440, 0.8260, 0.0080, 0.1030, 0.0010, 0.0140, 0.0000, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1230, 0.4250, 0.0740, 0.2680, 0.0130, 0.0490, 0.0110, 0.0370]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3210, 0.5770, 0.0330, 0.0690, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3470, 0.5470, 0.0200, 0.0280, 0.0190, 0.0370, 0.0020, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1990, 0.1600, 0.2490, 0.2270, 0.0430, 0.0450, 0.0450, 0.0320]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.6790, 0.2390, 0.0370, 0.0170, 0.0170, 0.0100, 0.0000, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0970, 0.5390, 0.0470, 0.3040, 0.0000, 0.0100, 0.0000, 0.0030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1510, 0.5090, 0.0370, 0.1000, 0.0420, 0.1330, 0.0080, 0.0200]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1010, 0.5870, 0.0000, 0.0020, 0.0450, 0.2650, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0290, 0.9420, 0.0000, 0.0140, 0.0000, 0.0150, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1520, 0.2830, 0.1110, 0.2450, 0.0320, 0.0690, 0.0360, 0.0720]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0800, 0.8220, 0.0030, 0.0570, 0.0030, 0.0330, 0.0000, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0250, 0.8100, 0.0000, 0.0010, 0.0030, 0.1610, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0380, 0.6680, 0.0170, 0.2770, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0640, 0.7310, 0.0120, 0.1220, 0.0020, 0.0570, 0.0020, 0.0100]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1580, 0.3590, 0.0760, 0.1920, 0.0430, 0.0940, 0.0310, 0.0470]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0560, 0.4610, 0.0010, 0.0140, 0.0550, 0.3950, 0.0010, 0.0170]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0070, 0.8540, 0.0000, 0.0500, 0.0000, 0.0810, 0.0000, 0.0080]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2510, 0.7300, 0.0000, 0.0000, 0.0110, 0.0080, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.5940, 0.3080, 0.0080, 0.0050, 0.0570, 0.0280, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1790, 0.2350, 0.0870, 0.1400, 0.0900, 0.1330, 0.0600, 0.0760]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0110, 0.5030, 0.0030, 0.1990, 0.0070, 0.1940, 0.0000, 0.0830]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2600, 0.6290, 0.0160, 0.0350, 0.0210, 0.0340, 0.0010, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0760, 0.8570, 0.0020, 0.0170, 0.0040, 0.0420, 0.0000, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0040, 0.9470, 0.0000, 0.0350, 0.0000, 0.0130, 0.0000, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0040, 0.9490, 0.0000, 0.0130, 0.0000, 0.0330, 0.0000, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.5370, 0.0000, 0.2280, 0.0030, 0.1760, 0.0010, 0.0550]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0030, 0.4960, 0.0000, 0.1130, 0.0010, 0.3180, 0.0010, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3700, 0.5430, 0.0220, 0.0440, 0.0120, 0.0090, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.2970, 0.0000, 0.2360, 0.0010, 0.2420, 0.0000, 0.2240]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2510, 0.3660, 0.0530, 0.0990, 0.0770, 0.1090, 0.0200, 0.0250]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1200, 0.2800, 0.0840, 0.1900, 0.0550, 0.1450, 0.0390, 0.0870]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.8790, 0.0020, 0.1110, 0.0010, 0.0060, 0.0000, 0.0010, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3640, 0.1660, 0.2470, 0.1040, 0.0400, 0.0260, 0.0350, 0.0180]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0710, 0.5240, 0.0280, 0.2520, 0.0060, 0.0710, 0.0070, 0.0410]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.4200, 0.0000, 0.3650, 0.0000, 0.1230, 0.0000, 0.0920]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0010, 0.3430, 0.0010, 0.2180, 0.0000, 0.2780, 0.0000, 0.1590]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2820, 0.1710, 0.0410, 0.0350, 0.2370, 0.1620, 0.0460, 0.0260]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1730, 0.6760, 0.0250, 0.0560, 0.0150, 0.0480, 0.0020, 0.0050]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0830, 0.9010, 0.0010, 0.0130, 0.0000, 0.0020, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4980, 0.0000, 0.3960, 0.0000, 0.0530, 0.0000, 0.0530, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1240, 0.3950, 0.0700, 0.1950, 0.0250, 0.1020, 0.0190, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2680, 0.3110, 0.1210, 0.1430, 0.0560, 0.0450, 0.0270, 0.0290]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0300, 0.7060, 0.0110, 0.1930, 0.0030, 0.0430, 0.0000, 0.0140]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0080, 0.2760, 0.0100, 0.2210, 0.0130, 0.2360, 0.0090, 0.2270]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3740, 0.4690, 0.0640, 0.0830, 0.0050, 0.0050, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0200, 0.4190, 0.0260, 0.3500, 0.0040, 0.0940, 0.0020, 0.0850]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0530, 0.4290, 0.0020, 0.0630, 0.0460, 0.3510, 0.0070, 0.0490]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3630, 0.0160, 0.2070, 0.0100, 0.2390, 0.0100, 0.1530, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0140, 0.5920, 0.0070, 0.2350, 0.0010, 0.1080, 0.0010, 0.0420]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1450, 0.2870, 0.1080, 0.1880, 0.0620, 0.0990, 0.0400, 0.0710]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3130, 0.0000, 0.1760, 0.0000, 0.3290, 0.0000, 0.1820, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.8930, 0.0000, 0.0720, 0.0000, 0.0320, 0.0000, 0.0030, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1810, 0.7040, 0.0150, 0.0420, 0.0130, 0.0400, 0.0010, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0990, 0.7190, 0.0080, 0.0450, 0.0160, 0.1090, 0.0010, 0.0030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3390, 0.0020, 0.2220, 0.0010, 0.2620, 0.0000, 0.1720, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0740, 0.8240, 0.0050, 0.0640, 0.0030, 0.0260, 0.0000, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3190, 0.0330, 0.2530, 0.0220, 0.2120, 0.0090, 0.1400, 0.0120]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4480, 0.4040, 0.0520, 0.0380, 0.0260, 0.0260, 0.0030, 0.0030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4080, 0.5340, 0.0060, 0.0030, 0.0230, 0.0250, 0.0000, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0330, 0.4940, 0.0170, 0.2550, 0.0110, 0.1210, 0.0070, 0.0620]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0020, 0.3910, 0.0030, 0.3050, 0.0000, 0.1740, 0.0010, 0.1240]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4500, 0.0010, 0.4560, 0.0010, 0.0470, 0.0000, 0.0450, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2920, 0.1550, 0.2420, 0.1600, 0.0500, 0.0190, 0.0530, 0.0290]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0030, 0.2450, 0.0050, 0.2330, 0.0020, 0.2400, 0.0010, 0.2710]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0550, 0.4100, 0.0180, 0.1030, 0.0510, 0.2810, 0.0120, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0300, 0.5280, 0.0210, 0.4000, 0.0020, 0.0090, 0.0000, 0.0100]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.5450, 0.0270, 0.2880, 0.0240, 0.0610, 0.0090, 0.0440, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4330, 0.1300, 0.2800, 0.0800, 0.0400, 0.0110, 0.0170, 0.0090]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.6360, 0.0350, 0.3060, 0.0160, 0.0060, 0.0000, 0.0010, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1360, 0.3230, 0.0640, 0.1600, 0.0720, 0.1430, 0.0210, 0.0810]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1070, 0.3740, 0.0480, 0.1710, 0.0420, 0.1600, 0.0180, 0.0800]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0280, 0.1610, 0.0040, 0.0340, 0.0530, 0.5290, 0.0300, 0.1610]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2760, 0.4200, 0.1300, 0.1670, 0.0020, 0.0040, 0.0000, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3890, 0.0060, 0.2440, 0.0060, 0.2220, 0.0040, 0.1260, 0.0030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4210, 0.0850, 0.3570, 0.0690, 0.0330, 0.0090, 0.0200, 0.0060]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.5620, 0.0200, 0.3400, 0.0150, 0.0340, 0.0010, 0.0270, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1300, 0.1720, 0.1130, 0.1610, 0.1200, 0.1020, 0.0920, 0.1100]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1540, 0.2710, 0.0900, 0.1900, 0.0780, 0.1030, 0.0370, 0.0770]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1640, 0.2120, 0.1870, 0.2020, 0.0560, 0.0710, 0.0450, 0.0630]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.6740, 0.1460, 0.1530, 0.0260, 0.0010, 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1800, 0.1340, 0.1850, 0.1200, 0.1020, 0.0900, 0.1070, 0.0820]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0270, 0.4690, 0.0110, 0.1740, 0.0090, 0.2170, 0.0080, 0.0850]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2380, 0.1300, 0.2180, 0.1430, 0.0920, 0.0460, 0.0820, 0.0510]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4190, 0.4920, 0.0060, 0.0080, 0.0370, 0.0370, 0.0010, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2470, 0.0020, 0.2630, 0.0030, 0.2460, 0.0020, 0.2360, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0530, 0.4210, 0.0110, 0.0790, 0.0440, 0.3210, 0.0110, 0.0600]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1760, 0.1330, 0.1630, 0.1470, 0.0960, 0.0910, 0.1090, 0.0850]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2460, 0.2210, 0.2370, 0.1890, 0.0240, 0.0260, 0.0330, 0.0240]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3690, 0.0150, 0.3070, 0.0080, 0.1730, 0.0060, 0.1160, 0.0060]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1020, 0.2330, 0.0710, 0.1470, 0.0790, 0.1720, 0.0620, 0.1340]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1190, 0.3790, 0.0700, 0.1690, 0.0490, 0.1400, 0.0220, 0.0520]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3340, 0.0600, 0.1670, 0.0310, 0.2490, 0.0290, 0.1100, 0.0200]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1710, 0.5320, 0.0270, 0.1180, 0.0190, 0.1050, 0.0030, 0.0250]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1720, 0.3110, 0.1200, 0.2090, 0.0400, 0.0680, 0.0260, 0.0540]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4450, 0.2630, 0.0060, 0.0060, 0.1740, 0.1020, 0.0030, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1760, 0.1140, 0.1360, 0.1080, 0.1370, 0.0960, 0.1390, 0.0940]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.7900, 0.1710, 0.0100, 0.0020, 0.0200, 0.0060, 0.0010, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2780, 0.6520, 0.0080, 0.0220, 0.0080, 0.0310, 0.0000, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0280, 0.2660, 0.0370, 0.2250, 0.0220, 0.2330, 0.0270, 0.1620]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0080, 0.3190, 0.0050, 0.2890, 0.0060, 0.2060, 0.0030, 0.1640]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4200, 0.0630, 0.4050, 0.0470, 0.0310, 0.0050, 0.0200, 0.0090]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2370, 0.6700, 0.0070, 0.0220, 0.0140, 0.0480, 0.0000, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1290, 0.2360, 0.1030, 0.2060, 0.0520, 0.1050, 0.0530, 0.1160]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3280, 0.0230, 0.2230, 0.0250, 0.1910, 0.0130, 0.1750, 0.0220]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2110, 0.2550, 0.0960, 0.1200, 0.1080, 0.1040, 0.0490, 0.0570]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0970, 0.4800, 0.0620, 0.2600, 0.0130, 0.0510, 0.0050, 0.0320]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1300, 0.1410, 0.1510, 0.1470, 0.0900, 0.1130, 0.1220, 0.1060]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0010, 0.3340, 0.0010, 0.2760, 0.0010, 0.2010, 0.0000, 0.1860]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4080, 0.1450, 0.3010, 0.1080, 0.0180, 0.0070, 0.0080, 0.0050]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1590, 0.3030, 0.1210, 0.1960, 0.0540, 0.0910, 0.0240, 0.0520]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0030, 0.2490, 0.0050, 0.2560, 0.0060, 0.2460, 0.0050, 0.2300]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1740, 0.1810, 0.1770, 0.1410, 0.0950, 0.0670, 0.1000, 0.0650]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1620, 0.4180, 0.0090, 0.0180, 0.1020, 0.2570, 0.0120, 0.0220]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0830, 0.3780, 0.0230, 0.1300, 0.0520, 0.2210, 0.0170, 0.0960]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1980, 0.2400, 0.0410, 0.0380, 0.1980, 0.2210, 0.0270, 0.0370]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2780, 0.2060, 0.2570, 0.2200, 0.0130, 0.0060, 0.0130, 0.0070]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1130, 0.3340, 0.0020, 0.0080, 0.1390, 0.4000, 0.0010, 0.0030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3470, 0.0110, 0.2440, 0.0030, 0.2390, 0.0020, 0.1520, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2690, 0.2770, 0.2230, 0.2270, 0.0030, 0.0000, 0.0010, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0660, 0.2650, 0.0400, 0.2070, 0.0390, 0.1890, 0.0220, 0.1720]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2390, 0.2030, 0.1740, 0.2110, 0.0470, 0.0510, 0.0320, 0.0430]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1330, 0.2680, 0.1070, 0.2220, 0.0520, 0.1040, 0.0450, 0.0690]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2610, 0.1360, 0.1310, 0.0580, 0.1950, 0.0830, 0.0960, 0.0400]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0320, 0.2190, 0.0260, 0.2020, 0.0350, 0.2200, 0.0380, 0.2280]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1030, 0.1630, 0.1040, 0.1500, 0.0960, 0.1420, 0.1090, 0.1330]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1320, 0.3340, 0.0290, 0.0840, 0.0980, 0.2430, 0.0210, 0.0590]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0110, 0.2290, 0.0090, 0.2810, 0.0090, 0.2320, 0.0120, 0.2170]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2670, 0.2230, 0.2380, 0.2050, 0.0160, 0.0160, 0.0210, 0.0140]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0050, 0.3030, 0.0080, 0.2130, 0.0090, 0.2720, 0.0080, 0.1820]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1200, 0.1480, 0.1090, 0.1270, 0.1130, 0.1580, 0.0850, 0.1400]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2940, 0.1310, 0.2170, 0.1230, 0.0880, 0.0400, 0.0690, 0.0380]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3100, 0.5350, 0.0510, 0.1040, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1490, 0.3470, 0.0760, 0.2200, 0.0440, 0.0870, 0.0250, 0.0520]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2250, 0.2150, 0.2260, 0.1900, 0.0330, 0.0420, 0.0340, 0.0350]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1220, 0.4830, 0.0000, 0.0050, 0.0770, 0.3090, 0.0010, 0.0030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1360, 0.1390, 0.1360, 0.1170, 0.1080, 0.1010, 0.1320, 0.1310]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1060, 0.4440, 0.0060, 0.0370, 0.0650, 0.3110, 0.0060, 0.0250]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1200, 0.2830, 0.1130, 0.2080, 0.0550, 0.0990, 0.0390, 0.0830]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1610, 0.2640, 0.1170, 0.2030, 0.0520, 0.0910, 0.0440, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1590, 0.3380, 0.0770, 0.1230, 0.0700, 0.1340, 0.0380, 0.0610]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1410, 0.2400, 0.1080, 0.2140, 0.0670, 0.1030, 0.0370, 0.0900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1520, 0.1180, 0.1310, 0.1310, 0.1130, 0.1010, 0.1490, 0.1050]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1720, 0.1500, 0.1420, 0.1290, 0.1120, 0.1050, 0.1000, 0.0900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3110, 0.0090, 0.3050, 0.0170, 0.1720, 0.0080, 0.1750, 0.0030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4780, 0.0050, 0.4730, 0.0050, 0.0250, 0.0000, 0.0140, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2880, 0.2460, 0.2640, 0.1900, 0.0030, 0.0020, 0.0050, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0720, 0.3900, 0.0260, 0.1240, 0.0470, 0.2440, 0.0100, 0.0870]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0160, 0.4050, 0.0130, 0.1500, 0.0130, 0.2690, 0.0060, 0.1280]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1720, 0.2820, 0.0270, 0.0510, 0.1540, 0.2470, 0.0330, 0.0340]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1260, 0.4010, 0.0010, 0.0100, 0.1170, 0.3350, 0.0050, 0.0050]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1550, 0.1120, 0.1560, 0.0910, 0.1510, 0.0790, 0.1560, 0.1000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1480, 0.1420, 0.1440, 0.1360, 0.1130, 0.0990, 0.1210, 0.0970]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0740, 0.2640, 0.0440, 0.1360, 0.0630, 0.2380, 0.0440, 0.1370]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0880, 0.1830, 0.0940, 0.1820, 0.0850, 0.1620, 0.0760, 0.1300]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1310, 0.2660, 0.1030, 0.2330, 0.0450, 0.0910, 0.0310, 0.1000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2660, 0.2110, 0.2280, 0.1940, 0.0240, 0.0300, 0.0230, 0.0240]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1200, 0.1410, 0.1220, 0.1240, 0.1210, 0.1160, 0.1140, 0.1420]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2190, 0.0210, 0.2230, 0.0390, 0.2380, 0.0240, 0.2100, 0.0260]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0460, 0.3460, 0.0180, 0.1190, 0.0460, 0.3030, 0.0150, 0.1070]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2100, 0.1850, 0.1920, 0.1630, 0.0540, 0.0760, 0.0680, 0.0520]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2380, 0.2320, 0.2360, 0.2250, 0.0110, 0.0200, 0.0170, 0.0210]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1480, 0.2620, 0.1010, 0.2410, 0.0440, 0.0890, 0.0390, 0.0760]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1070, 0.3480, 0.0440, 0.1770, 0.0520, 0.1520, 0.0250, 0.0950]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2300, 0.1730, 0.1680, 0.1400, 0.1020, 0.0760, 0.0560, 0.0550]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2800, 0.1890, 0.2390, 0.1990, 0.0240, 0.0240, 0.0220, 0.0230]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2790, 0.2730, 0.0180, 0.0260, 0.1850, 0.1900, 0.0150, 0.0140]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0330, 0.2400, 0.0350, 0.2120, 0.0370, 0.2140, 0.0220, 0.2070]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4860, 0.2560, 0.1670, 0.0850, 0.0030, 0.0020, 0.0010, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0760, 0.0580, 0.0470, 0.0530, 0.2330, 0.1820, 0.1750, 0.1760]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3070, 0.0020, 0.2110, 0.0020, 0.2760, 0.0000, 0.2020, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0060, 0.1890, 0.0000, 0.0230, 0.0190, 0.6870, 0.0030, 0.0730]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1190, 0.1150, 0.1410, 0.1540, 0.1150, 0.1180, 0.1160, 0.1220]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0750, 0.0310, 0.0740, 0.0360, 0.2730, 0.1280, 0.2530, 0.1300]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.6650, 0.1340, 0.0200, 0.0040, 0.1380, 0.0330, 0.0040, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1260, 0.2860, 0.1060, 0.2160, 0.0550, 0.1080, 0.0390, 0.0640]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0010, 0.5190, 0.0010, 0.2660, 0.0000, 0.1510, 0.0000, 0.0620]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "Training [10%]\tLoss: 2.3028\n",
      "output of QC = tensor([[0.0000, 0.6040, 0.0000, 0.1520, 0.0000, 0.1990, 0.0000, 0.0450]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1230, 0.2500, 0.1130, 0.2130, 0.0670, 0.1000, 0.0420, 0.0920]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0100, 0.0130, 0.0100, 0.0110, 0.2490, 0.2430, 0.2540, 0.2100]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0240, 0.0190, 0.0250, 0.0210, 0.2170, 0.2060, 0.2470, 0.2410]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0650, 0.0610, 0.0670, 0.0790, 0.1730, 0.1950, 0.1810, 0.1790]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1480, 0.2060, 0.1290, 0.2050, 0.0540, 0.1040, 0.0560, 0.0980]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0580, 0.2780, 0.0430, 0.1590, 0.0470, 0.2410, 0.0310, 0.1430]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1520, 0.2170, 0.1270, 0.1980, 0.0580, 0.1030, 0.0630, 0.0820]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2540, 0.1860, 0.2260, 0.1970, 0.0480, 0.0280, 0.0300, 0.0310]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0300, 0.1060, 0.0430, 0.1130, 0.0720, 0.2630, 0.0920, 0.2810]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1440, 0.2220, 0.1060, 0.1570, 0.0870, 0.1290, 0.0640, 0.0910]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1520, 0.2130, 0.1630, 0.2290, 0.0560, 0.0660, 0.0520, 0.0690]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1580, 0.2550, 0.1090, 0.2080, 0.0420, 0.1160, 0.0410, 0.0710]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.7450, 0.0650, 0.0810, 0.0040, 0.0880, 0.0090, 0.0060, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.2820, 0.0010, 0.2730, 0.0010, 0.2000, 0.0000, 0.2430]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0660, 0.7910, 0.0000, 0.0090, 0.0050, 0.1280, 0.0000, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0140, 0.3660, 0.0110, 0.2090, 0.0040, 0.2310, 0.0070, 0.1580]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2830, 0.0910, 0.2580, 0.0900, 0.1020, 0.0380, 0.1000, 0.0380]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2320, 0.0790, 0.1480, 0.0470, 0.2190, 0.0810, 0.1510, 0.0430]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.2830, 0.0000, 0.2140, 0.0000, 0.2660, 0.0000, 0.2370]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2890, 0.1880, 0.3010, 0.1520, 0.0260, 0.0090, 0.0250, 0.0100]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0830, 0.0840, 0.0840, 0.0560, 0.1680, 0.1650, 0.1780, 0.1820]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2130, 0.2090, 0.1860, 0.1650, 0.0510, 0.0590, 0.0600, 0.0570]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2530, 0.0100, 0.2540, 0.0200, 0.2400, 0.0180, 0.1930, 0.0120]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2610, 0.0340, 0.2150, 0.0320, 0.2090, 0.0260, 0.1750, 0.0480]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0270, 0.0210, 0.0190, 0.0120, 0.2760, 0.2670, 0.1910, 0.1870]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1760, 0.2350, 0.1000, 0.1800, 0.0610, 0.1130, 0.0450, 0.0900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1590, 0.1080, 0.0930, 0.0530, 0.2350, 0.1210, 0.1410, 0.0900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3440, 0.1020, 0.1520, 0.0500, 0.1910, 0.0550, 0.0810, 0.0250]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0550, 0.2040, 0.0560, 0.2130, 0.0770, 0.1840, 0.0470, 0.1640]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1310, 0.1310, 0.1220, 0.1260, 0.1250, 0.1070, 0.1250, 0.1330]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1390, 0.1350, 0.1430, 0.1140, 0.1310, 0.1220, 0.1310, 0.0850]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1180, 0.1580, 0.0850, 0.1400, 0.1070, 0.1760, 0.0760, 0.1400]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3050, 0.1130, 0.0900, 0.0410, 0.2270, 0.1050, 0.0790, 0.0400]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1990, 0.1600, 0.1540, 0.1400, 0.0960, 0.0990, 0.0850, 0.0670]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1320, 0.2120, 0.0640, 0.0870, 0.1370, 0.2130, 0.0560, 0.0990]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.7580, 0.0060, 0.0250, 0.0000, 0.2040, 0.0020, 0.0050, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2870, 0.1960, 0.1420, 0.0780, 0.1190, 0.0770, 0.0550, 0.0460]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1330, 0.1580, 0.0820, 0.1220, 0.1330, 0.1540, 0.0950, 0.1230]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1720, 0.1930, 0.1440, 0.1950, 0.0610, 0.0910, 0.0720, 0.0720]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4630, 0.0240, 0.1390, 0.0120, 0.2710, 0.0160, 0.0710, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3130, 0.1160, 0.1200, 0.0290, 0.2450, 0.0800, 0.0740, 0.0230]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2300, 0.1090, 0.1340, 0.0520, 0.2060, 0.0880, 0.1270, 0.0540]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1790, 0.1630, 0.0920, 0.0970, 0.1630, 0.1440, 0.0890, 0.0730]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3830, 0.0130, 0.1360, 0.0070, 0.3350, 0.0150, 0.1070, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1340, 0.2770, 0.1070, 0.2600, 0.0280, 0.0830, 0.0390, 0.0720]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1320, 0.2020, 0.1670, 0.2430, 0.0500, 0.0750, 0.0560, 0.0750]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1030, 0.5000, 0.0240, 0.1390, 0.0280, 0.1490, 0.0070, 0.0500]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1800, 0.1790, 0.1130, 0.1070, 0.1360, 0.1160, 0.0880, 0.0810]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1890, 0.2060, 0.2100, 0.2040, 0.0410, 0.0510, 0.0380, 0.0610]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1290, 0.1460, 0.1140, 0.1360, 0.1210, 0.1170, 0.1240, 0.1130]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1470, 0.1480, 0.1070, 0.1290, 0.1450, 0.1200, 0.1010, 0.1030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2950, 0.2410, 0.0100, 0.0100, 0.2370, 0.1910, 0.0090, 0.0070]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1190, 0.1300, 0.1180, 0.1200, 0.1420, 0.1200, 0.1250, 0.1260]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1600, 0.1550, 0.1400, 0.1500, 0.1080, 0.1000, 0.1030, 0.0840]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1710, 0.1110, 0.1450, 0.1090, 0.1450, 0.1160, 0.1110, 0.0920]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3420, 0.2210, 0.1010, 0.0570, 0.1230, 0.0810, 0.0450, 0.0300]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4290, 0.0010, 0.0960, 0.0000, 0.3870, 0.0010, 0.0860, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1460, 0.2510, 0.0380, 0.0620, 0.1340, 0.2860, 0.0270, 0.0560]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2530, 0.1900, 0.0530, 0.0380, 0.2300, 0.1580, 0.0380, 0.0400]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3670, 0.2170, 0.0100, 0.0040, 0.2600, 0.1310, 0.0090, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0250, 0.3180, 0.0110, 0.1460, 0.0240, 0.3260, 0.0140, 0.1360]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0180, 0.4550, 0.0150, 0.2410, 0.0090, 0.1660, 0.0050, 0.0910]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3600, 0.2560, 0.0720, 0.0440, 0.1410, 0.0890, 0.0250, 0.0130]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0660, 0.3020, 0.0270, 0.1150, 0.0500, 0.2970, 0.0350, 0.1080]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1540, 0.3410, 0.0000, 0.0000, 0.1290, 0.3760, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1640, 0.2050, 0.1390, 0.2090, 0.0720, 0.0860, 0.0600, 0.0650]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1360, 0.1060, 0.1430, 0.1300, 0.1410, 0.1210, 0.1110, 0.1120]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2550, 0.0000, 0.2450, 0.0000, 0.2680, 0.0010, 0.2310, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2030, 0.0340, 0.1920, 0.0540, 0.2010, 0.0530, 0.2090, 0.0540]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1740, 0.4530, 0.1000, 0.2570, 0.0020, 0.0070, 0.0020, 0.0050]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0900, 0.2280, 0.0380, 0.1310, 0.0940, 0.2410, 0.0450, 0.1330]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2010, 0.0930, 0.1720, 0.0770, 0.1620, 0.0840, 0.1300, 0.0810]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1280, 0.1300, 0.1350, 0.1390, 0.1140, 0.1090, 0.1260, 0.1190]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1350, 0.6770, 0.0080, 0.0450, 0.0170, 0.1090, 0.0010, 0.0080]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2360, 0.0490, 0.1930, 0.0410, 0.2130, 0.0380, 0.2050, 0.0250]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1610, 0.1320, 0.1250, 0.0840, 0.1630, 0.1170, 0.1220, 0.0960]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1240, 0.2920, 0.1160, 0.2450, 0.0290, 0.0820, 0.0360, 0.0760]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4530, 0.0680, 0.0130, 0.0000, 0.3960, 0.0580, 0.0080, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0280, 0.8670, 0.0050, 0.0700, 0.0010, 0.0260, 0.0000, 0.0030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0460, 0.5160, 0.0190, 0.1560, 0.0240, 0.1810, 0.0030, 0.0550]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1210, 0.1410, 0.1190, 0.1220, 0.1270, 0.1190, 0.1240, 0.1270]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4250, 0.0640, 0.0030, 0.0000, 0.4330, 0.0740, 0.0010, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1360, 0.1380, 0.1270, 0.1030, 0.1300, 0.1250, 0.1280, 0.1130]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1630, 0.1410, 0.1680, 0.1120, 0.1300, 0.1090, 0.1050, 0.0720]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1400, 0.1130, 0.1210, 0.1210, 0.1380, 0.1110, 0.1370, 0.1190]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1310, 0.1330, 0.1350, 0.1410, 0.1050, 0.1130, 0.1360, 0.1060]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1820, 0.7100, 0.0180, 0.0710, 0.0020, 0.0150, 0.0010, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1440, 0.1200, 0.1350, 0.1040, 0.1230, 0.1210, 0.1380, 0.1150]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4380, 0.1080, 0.0030, 0.0000, 0.3550, 0.0940, 0.0020, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0590, 0.3080, 0.0250, 0.1560, 0.0490, 0.2770, 0.0170, 0.1090]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1130, 0.1320, 0.1190, 0.1270, 0.1260, 0.1220, 0.1150, 0.1460]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1030, 0.4250, 0.0120, 0.0320, 0.0700, 0.3280, 0.0070, 0.0230]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0110, 0.6230, 0.0000, 0.0050, 0.0030, 0.3550, 0.0000, 0.0030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1220, 0.1220, 0.1390, 0.1260, 0.1270, 0.1350, 0.1130, 0.1160]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3770, 0.0090, 0.1350, 0.0050, 0.3410, 0.0190, 0.1100, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0280, 0.0940, 0.0970, 0.2360, 0.0490, 0.1000, 0.1030, 0.2930]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1890, 0.7640, 0.0030, 0.0040, 0.0070, 0.0330, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0410, 0.4660, 0.0000, 0.0000, 0.0240, 0.4680, 0.0000, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1630, 0.1110, 0.1450, 0.1160, 0.1160, 0.1120, 0.1310, 0.1060]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1250, 0.1150, 0.1360, 0.1200, 0.1220, 0.1260, 0.1410, 0.1150]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.8300, 0.0000, 0.0260, 0.0000, 0.1400, 0.0000, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0640, 0.3440, 0.0140, 0.0640, 0.0500, 0.3720, 0.0160, 0.0760]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1600, 0.2810, 0.1150, 0.1960, 0.0500, 0.1010, 0.0300, 0.0670]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2430, 0.0000, 0.2530, 0.0000, 0.2550, 0.0000, 0.2490, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1360, 0.1430, 0.1430, 0.1380, 0.1170, 0.1120, 0.1040, 0.1070]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0140, 0.5050, 0.0050, 0.1560, 0.0040, 0.2230, 0.0030, 0.0900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3590, 0.2710, 0.0470, 0.0350, 0.1500, 0.1040, 0.0200, 0.0140]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2030, 0.2970, 0.0850, 0.1490, 0.0580, 0.1140, 0.0390, 0.0550]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1440, 0.1200, 0.1350, 0.1340, 0.1160, 0.1290, 0.1020, 0.1200]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0730, 0.1680, 0.0590, 0.1770, 0.0800, 0.2100, 0.0630, 0.1700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0010, 0.7960, 0.0000, 0.1950, 0.0000, 0.0060, 0.0000, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2020, 0.0970, 0.1290, 0.0760, 0.1710, 0.1010, 0.1290, 0.0950]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1770, 0.1660, 0.1630, 0.1280, 0.0890, 0.1000, 0.0950, 0.0820]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0900, 0.2640, 0.0930, 0.2320, 0.0380, 0.1220, 0.0380, 0.1230]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1050, 0.0160, 0.4460, 0.0410, 0.0540, 0.0090, 0.2980, 0.0310]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1780, 0.2590, 0.1260, 0.2110, 0.0510, 0.0830, 0.0370, 0.0550]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4100, 0.0070, 0.0660, 0.0000, 0.4560, 0.0080, 0.0530, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1600, 0.0220, 0.3960, 0.0540, 0.1190, 0.0130, 0.2040, 0.0320]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0050, 0.8480, 0.0000, 0.0010, 0.0020, 0.1440, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0600, 0.4110, 0.0100, 0.0590, 0.0670, 0.3260, 0.0050, 0.0620]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1180, 0.1070, 0.1430, 0.1150, 0.0980, 0.1560, 0.1340, 0.1290]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1350, 0.1190, 0.1220, 0.1340, 0.1320, 0.1170, 0.1140, 0.1270]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1100, 0.4220, 0.0110, 0.0480, 0.0770, 0.3000, 0.0120, 0.0200]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1000, 0.2700, 0.1240, 0.2750, 0.0400, 0.0630, 0.0380, 0.0900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1390, 0.3410, 0.0750, 0.1630, 0.0610, 0.1170, 0.0370, 0.0670]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1240, 0.1180, 0.1110, 0.1260, 0.1200, 0.1450, 0.1270, 0.1290]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1180, 0.2750, 0.0250, 0.0820, 0.1050, 0.2850, 0.0300, 0.0800]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2340, 0.2050, 0.0900, 0.0960, 0.1500, 0.1160, 0.0610, 0.0480]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.7930, 0.0050, 0.1980, 0.0020, 0.0010, 0.0000, 0.0010, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1250, 0.3420, 0.1170, 0.2510, 0.0270, 0.0700, 0.0200, 0.0480]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1510, 0.2910, 0.1010, 0.2080, 0.0550, 0.0950, 0.0280, 0.0710]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1870, 0.0790, 0.2140, 0.0810, 0.1620, 0.0680, 0.1510, 0.0580]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2060, 0.0730, 0.1440, 0.0710, 0.1790, 0.0800, 0.1700, 0.0770]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3610, 0.0000, 0.1480, 0.0010, 0.3590, 0.0000, 0.1310, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1600, 0.3360, 0.0130, 0.0180, 0.1270, 0.3190, 0.0070, 0.0200]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0070, 0.6470, 0.0020, 0.1310, 0.0050, 0.1680, 0.0000, 0.0400]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1120, 0.2680, 0.1080, 0.2810, 0.0410, 0.0910, 0.0310, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1090, 0.1390, 0.1220, 0.1310, 0.1210, 0.1170, 0.1390, 0.1220]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.0080, 0.0090, 0.7900, 0.0010, 0.0010, 0.0010, 0.1900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1400, 0.7500, 0.0100, 0.0830, 0.0000, 0.0150, 0.0000, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2970, 0.1210, 0.0630, 0.0320, 0.2820, 0.1070, 0.0640, 0.0340]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1820, 0.1030, 0.1470, 0.0860, 0.1720, 0.0760, 0.1440, 0.0900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2280, 0.0410, 0.2010, 0.0320, 0.2400, 0.0390, 0.1900, 0.0290]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0060, 0.5200, 0.0000, 0.0000, 0.0010, 0.4730, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.5120, 0.0510, 0.1500, 0.0120, 0.2000, 0.0150, 0.0560, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0680, 0.6170, 0.0120, 0.2030, 0.0060, 0.0640, 0.0020, 0.0280]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4450, 0.1720, 0.1060, 0.0340, 0.1590, 0.0400, 0.0310, 0.0130]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1470, 0.1020, 0.1430, 0.1110, 0.1280, 0.1120, 0.1420, 0.1150]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3610, 0.0810, 0.1340, 0.0260, 0.2480, 0.0510, 0.0820, 0.0170]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2550, 0.1540, 0.2080, 0.1110, 0.0900, 0.0600, 0.0780, 0.0440]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.5090, 0.0050, 0.0000, 0.0000, 0.4840, 0.0020, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3210, 0.0280, 0.1480, 0.0130, 0.3200, 0.0230, 0.1360, 0.0110]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1820, 0.1390, 0.1440, 0.1370, 0.1210, 0.0920, 0.0920, 0.0930]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0020, 0.2920, 0.0000, 0.2180, 0.0010, 0.2700, 0.0030, 0.2140]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1960, 0.0820, 0.1760, 0.0900, 0.1730, 0.0680, 0.1520, 0.0630]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0050, 0.4160, 0.0000, 0.0920, 0.0010, 0.4040, 0.0020, 0.0800]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1290, 0.3280, 0.1080, 0.2270, 0.0360, 0.0880, 0.0270, 0.0570]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.6630, 0.0420, 0.2480, 0.0210, 0.0130, 0.0030, 0.0090, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2150, 0.0450, 0.2010, 0.0380, 0.2030, 0.0500, 0.1890, 0.0590]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2670, 0.0050, 0.2350, 0.0040, 0.2440, 0.0150, 0.2280, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2500, 0.0560, 0.2050, 0.0310, 0.2090, 0.0470, 0.1710, 0.0310]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0380, 0.2900, 0.0500, 0.4340, 0.0090, 0.0610, 0.0120, 0.1060]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1220, 0.3360, 0.0910, 0.2780, 0.0250, 0.0660, 0.0240, 0.0580]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2440, 0.2590, 0.1860, 0.2430, 0.0200, 0.0170, 0.0150, 0.0160]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2650, 0.5290, 0.0390, 0.0950, 0.0270, 0.0390, 0.0040, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1330, 0.3290, 0.1060, 0.2070, 0.0430, 0.0970, 0.0300, 0.0550]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4540, 0.1160, 0.0040, 0.0020, 0.3420, 0.0730, 0.0080, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.5300, 0.0220, 0.0880, 0.0070, 0.2820, 0.0140, 0.0560, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4830, 0.0220, 0.0680, 0.0030, 0.3550, 0.0130, 0.0560, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1440, 0.3250, 0.0830, 0.1660, 0.0540, 0.1320, 0.0320, 0.0640]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1270, 0.3150, 0.1050, 0.2500, 0.0330, 0.0720, 0.0260, 0.0720]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1090, 0.2210, 0.0690, 0.1500, 0.0760, 0.1970, 0.0620, 0.1160]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1350, 0.3140, 0.0880, 0.2880, 0.0230, 0.0750, 0.0240, 0.0530]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3090, 0.0130, 0.1880, 0.0080, 0.2810, 0.0110, 0.1830, 0.0070]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0310, 0.4600, 0.0030, 0.0520, 0.0260, 0.3920, 0.0020, 0.0340]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.6250, 0.0010, 0.0350, 0.0000, 0.3320, 0.0000, 0.0070, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.4430, 0.0010, 0.1270, 0.0000, 0.3300, 0.0000, 0.0990]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.7250, 0.1840, 0.0060, 0.0020, 0.0670, 0.0150, 0.0010, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1160, 0.2700, 0.1200, 0.2340, 0.0430, 0.1100, 0.0260, 0.0810]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0730, 0.5020, 0.0100, 0.0890, 0.0340, 0.2460, 0.0090, 0.0370]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4720, 0.2800, 0.1180, 0.0710, 0.0240, 0.0210, 0.0080, 0.0060]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0550, 0.4310, 0.0000, 0.0020, 0.0640, 0.4430, 0.0010, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0390, 0.0280, 0.3370, 0.2070, 0.0340, 0.0210, 0.2000, 0.1340]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0940, 0.3060, 0.0210, 0.0640, 0.0930, 0.3450, 0.0130, 0.0640]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1390, 0.2810, 0.1130, 0.2310, 0.0320, 0.0830, 0.0280, 0.0930]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.6780, 0.1870, 0.0880, 0.0270, 0.0130, 0.0050, 0.0010, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1660, 0.0780, 0.3770, 0.1230, 0.0580, 0.0280, 0.1300, 0.0400]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0010, 0.0110, 0.0180, 0.5980, 0.0000, 0.0090, 0.0090, 0.3540]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3720, 0.0070, 0.1300, 0.0020, 0.3750, 0.0050, 0.1080, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1330, 0.2580, 0.1290, 0.2950, 0.0300, 0.0650, 0.0310, 0.0590]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0400, 0.0230, 0.3210, 0.1670, 0.0280, 0.0140, 0.2640, 0.1430]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2900, 0.2100, 0.1280, 0.1000, 0.1070, 0.0730, 0.0530, 0.0390]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1120, 0.2800, 0.1160, 0.3110, 0.0410, 0.0580, 0.0250, 0.0570]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0950, 0.2740, 0.1250, 0.3110, 0.0230, 0.0720, 0.0320, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4780, 0.0600, 0.0010, 0.0000, 0.4070, 0.0520, 0.0020, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1610, 0.2730, 0.0600, 0.0860, 0.1300, 0.1900, 0.0390, 0.0610]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1690, 0.0840, 0.1640, 0.0820, 0.1520, 0.0990, 0.1690, 0.0810]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1370, 0.3270, 0.1040, 0.2230, 0.0300, 0.0910, 0.0320, 0.0560]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4150, 0.0000, 0.1200, 0.0000, 0.3640, 0.0000, 0.1010, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "Training [20%]\tLoss: 2.3019\n",
      "output of QC = tensor([[0.4770, 0.0030, 0.0090, 0.0000, 0.5010, 0.0020, 0.0080, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4390, 0.0570, 0.0560, 0.0090, 0.3240, 0.0630, 0.0450, 0.0070]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3250, 0.0660, 0.1040, 0.0200, 0.2920, 0.0700, 0.0930, 0.0300]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1390, 0.0000, 0.4110, 0.0030, 0.1190, 0.0000, 0.3280, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0250, 0.1500, 0.0660, 0.4800, 0.0060, 0.0580, 0.0250, 0.1900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1090, 0.2660, 0.1270, 0.2620, 0.0350, 0.0840, 0.0250, 0.0920]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2460, 0.1330, 0.0720, 0.0380, 0.2700, 0.1250, 0.0880, 0.0280]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1340, 0.3020, 0.0980, 0.2430, 0.0300, 0.0980, 0.0270, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1550, 0.3040, 0.1120, 0.2250, 0.0370, 0.0800, 0.0360, 0.0510]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.5700, 0.2110, 0.0560, 0.0260, 0.0940, 0.0270, 0.0120, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4760, 0.0820, 0.0380, 0.0050, 0.3050, 0.0580, 0.0280, 0.0080]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1250, 0.2910, 0.1090, 0.2970, 0.0270, 0.0680, 0.0370, 0.0460]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1160, 0.3380, 0.0410, 0.1360, 0.0710, 0.1770, 0.0260, 0.0950]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1070, 0.2920, 0.1250, 0.2740, 0.0250, 0.0810, 0.0310, 0.0650]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4530, 0.0100, 0.5190, 0.0120, 0.0030, 0.0000, 0.0020, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.0010, 0.0240, 0.4580, 0.0000, 0.0000, 0.0220, 0.4950]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1200, 0.2990, 0.0900, 0.2470, 0.0430, 0.0980, 0.0290, 0.0740]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3070, 0.0670, 0.1790, 0.0510, 0.2030, 0.0440, 0.1250, 0.0240]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.0000, 0.4200, 0.2040, 0.0000, 0.0000, 0.2490, 0.1270]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2310, 0.1290, 0.1050, 0.0480, 0.2410, 0.1310, 0.0740, 0.0410]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1180, 0.3000, 0.1050, 0.2620, 0.0240, 0.0780, 0.0390, 0.0740]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1720, 0.3170, 0.0020, 0.0100, 0.1760, 0.3120, 0.0020, 0.0090]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3910, 0.1010, 0.0000, 0.0000, 0.4010, 0.1070, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.3620, 0.0000, 0.6160, 0.0000, 0.0120, 0.0000, 0.0100]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.0860, 0.0000, 0.4350, 0.0000, 0.0770, 0.0010, 0.4010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1150, 0.3240, 0.0980, 0.2970, 0.0210, 0.0720, 0.0240, 0.0490]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0350, 0.4350, 0.0000, 0.0380, 0.0380, 0.4160, 0.0050, 0.0330]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2520, 0.0820, 0.1710, 0.0310, 0.2200, 0.0740, 0.1300, 0.0400]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.8810, 0.1170, 0.0020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.7020, 0.1410, 0.0780, 0.0120, 0.0510, 0.0120, 0.0040, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0090, 0.1100, 0.0590, 0.3510, 0.0090, 0.1070, 0.0500, 0.3050]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0010, 0.0340, 0.0210, 0.5030, 0.0020, 0.0300, 0.0170, 0.3920]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3270, 0.0010, 0.1930, 0.0000, 0.3030, 0.0030, 0.1720, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1700, 0.2300, 0.0550, 0.0760, 0.1540, 0.1760, 0.0710, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1300, 0.2930, 0.1170, 0.2620, 0.0340, 0.0810, 0.0230, 0.0600]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.8710, 0.0210, 0.0700, 0.0000, 0.0330, 0.0010, 0.0040, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1560, 0.3090, 0.0960, 0.1970, 0.0520, 0.0910, 0.0320, 0.0670]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1180, 0.3350, 0.1110, 0.2560, 0.0210, 0.0740, 0.0200, 0.0650]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0160, 0.0000, 0.4950, 0.0000, 0.0140, 0.0000, 0.4740, 0.0010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0470, 0.0720, 0.1550, 0.2400, 0.0460, 0.0560, 0.1710, 0.2130]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0250, 0.0290, 0.1960, 0.2640, 0.0180, 0.0340, 0.1690, 0.2650]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1300, 0.2830, 0.0940, 0.2070, 0.0660, 0.1040, 0.0390, 0.0770]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1240, 0.3310, 0.1100, 0.2380, 0.0280, 0.0880, 0.0300, 0.0510]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0150, 0.3040, 0.0150, 0.1700, 0.0170, 0.2930, 0.0080, 0.1780]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0170, 0.1120, 0.0800, 0.3390, 0.0210, 0.0860, 0.0630, 0.2820]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1130, 0.3180, 0.0890, 0.3160, 0.0230, 0.0730, 0.0150, 0.0530]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0020, 0.7390, 0.0010, 0.2030, 0.0000, 0.0420, 0.0000, 0.0130]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4270, 0.4290, 0.0210, 0.0210, 0.0480, 0.0490, 0.0010, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1520, 0.2780, 0.1000, 0.2570, 0.0400, 0.0910, 0.0190, 0.0630]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0150, 0.3550, 0.0010, 0.1280, 0.0100, 0.3370, 0.0050, 0.1490]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1630, 0.2820, 0.1060, 0.2270, 0.0330, 0.0860, 0.0280, 0.0750]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.0020, 0.1710, 0.3120, 0.0020, 0.0010, 0.1750, 0.3370]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0090, 0.1230, 0.0350, 0.3980, 0.0090, 0.0900, 0.0290, 0.3070]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0060, 0.0290, 0.1130, 0.4450, 0.0040, 0.0140, 0.0800, 0.3090]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1360, 0.3160, 0.0900, 0.2820, 0.0340, 0.0590, 0.0270, 0.0560]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1960, 0.2230, 0.0720, 0.0810, 0.1470, 0.1840, 0.0490, 0.0480]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0480, 0.2790, 0.0440, 0.1620, 0.0570, 0.2240, 0.0340, 0.1520]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0030, 0.5340, 0.0000, 0.0090, 0.0000, 0.4490, 0.0000, 0.0050]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1090, 0.3220, 0.1090, 0.2610, 0.0170, 0.0920, 0.0250, 0.0650]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1480, 0.5530, 0.0230, 0.0900, 0.0300, 0.1270, 0.0030, 0.0260]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1310, 0.3170, 0.1150, 0.2290, 0.0260, 0.0900, 0.0240, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1040, 0.2740, 0.1270, 0.2810, 0.0310, 0.0830, 0.0280, 0.0720]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0650, 0.4900, 0.0390, 0.3010, 0.0140, 0.0500, 0.0010, 0.0400]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1260, 0.2790, 0.1120, 0.2830, 0.0320, 0.0710, 0.0300, 0.0670]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0490, 0.2470, 0.0330, 0.1930, 0.0580, 0.2320, 0.0300, 0.1580]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0010, 0.0000, 0.1970, 0.2880, 0.0000, 0.0010, 0.2190, 0.2940]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1840, 0.3320, 0.0000, 0.0000, 0.1470, 0.3370, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0320, 0.4610, 0.0320, 0.2900, 0.0050, 0.1040, 0.0070, 0.0690]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1330, 0.3490, 0.0890, 0.2540, 0.0230, 0.0740, 0.0240, 0.0540]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.8720, 0.0960, 0.0040, 0.0000, 0.0260, 0.0020, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1240, 0.2790, 0.1120, 0.2520, 0.0320, 0.0730, 0.0400, 0.0880]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0020, 0.0380, 0.0590, 0.4230, 0.0050, 0.0300, 0.0400, 0.4030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1840, 0.0890, 0.0150, 0.0110, 0.4410, 0.1990, 0.0460, 0.0150]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1010, 0.3240, 0.0960, 0.2820, 0.0210, 0.0740, 0.0210, 0.0810]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2120, 0.2720, 0.0080, 0.0160, 0.2000, 0.2560, 0.0130, 0.0230]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1300, 0.3250, 0.0940, 0.2040, 0.0510, 0.1090, 0.0330, 0.0540]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1510, 0.3790, 0.0660, 0.1970, 0.0460, 0.0970, 0.0190, 0.0450]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1140, 0.2990, 0.1060, 0.2850, 0.0180, 0.0800, 0.0220, 0.0760]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1430, 0.3720, 0.0860, 0.1900, 0.0340, 0.0910, 0.0220, 0.0620]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.1280, 0.0010, 0.6350, 0.0000, 0.0230, 0.0010, 0.2120]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1080, 0.3800, 0.0910, 0.2220, 0.0290, 0.0900, 0.0180, 0.0620]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1330, 0.3320, 0.1080, 0.2460, 0.0260, 0.0700, 0.0280, 0.0570]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1400, 0.3010, 0.0110, 0.0400, 0.1470, 0.3110, 0.0220, 0.0280]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2300, 0.0560, 0.2060, 0.0390, 0.2210, 0.0560, 0.1470, 0.0450]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2990, 0.4190, 0.0020, 0.0000, 0.1090, 0.1710, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.0000, 0.0900, 0.4120, 0.0000, 0.0000, 0.1140, 0.3840]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1350, 0.3020, 0.1080, 0.2420, 0.0310, 0.0820, 0.0360, 0.0640]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0440, 0.7440, 0.0050, 0.0760, 0.0080, 0.1110, 0.0000, 0.0120]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0020, 0.0520, 0.0280, 0.6260, 0.0000, 0.0150, 0.0090, 0.2680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1790, 0.2810, 0.0190, 0.0320, 0.1720, 0.2630, 0.0210, 0.0330]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1430, 0.2850, 0.0920, 0.2110, 0.0560, 0.0950, 0.0380, 0.0800]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3000, 0.0140, 0.2660, 0.0160, 0.1910, 0.0170, 0.1830, 0.0130]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1300, 0.2810, 0.1030, 0.2080, 0.0500, 0.1040, 0.0490, 0.0750]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1120, 0.3120, 0.0130, 0.0360, 0.1160, 0.3680, 0.0090, 0.0340]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4970, 0.0050, 0.0020, 0.0000, 0.4880, 0.0050, 0.0030, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1420, 0.2980, 0.1050, 0.2240, 0.0410, 0.1000, 0.0420, 0.0480]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.0060, 0.0030, 0.5330, 0.0000, 0.0120, 0.0010, 0.4450]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0520, 0.4280, 0.0020, 0.0310, 0.0570, 0.3890, 0.0050, 0.0360]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1110, 0.1720, 0.0700, 0.1470, 0.1120, 0.1790, 0.0720, 0.1370]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1050, 0.2680, 0.1090, 0.2930, 0.0340, 0.0780, 0.0370, 0.0760]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1380, 0.3120, 0.1140, 0.2220, 0.0310, 0.0920, 0.0230, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1150, 0.3700, 0.0080, 0.0160, 0.1090, 0.3560, 0.0070, 0.0190]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1550, 0.3320, 0.0040, 0.0060, 0.1600, 0.3320, 0.0010, 0.0100]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.0000, 0.0090, 0.5020, 0.0000, 0.0000, 0.0090, 0.4800]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.3590, 0.0000, 0.1330, 0.0010, 0.3800, 0.0000, 0.1270]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3170, 0.1770, 0.0150, 0.0100, 0.3030, 0.1630, 0.0100, 0.0050]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0140, 0.0530, 0.0920, 0.3360, 0.0220, 0.0580, 0.0860, 0.3390]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0510, 0.3580, 0.0260, 0.0830, 0.0410, 0.3170, 0.0160, 0.1080]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0010, 0.0860, 0.0070, 0.8900, 0.0000, 0.0020, 0.0000, 0.0140]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1070, 0.2570, 0.1100, 0.2650, 0.0420, 0.0930, 0.0380, 0.0880]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3520, 0.2850, 0.1820, 0.1330, 0.0200, 0.0120, 0.0060, 0.0100]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1270, 0.2140, 0.0590, 0.1200, 0.1270, 0.1970, 0.0570, 0.0990]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1700, 0.2730, 0.1070, 0.2110, 0.0450, 0.0840, 0.0400, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1700, 0.2780, 0.0930, 0.2250, 0.0500, 0.0810, 0.0440, 0.0590]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0890, 0.0160, 0.5510, 0.1040, 0.0280, 0.0050, 0.1650, 0.0420]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2540, 0.0070, 0.2340, 0.0040, 0.2560, 0.0030, 0.2400, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1360, 0.3100, 0.1000, 0.2730, 0.0170, 0.0660, 0.0270, 0.0710]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2300, 0.0490, 0.1830, 0.0410, 0.2070, 0.0490, 0.1990, 0.0420]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4020, 0.3250, 0.0660, 0.0680, 0.0590, 0.0570, 0.0130, 0.0100]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2700, 0.0020, 0.2440, 0.0020, 0.2630, 0.0030, 0.2130, 0.0030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.7590, 0.1240, 0.1020, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0170, 0.3330, 0.0110, 0.1550, 0.0160, 0.3030, 0.0060, 0.1590]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0060, 0.1750, 0.0060, 0.3330, 0.0020, 0.1550, 0.0100, 0.3130]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.7310, 0.0030, 0.1570, 0.0010, 0.0950, 0.0000, 0.0130, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1370, 0.2580, 0.1120, 0.2070, 0.0570, 0.1050, 0.0480, 0.0760]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2160, 0.0380, 0.2170, 0.0290, 0.2150, 0.0340, 0.2130, 0.0380]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0320, 0.1260, 0.1470, 0.5700, 0.0010, 0.0130, 0.0200, 0.0910]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1330, 0.0970, 0.1550, 0.1070, 0.1490, 0.1030, 0.1470, 0.1090]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2320, 0.0380, 0.1880, 0.0500, 0.1960, 0.0510, 0.1950, 0.0500]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0130, 0.2400, 0.0160, 0.2430, 0.0110, 0.2380, 0.0060, 0.2330]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1380, 0.2640, 0.1220, 0.2370, 0.0400, 0.0960, 0.0300, 0.0730]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1630, 0.1080, 0.1080, 0.1020, 0.1610, 0.1320, 0.1160, 0.1100]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1340, 0.2710, 0.1090, 0.2400, 0.0420, 0.1020, 0.0290, 0.0730]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2130, 0.0130, 0.5290, 0.0350, 0.0620, 0.0040, 0.1340, 0.0100]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1300, 0.2910, 0.1360, 0.2210, 0.0280, 0.0720, 0.0420, 0.0800]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3220, 0.3950, 0.1110, 0.1610, 0.0050, 0.0010, 0.0020, 0.0030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0030, 0.1380, 0.0100, 0.7060, 0.0010, 0.0210, 0.0020, 0.1190]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1510, 0.2800, 0.1230, 0.1960, 0.0450, 0.0840, 0.0460, 0.0750]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1040, 0.1390, 0.3020, 0.4340, 0.0060, 0.0030, 0.0060, 0.0060]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1430, 0.3230, 0.1130, 0.1900, 0.0500, 0.0950, 0.0230, 0.0630]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0050, 0.3080, 0.0020, 0.1810, 0.0020, 0.3200, 0.0020, 0.1800]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2310, 0.0370, 0.2210, 0.0240, 0.1990, 0.0320, 0.2160, 0.0400]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0020, 0.0030, 0.4300, 0.4080, 0.0010, 0.0000, 0.0750, 0.0810]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1130, 0.2680, 0.1220, 0.2230, 0.0570, 0.0890, 0.0390, 0.0890]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1740, 0.0000, 0.4960, 0.0000, 0.0840, 0.0000, 0.2460, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.0680, 0.0090, 0.4870, 0.0010, 0.0580, 0.0030, 0.3740]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1150, 0.2930, 0.1300, 0.2600, 0.0310, 0.0730, 0.0410, 0.0570]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2350, 0.0380, 0.2460, 0.0390, 0.2050, 0.0370, 0.1680, 0.0320]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4250, 0.0770, 0.2030, 0.0330, 0.1750, 0.0250, 0.0540, 0.0080]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1300, 0.2560, 0.1350, 0.2260, 0.0500, 0.0850, 0.0480, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3880, 0.0010, 0.1150, 0.0000, 0.3580, 0.0000, 0.1380, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1590, 0.0920, 0.1480, 0.1070, 0.1480, 0.0850, 0.1590, 0.1020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1230, 0.2400, 0.2260, 0.3960, 0.0000, 0.0040, 0.0040, 0.0070]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1140, 0.2950, 0.1160, 0.2460, 0.0330, 0.0900, 0.0310, 0.0750]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1370, 0.3710, 0.0900, 0.3330, 0.0030, 0.0320, 0.0090, 0.0250]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1770, 0.2360, 0.0970, 0.1620, 0.0690, 0.1230, 0.0460, 0.0900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1420, 0.3020, 0.1110, 0.1940, 0.0530, 0.0880, 0.0400, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1360, 0.0990, 0.1360, 0.1140, 0.1620, 0.1010, 0.1490, 0.1030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1110, 0.3020, 0.1190, 0.2660, 0.0320, 0.0650, 0.0370, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1370, 0.2780, 0.1160, 0.2580, 0.0390, 0.0750, 0.0260, 0.0710]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1720, 0.0780, 0.1760, 0.1010, 0.1520, 0.0810, 0.1480, 0.0920]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2490, 0.1980, 0.2590, 0.2030, 0.0310, 0.0240, 0.0160, 0.0200]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2370, 0.0230, 0.2550, 0.0210, 0.2210, 0.0240, 0.2070, 0.0120]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1480, 0.3190, 0.0910, 0.2360, 0.0490, 0.0820, 0.0220, 0.0530]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1650, 0.0850, 0.1590, 0.0800, 0.1700, 0.0870, 0.1670, 0.0870]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2030, 0.1200, 0.1090, 0.0790, 0.1870, 0.1240, 0.1100, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0040, 0.0140, 0.1510, 0.4040, 0.0040, 0.0070, 0.1360, 0.2800]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1490, 0.2830, 0.1060, 0.2410, 0.0390, 0.0850, 0.0330, 0.0640]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1720, 0.2790, 0.1050, 0.1680, 0.0570, 0.1010, 0.0380, 0.0800]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2880, 0.0420, 0.1430, 0.0230, 0.2810, 0.0510, 0.1500, 0.0220]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1310, 0.2960, 0.0170, 0.0660, 0.1230, 0.3110, 0.0160, 0.0400]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1690, 0.0990, 0.1370, 0.0910, 0.1540, 0.0980, 0.1550, 0.0970]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1410, 0.1120, 0.1540, 0.1130, 0.1490, 0.0800, 0.1550, 0.0960]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1270, 0.2430, 0.1150, 0.2300, 0.0400, 0.1100, 0.0440, 0.0910]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1960, 0.0580, 0.2280, 0.0560, 0.1810, 0.0500, 0.1880, 0.0430]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1760, 0.2430, 0.1130, 0.2160, 0.0550, 0.0810, 0.0390, 0.0770]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1350, 0.2640, 0.1080, 0.2320, 0.0460, 0.1000, 0.0320, 0.0830]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4320, 0.0020, 0.3140, 0.0020, 0.1510, 0.0000, 0.0990, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1400, 0.3080, 0.0990, 0.2180, 0.0500, 0.0870, 0.0300, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1600, 0.0860, 0.1650, 0.0710, 0.1720, 0.0860, 0.1790, 0.0810]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2510, 0.0300, 0.2420, 0.0190, 0.2080, 0.0200, 0.2080, 0.0220]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1170, 0.1310, 0.1280, 0.1170, 0.1410, 0.1210, 0.1240, 0.1210]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0780, 0.2000, 0.0580, 0.1450, 0.0780, 0.2140, 0.0560, 0.1710]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1290, 0.1210, 0.1320, 0.1140, 0.1350, 0.1210, 0.1220, 0.1260]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0090, 0.2910, 0.0030, 0.2170, 0.0030, 0.2710, 0.0030, 0.2030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2500, 0.0220, 0.2120, 0.0220, 0.2520, 0.0250, 0.2030, 0.0140]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1420, 0.1200, 0.1450, 0.1100, 0.1440, 0.1050, 0.1110, 0.1230]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2460, 0.0000, 0.2390, 0.0000, 0.2320, 0.0000, 0.2830, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2150, 0.0880, 0.1310, 0.0610, 0.2140, 0.1090, 0.1320, 0.0500]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1260, 0.2400, 0.1230, 0.2250, 0.0640, 0.0870, 0.0460, 0.0890]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1240, 0.1240, 0.1420, 0.1350, 0.1300, 0.1020, 0.1240, 0.1190]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0730, 0.1950, 0.0490, 0.1550, 0.0900, 0.2150, 0.0490, 0.1740]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1790, 0.1130, 0.1420, 0.1020, 0.1300, 0.0940, 0.1360, 0.1040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0330, 0.0450, 0.1860, 0.2420, 0.0370, 0.0460, 0.1630, 0.2480]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1160, 0.1960, 0.1420, 0.2230, 0.0480, 0.1010, 0.0650, 0.1090]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1480, 0.1370, 0.1510, 0.1050, 0.1210, 0.1180, 0.1240, 0.0960]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1010, 0.0360, 0.0840, 0.0260, 0.3060, 0.1220, 0.2280, 0.0970]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1350, 0.2250, 0.1160, 0.2270, 0.0520, 0.0930, 0.0570, 0.0950]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1140, 0.2360, 0.1150, 0.2480, 0.0470, 0.0950, 0.0460, 0.0990]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1780, 0.1970, 0.2190, 0.1950, 0.0580, 0.0540, 0.0610, 0.0380]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "Training [30%]\tLoss: 2.3023\n",
      "output of QC = tensor([[0.1300, 0.2440, 0.1110, 0.2150, 0.0610, 0.0970, 0.0490, 0.0930]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1600, 0.1610, 0.1610, 0.1490, 0.0880, 0.1000, 0.0880, 0.0930]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1420, 0.3010, 0.1040, 0.2320, 0.0300, 0.0860, 0.0320, 0.0730]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1740, 0.2150, 0.2210, 0.1930, 0.0560, 0.0410, 0.0420, 0.0580]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1170, 0.3190, 0.0190, 0.0760, 0.0840, 0.3040, 0.0190, 0.0620]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2460, 0.0310, 0.1980, 0.0290, 0.2170, 0.0280, 0.2290, 0.0220]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1330, 0.2540, 0.1210, 0.2200, 0.0620, 0.0890, 0.0560, 0.0650]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.5380, 0.2420, 0.0050, 0.0020, 0.1560, 0.0570, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1330, 0.1230, 0.1410, 0.1190, 0.1170, 0.1250, 0.1270, 0.1150]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1380, 0.2650, 0.1260, 0.1710, 0.0610, 0.1040, 0.0480, 0.0870]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0020, 0.3940, 0.0000, 0.1230, 0.0010, 0.3620, 0.0000, 0.1180]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2790, 0.0500, 0.1470, 0.0300, 0.2620, 0.0540, 0.1590, 0.0190]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3070, 0.1150, 0.2130, 0.0820, 0.1360, 0.0410, 0.0840, 0.0220]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1460, 0.2720, 0.0890, 0.2410, 0.0490, 0.0860, 0.0380, 0.0790]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.5020, 0.0580, 0.0630, 0.0130, 0.2900, 0.0340, 0.0330, 0.0070]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1400, 0.2720, 0.1240, 0.2370, 0.0460, 0.0770, 0.0340, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2940, 0.0000, 0.2380, 0.0010, 0.2350, 0.0010, 0.2310, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3600, 0.1240, 0.0110, 0.0040, 0.3540, 0.1250, 0.0180, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1810, 0.2400, 0.1500, 0.1860, 0.0630, 0.0790, 0.0410, 0.0600]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1810, 0.1000, 0.1530, 0.1070, 0.1410, 0.0960, 0.1360, 0.0860]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1460, 0.1210, 0.1290, 0.0990, 0.1640, 0.1120, 0.1260, 0.1030]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1460, 0.2590, 0.1050, 0.2150, 0.0530, 0.0950, 0.0420, 0.0850]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2610, 0.0000, 0.2450, 0.0000, 0.2380, 0.0000, 0.2560, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1120, 0.1220, 0.1360, 0.1280, 0.1270, 0.1360, 0.1200, 0.1190]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1500, 0.2770, 0.1070, 0.1960, 0.0600, 0.1020, 0.0360, 0.0720]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1300, 0.1240, 0.1140, 0.1360, 0.1340, 0.1250, 0.1130, 0.1240]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0180, 0.3150, 0.0030, 0.1790, 0.0150, 0.3430, 0.0060, 0.1210]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1440, 0.1060, 0.1470, 0.1020, 0.1460, 0.1130, 0.1410, 0.1010]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1520, 0.1020, 0.1330, 0.1160, 0.1550, 0.0920, 0.1290, 0.1210]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1290, 0.1270, 0.1380, 0.1270, 0.1230, 0.1080, 0.1430, 0.1050]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1690, 0.2840, 0.0950, 0.1480, 0.0740, 0.1080, 0.0380, 0.0840]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1400, 0.1370, 0.1270, 0.1060, 0.1120, 0.1230, 0.1150, 0.1400]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1350, 0.2750, 0.1230, 0.2400, 0.0370, 0.0880, 0.0340, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1260, 0.2620, 0.1110, 0.2320, 0.0540, 0.1010, 0.0370, 0.0770]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0640, 0.0540, 0.0120, 0.0140, 0.4200, 0.3010, 0.0840, 0.0510]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1330, 0.2980, 0.1150, 0.2270, 0.0390, 0.0820, 0.0360, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1450, 0.2470, 0.1400, 0.2190, 0.0440, 0.0980, 0.0370, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1650, 0.2790, 0.1230, 0.2060, 0.0490, 0.0770, 0.0310, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2770, 0.0040, 0.2590, 0.0010, 0.2310, 0.0030, 0.2180, 0.0070]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1600, 0.2610, 0.1220, 0.2040, 0.0610, 0.0830, 0.0500, 0.0590]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1590, 0.2760, 0.1010, 0.1830, 0.0620, 0.1050, 0.0470, 0.0670]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1610, 0.2710, 0.1450, 0.1950, 0.0440, 0.0770, 0.0450, 0.0620]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1700, 0.3010, 0.1220, 0.1830, 0.0430, 0.0880, 0.0350, 0.0580]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1390, 0.2810, 0.1210, 0.2240, 0.0410, 0.0950, 0.0330, 0.0660]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0630, 0.1960, 0.0700, 0.1840, 0.0800, 0.1550, 0.0730, 0.1790]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2300, 0.0350, 0.2040, 0.0280, 0.2470, 0.0280, 0.2100, 0.0180]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0340, 0.0330, 0.0340, 0.0270, 0.2290, 0.2090, 0.2140, 0.2200]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1620, 0.0720, 0.1910, 0.0820, 0.1480, 0.0830, 0.1720, 0.0900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1360, 0.2200, 0.1240, 0.2280, 0.0690, 0.1020, 0.0410, 0.0800]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1640, 0.0920, 0.1480, 0.0790, 0.1540, 0.0850, 0.1760, 0.1020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0480, 0.4620, 0.0000, 0.0030, 0.0450, 0.4320, 0.0010, 0.0090]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1500, 0.2930, 0.1090, 0.1710, 0.0740, 0.1200, 0.0320, 0.0510]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1650, 0.2490, 0.1080, 0.1860, 0.0640, 0.1150, 0.0490, 0.0640]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0000, 0.3360, 0.0000, 0.1840, 0.0000, 0.3150, 0.0000, 0.1650]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1760, 0.2730, 0.1070, 0.1620, 0.0630, 0.1100, 0.0440, 0.0650]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1480, 0.2520, 0.1120, 0.2250, 0.0540, 0.0890, 0.0380, 0.0820]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2020, 0.0360, 0.2210, 0.0510, 0.1750, 0.0600, 0.1970, 0.0580]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1610, 0.2630, 0.1040, 0.2000, 0.0520, 0.1020, 0.0450, 0.0730]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1750, 0.2970, 0.1110, 0.2030, 0.0480, 0.0720, 0.0300, 0.0640]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1110, 0.2770, 0.1300, 0.2760, 0.0360, 0.0740, 0.0230, 0.0730]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1550, 0.2520, 0.1260, 0.1850, 0.0570, 0.0950, 0.0580, 0.0720]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1450, 0.3100, 0.1170, 0.2370, 0.0390, 0.0770, 0.0230, 0.0520]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.4810, 0.1250, 0.2070, 0.0640, 0.0640, 0.0280, 0.0270, 0.0040]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1530, 0.2680, 0.1190, 0.2100, 0.0540, 0.0810, 0.0490, 0.0660]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1510, 0.1190, 0.1190, 0.1250, 0.1230, 0.1230, 0.1110, 0.1290]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1730, 0.0850, 0.1660, 0.0640, 0.2050, 0.0740, 0.1630, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1350, 0.1250, 0.1120, 0.1140, 0.1410, 0.1230, 0.1390, 0.1110]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0010, 0.2540, 0.0020, 0.2460, 0.0010, 0.2420, 0.0000, 0.2540]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1320, 0.2550, 0.1250, 0.2100, 0.0520, 0.0990, 0.0540, 0.0730]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1540, 0.1210, 0.1480, 0.0960, 0.1470, 0.1140, 0.1300, 0.0900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1560, 0.2480, 0.1100, 0.2060, 0.0660, 0.0990, 0.0460, 0.0690]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1520, 0.2660, 0.1160, 0.2170, 0.0530, 0.1000, 0.0340, 0.0620]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1790, 0.2880, 0.1020, 0.1660, 0.0750, 0.0950, 0.0430, 0.0520]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1810, 0.2710, 0.1090, 0.1520, 0.0770, 0.0980, 0.0320, 0.0800]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1570, 0.2590, 0.1080, 0.2050, 0.0640, 0.0790, 0.0420, 0.0860]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1380, 0.2460, 0.1150, 0.2220, 0.0470, 0.1040, 0.0470, 0.0810]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1090, 0.1530, 0.1170, 0.1010, 0.1200, 0.1370, 0.1240, 0.1390]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1590, 0.2480, 0.1280, 0.1910, 0.0690, 0.0760, 0.0510, 0.0780]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1660, 0.2580, 0.1120, 0.2160, 0.0450, 0.0970, 0.0370, 0.0690]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1520, 0.2710, 0.1020, 0.1720, 0.0630, 0.1040, 0.0500, 0.0860]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1600, 0.2590, 0.1040, 0.2130, 0.0610, 0.1030, 0.0320, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1460, 0.2980, 0.1120, 0.2310, 0.0360, 0.0750, 0.0380, 0.0640]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.6860, 0.0850, 0.1460, 0.0240, 0.0370, 0.0100, 0.0100, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0080, 0.2440, 0.0080, 0.2470, 0.0060, 0.2400, 0.0120, 0.2350]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2500, 0.0030, 0.2680, 0.0030, 0.2490, 0.0050, 0.2200, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1450, 0.2330, 0.1130, 0.2090, 0.0700, 0.0990, 0.0520, 0.0790]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1440, 0.2500, 0.0990, 0.2290, 0.0450, 0.1090, 0.0410, 0.0830]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1350, 0.1070, 0.1580, 0.1160, 0.1550, 0.1010, 0.1290, 0.0990]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1380, 0.2500, 0.1580, 0.2010, 0.0460, 0.0940, 0.0440, 0.0690]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1210, 0.2010, 0.0710, 0.1080, 0.1390, 0.1940, 0.0850, 0.0810]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1660, 0.2130, 0.1320, 0.2010, 0.0560, 0.1100, 0.0490, 0.0730]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2120, 0.0290, 0.2190, 0.0380, 0.2250, 0.0210, 0.2240, 0.0320]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2160, 0.0490, 0.1950, 0.0510, 0.2250, 0.0280, 0.2010, 0.0350]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0360, 0.2220, 0.0320, 0.2200, 0.0300, 0.2060, 0.0400, 0.2140]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1540, 0.2850, 0.1290, 0.1960, 0.0490, 0.0920, 0.0310, 0.0640]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1670, 0.2540, 0.1140, 0.1900, 0.0550, 0.1080, 0.0440, 0.0680]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1390, 0.2140, 0.1220, 0.2170, 0.0530, 0.1040, 0.0580, 0.0930]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2660, 0.1870, 0.2460, 0.1280, 0.0520, 0.0500, 0.0400, 0.0310]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1090, 0.1560, 0.0890, 0.1680, 0.0790, 0.1370, 0.1060, 0.1560]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1220, 0.2830, 0.1090, 0.2620, 0.0440, 0.0660, 0.0410, 0.0730]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1330, 0.1390, 0.1220, 0.1400, 0.1230, 0.1430, 0.0900, 0.1100]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1560, 0.1340, 0.1650, 0.1540, 0.1050, 0.1000, 0.1000, 0.0860]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1560, 0.2310, 0.1250, 0.1760, 0.0690, 0.1190, 0.0540, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1410, 0.2700, 0.1030, 0.1980, 0.0750, 0.1030, 0.0320, 0.0780]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1120, 0.2360, 0.1210, 0.2700, 0.0310, 0.0910, 0.0390, 0.1000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.8620, 0.0000, 0.1180, 0.0010, 0.0180, 0.0000, 0.0010, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1380, 0.2330, 0.1300, 0.1680, 0.0840, 0.1170, 0.0600, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2610, 0.1040, 0.0910, 0.0380, 0.2680, 0.1070, 0.0940, 0.0370]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1230, 0.2880, 0.0230, 0.0820, 0.1080, 0.2780, 0.0270, 0.0710]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0250, 0.0470, 0.1570, 0.3030, 0.0260, 0.0430, 0.1270, 0.2720]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1870, 0.0600, 0.1800, 0.0730, 0.1750, 0.0710, 0.1920, 0.0620]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0620, 0.1990, 0.0500, 0.1900, 0.0590, 0.1980, 0.0600, 0.1820]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0910, 0.2570, 0.1260, 0.2660, 0.0320, 0.1050, 0.0380, 0.0850]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1200, 0.2510, 0.1190, 0.2000, 0.0520, 0.1070, 0.0600, 0.0910]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0300, 0.0930, 0.1260, 0.2690, 0.0330, 0.0760, 0.1110, 0.2620]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1060, 0.2450, 0.1340, 0.2790, 0.0310, 0.0950, 0.0400, 0.0700]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1330, 0.2200, 0.1130, 0.2250, 0.0600, 0.0940, 0.0500, 0.1050]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0140, 0.0640, 0.1170, 0.3170, 0.0270, 0.0560, 0.1050, 0.3000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1180, 0.2590, 0.1170, 0.2450, 0.0400, 0.0870, 0.0420, 0.0920]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0360, 0.4210, 0.0020, 0.0480, 0.0340, 0.4210, 0.0030, 0.0350]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1340, 0.2310, 0.1260, 0.1830, 0.0680, 0.1080, 0.0600, 0.0900]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1510, 0.2290, 0.1260, 0.2030, 0.0540, 0.1030, 0.0510, 0.0830]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0030, 0.0000, 0.0000, 0.0000, 0.9170, 0.0620, 0.0160, 0.0020]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0020, 0.0000, 0.0000, 0.0000, 0.9580, 0.0290, 0.0110, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.0290, 0.2850, 0.0150, 0.1770, 0.0370, 0.2460, 0.0240, 0.1870]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2790, 0.0200, 0.2330, 0.0090, 0.2260, 0.0090, 0.2110, 0.0130]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1540, 0.2450, 0.1360, 0.2470, 0.0400, 0.0740, 0.0310, 0.0730]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1600, 0.2200, 0.1210, 0.2190, 0.0580, 0.1010, 0.0400, 0.0810]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1470, 0.2200, 0.1410, 0.2040, 0.0470, 0.1000, 0.0540, 0.0870]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1150, 0.2340, 0.1080, 0.2570, 0.0500, 0.0870, 0.0520, 0.0970]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1440, 0.2130, 0.1190, 0.2070, 0.0590, 0.1250, 0.0500, 0.0830]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.2170, 0.2430, 0.0220, 0.0280, 0.1970, 0.2280, 0.0350, 0.0300]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3510, 0.1530, 0.2340, 0.1050, 0.0780, 0.0220, 0.0360, 0.0210]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.3630, 0.2440, 0.0990, 0.1050, 0.0780, 0.0660, 0.0260, 0.0190]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1480, 0.2660, 0.1130, 0.2280, 0.0330, 0.0820, 0.0430, 0.0870]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1180, 0.1900, 0.0610, 0.1280, 0.1150, 0.2230, 0.0540, 0.1110]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1380, 0.2530, 0.1290, 0.2780, 0.0280, 0.0780, 0.0420, 0.0540]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "output of QC = tensor([[0.1140, 0.2420, 0.1240, 0.2380, 0.0570, 0.0870, 0.0490, 0.0890]],\n",
      "       dtype=torch.float64, grad_fn=<TorchCircuitBackward>)"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_list = []\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()        \n",
    "        # Forward pass\n",
    "        output = network(data)\n",
    "        # Calculating loss\n",
    "        loss = loss_func(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence for {}-qubit'.format(NUM_QUBITS))\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.savefig('Figures/{}-qubit Loss Curve ryN.jpg'.format(NUM_QUBITS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of NN\n",
    "\n",
    "The outcome is not always the same because the prediction is probabilistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "number = 0\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    number +=1\n",
    "    output = network.predict(data).item()\n",
    "    accuracy += (output == target[0].item())*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance on test data is is: {}/{} = {}%\".format(accuracy,number,100*accuracy/number))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_shape = (8, 6)\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=n_samples_shape[0], ncols=n_samples_shape[1], figsize=(10, 2*n_samples_shape[0]))\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if count == n_samples_shape[0]*n_samples_shape[1]:\n",
    "            break\n",
    "        pred = network.predict(data).item()\n",
    "\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].set_xticks([])\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].set_yticks([])\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].set_title('Predicted {}'.format(pred))\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
