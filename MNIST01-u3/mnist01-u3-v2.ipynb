{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals.\n",
    "#\n",
    "# Code adapted from QizGloria team, Qiskit Camp Europe 2019, updated by \n",
    "# Team Ube Pancake, Qiskit Summer Jam 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumRegister,QuantumCircuit,ClassicalRegister,execute\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import Aer\n",
    "import qiskit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "\n",
    "NUM_SHOTS = 10000\n",
    "\n",
    "SIMULATOR = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to translate Q-Circuit parameters from pytorch back to QISKIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QiskitCircuit()\n",
    "\n",
    "Parameters have to be defined according to the circuit. In this case we have a unitary U3 with 3 parameters, which we call Theta, Phi and Lambda.\n",
    "The paramter `shots` always has to be defined. It gives the number of measurements done on the simulator or on the hardware to do the averages for the expectation values.\n",
    "\n",
    "### create_circuit()\n",
    "Define a quantum cirquit in QISKIT language\n",
    "\n",
    "### N_qubit_expectation_Z()\n",
    "This is a function that allows to take the measurements and translate them to Z-expectation values for every single qubit.\n",
    "\n",
    "### bind( parameters )\n",
    "Takes the Neural Network parameters and puts them into a format that can be fed into the QIKSIT unitaries.\n",
    "\n",
    "To generalze this code we would have to write a function that replaces the line `self.circuit.data[2][0]._params`.\n",
    "Because the `self.circuit.data` is a list of all the gates  of the circuit. And the indices direct to the correct gate, where the parameters have to go.\n",
    "\n",
    "At some point we would need a better scheme here.\n",
    "\n",
    "### run( parameters )\n",
    "This function puts the circuit with the given parameters on a quantum simulater or hardware and returns the measurements of every qubit in Z-basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:09:30.598730Z",
     "start_time": "2019-10-01T16:09:30.567861Z"
    }
   },
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self.circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        \n",
    "        self.theta = Parameter('Theta')\n",
    "        self.phi = Parameter('Phi')\n",
    "        self.lam = Parameter('Lambda')\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.circuit.h(all_qubits)\n",
    "        self.circuit.barrier()\n",
    "        self.circuit.u3(self.theta, self.phi, self.lam, all_qubits)\n",
    "        self.circuit.barrier()\n",
    "        self.circuit.measure_all()\n",
    "        # ---------------------------\n",
    "        \n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects\n",
    "    \n",
    "    def run(self, i):\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        job_sim = execute(self.circuit,\n",
    "                          self.backend,\n",
    "                          shots=self.shots,\n",
    "                          parameter_binds=[{self.theta : i[0].item(),\n",
    "                                            self.phi : i[1].item(),\n",
    "                                            self.lam : i[2].item()}])\n",
    "        \n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value for rotation [pi/4, pi/4, pi/4]: 0.5149999999999999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐ ░ ┌──────────────────────┐ ░  ░ ┌─┐\n",
       "   q_0: ┤ H ├─░─┤ U3(Theta,Phi,Lambda) ├─░──░─┤M├\n",
       "        └───┘ ░ └──────────────────────┘ ░  ░ └╥┘\n",
       "meas_0: ═══════════════════════════════════════╩═\n",
       "                                                 </pre>"
      ],
      "text/plain": [
       "        ┌───┐ ░ ┌──────────────────────┐ ░  ░ ┌─┐\n",
       "   q_0: ┤ H ├─░─┤ U3(Theta,Phi,Lambda) ├─░──░─┤M├\n",
       "        └───┘ ░ └──────────────────────┘ ░  ░ └╥┘\n",
       "meas_0: ═══════════════════════════════════════╩═\n",
       "                                                 "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit = QiskitCircuit(1, SIMULATOR, NUM_SHOTS)\n",
    "print('Expected value for rotation [pi/4, pi/4, pi/4]: {}'.format(circuit.run(torch.Tensor([np.pi/4, np.pi/4, np.pi/4]))[0]))\n",
    "circuit.circuit.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchCircuit()\n",
    "\n",
    "A pytorch layer always has two functions. One for the forward pass and one for the backward pass. The forward pass simply takes the Quantum Circuits variational parameters from the previous pytorch layer and runs the circuit on the defined hardware (defined in `QiskitCircuit.run()`) and returns the measurements from the quantum hardware.\n",
    "These measurements will be the inputs of the next pytorch layer.\n",
    "\n",
    "The backward pass returns the gradients of the quantum circuit. In this case here it is finite difference.\n",
    "\n",
    "the `forward_tensor` is saved from the forward pass. So we just have to do one evaluation of the Q-Circuit in the backpass for the finite difference.\n",
    "\n",
    "The `gradient` variable here is as well hard coded to 3 parameters. This should be updated in the future and made more general.\n",
    "\n",
    "The loop `for k in range(len(input_numbers)):` goes through all the parameters (in this case 3), and shifts them by a small $\\epsilon$. Then it runs the circuit and takes the diefferences of the ouput for the parameters $\\Theta$ and $\\Theta + \\epsilon$. This is the finite difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(1, SIMULATOR, shots=NUM_SHOTS)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i[0])\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = 0.01\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors\n",
    "#         print(i)\n",
    "        input_numbers = to_numbers(i[0])\n",
    "#         print(input_numbers)\n",
    "        gradient = [0,0,0]\n",
    "        \n",
    "        for k in range(len(input_numbers)):\n",
    "            input_eps = input_numbers\n",
    "            input_eps[k] = input_numbers[k] + eps\n",
    "            exp_value = ctx.QiskitCirc.run(torch.tensor(input_eps))[0]\n",
    "            gradient_result = (exp_value - forward_tensor[0][0].item())#/eps\n",
    "            gradient[k] = gradient_result\n",
    "            \n",
    "#         print(gradient)\n",
    "        result = torch.tensor([gradient])\n",
    "#         print(result)\n",
    "\n",
    "        return result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.005400000000000071, 0.02200000000000002, -0.005199999999999927]\n",
      "tensor([[ 0.0054,  0.0220, -0.0052]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[np.pi/4, np.pi/4, np.pi/4]], requires_grad=True)\n",
    "# x = torch.tensor([[0.0, 0.0, 0.0]], requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "y1.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Quantum Circuit separately\n",
    "\n",
    "This example is simply to test the QC with a pytorch optimizer\n",
    "\n",
    "We define a cost function and a target expectation value (here -1). The cost is the square distance from the target value.\n",
    "\n",
    "`x` is the initialization of the parameters. Here again, this was hard coded such that every angle starts at $\\pi / 4$.\n",
    "\n",
    "The rest is standard pytorch optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                 | 1/50 [00:00<00:06,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.015200000000000047, -0.01440000000000008, -0.02779999999999999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                               | 2/50 [00:00<00:05,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.006199999999999983, 0.004599999999999993, -0.00039999999999995595]\n",
      "[0.00500000000000006, 0.006800000000000084, 0.004800000000000082]\n",
      "[0.0034000000000000696, -0.006399999999999961, -0.01919999999999994]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 5/50 [00:00<00:04,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.009599999999999997, -0.006000000000000005, -0.008400000000000019]\n",
      "[0.016599999999999948, 0.006999999999999951, 0.003599999999999992]\n",
      "[0.0035999999999999366, 0.004599999999999993, -0.0024000000000000687]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▎                                                                     | 8/50 [00:00<00:04,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.013400000000000023, 0.00019999999999997797, -0.011000000000000065]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▉                                                                    | 9/50 [00:00<00:04,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03280000000000005, 0.0021999999999999797, 0.013000000000000067]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████                                                                | 11/50 [00:01<00:04,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.008799999999999975, -0.015400000000000025, -0.006599999999999995]\n",
      "[0.020000000000000018, 0.0048000000000001375, 0.005600000000000049]\n",
      "[0.020199999999999996, -0.0009999999999998899, 0.005400000000000071]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████▎                                                            | 13/50 [00:01<00:03, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0132000000000001, 0.0050000000000001155, 0.0018000000000000238]\n",
      "[-0.004200000000000204, -0.0036000000000000476, -0.007200000000000095]\n",
      "[0.014999999999999902, 0.0025999999999999357, -0.021400000000000086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▌                                                         | 15/50 [00:01<00:03, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.006599999999999939, -0.009800000000000031, -0.005400000000000071]\n",
      "[0.0018000000000000238, -0.013000000000000123, -0.016000000000000014]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▉                                                      | 17/50 [00:01<00:03, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0014000000000000679, -0.0034000000000000696, -0.018399999999999972]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▏                                                  | 19/50 [00:01<00:02, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.012199999999999989, 0.0031999999999998696, -0.0048000000000001375]\n",
      "[0.005600000000000049, 0.006399999999999961, -0.006799999999999917]\n",
      "[-0.017200000000000104, -0.02059999999999995, -0.013000000000000123]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▋                                            | 23/50 [00:02<00:02, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.006599999999999939, -0.014000000000000012, -0.019400000000000084]\n",
      "[-0.0005999999999999339, -0.010599999999999943, -0.017599999999999838]\n",
      "[-0.011600000000000055, -0.009200000000000097, -0.02180000000000004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 25/50 [00:02<00:02, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00019999999999997797, 0.008000000000000007, -0.008000000000000007]\n",
      "[-0.0012000000000000899, 0.0052000000000000934, -0.008000000000000007]\n",
      "[-0.007200000000000095, -0.007400000000000073, -0.013400000000000079]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████████▌                                  | 29/50 [00:02<00:02, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008800000000000141, 0.01200000000000001, -0.007800000000000029]\n",
      "[-0.0018000000000000238, -0.010800000000000143, -0.010399999999999965]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████▊                               | 31/50 [00:03<00:01, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0020000000000000018, -0.0025999999999999357, -0.0005999999999999339]\n",
      "[0.0040000000000000036, -0.006000000000000005, 0.00039999999999995595]\n",
      "[-0.009800000000000031, -0.001000000000000112, -0.009200000000000097]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████████                            | 33/50 [00:03<00:01, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0047999999999999154, -0.0045999999999999375, -0.006000000000000005]\n",
      "[-0.006199999999999983, -0.019399999999999862, -0.009800000000000031]\n",
      "[0.0032000000000000917, -0.0043999999999999595, -0.005400000000000071]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████████████████████████████████████▋                     | 37/50 [00:03<00:01, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.014399999999999968, 0.004999999999999893, -0.0052000000000000934]\n",
      "[-0.013600000000000056, -0.0048000000000001375, -0.010599999999999943]\n",
      "[0.0030000000000001137, -0.01419999999999999, -0.0040000000000000036]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████▉                  | 39/50 [00:03<00:01, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0043999999999999595, -0.016799999999999926, -0.006399999999999961]\n",
      "[-0.0031999999999998696, -0.0016000000000000458, -0.0033999999999998476]\n",
      "[-0.005600000000000049, 0.00019999999999997797, 0.007600000000000051]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████████████████▌           | 43/50 [00:04<00:00, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.001000000000000112, 0.00039999999999995595, -0.007200000000000095]\n",
      "[-0.008799999999999919, -0.007600000000000051, -0.01419999999999999]\n",
      "[0.0038000000000000256, 0.009400000000000075, -0.0033999999999998476]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████     | 47/50 [00:04<00:00, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0029999999999998916, 0.006199999999999983, 0.011199999999999877]\n",
      "[-0.00019999999999997797, -0.010599999999999943, -0.010199999999999987]\n",
      "[-0.006399999999999961, -0.0047999999999999154, -0.006199999999999983]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████▎ | 49/50 [00:04<00:00, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01100000000000012, 0.0020000000000000018, 0.010800000000000143]\n",
      "[-0.019600000000000062, -0.01980000000000004, -0.010399999999999965]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0050000000000001155, -0.0021999999999999797, -0.009600000000000053]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2adbe1015f8>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)\n",
    "    return torch.abs(qc(x) - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([[-np.pi/2, -np.pi/2, -np.pi/2]], requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 50\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval.item())\n",
    "#     print(loss.item())\n",
    "\n",
    "plt.plot(loss_list)\n",
    "    \n",
    "# print(circuit(phi, theta))\n",
    "# print(cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST\n",
    "\n",
    "In this code we can not handle batches yet.\n",
    "This should be implemented as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 100\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size_train = 1\n",
    "batch_size_test = 1\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "n_datapoints = 100\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "labels = mnist_trainset.targets #get labels\n",
    "labels = labels.numpy()\n",
    "idx1 = np.where(labels == 0) #search all zeros\n",
    "idx2 = np.where(labels == 1) # search all ones\n",
    "idx = np.concatenate((idx1[0][0:n_datapoints//2],idx2[0][0:n_datapoints//2])) # concatenate their indices\n",
    "mnist_trainset.targets = labels[idx] \n",
    "mnist_trainset.data = mnist_trainset.data[idx]\n",
    "\n",
    "print(mnist_trainset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network with Q-node\n",
    "\n",
    "This NN is  2 layers of ConvNN and a fully connected layer, with a Q-Node as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "#         return F.softmax(x)\n",
    "        x = np.pi*torch.tanh(x)\n",
    "        x = qc(x) # This is the q node\n",
    "#         print(x)\n",
    "        x = (x+1)/2 # Translate expectation values [-1,1] to labels [0,1]\n",
    "        print(x)\n",
    "        x = torch.cat((x, 1-x), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "# optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "standard pytorch training loop.\n",
    "- Load data from train_loader. Which is this case a single example each step.\n",
    "- Forward pass through NN\n",
    "- Caluculate loss\n",
    "- Backprop and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3785]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02560000000000001, 0.02400000000000002, 0.034600000000000075]\n",
      "tensor([[0.4513]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0033999999999999586, -0.021200000000000052, -0.0048000000000000265]\n",
      "tensor([[0.3780]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02360000000000001, 0.005800000000000027, 0.01919999999999994]\n",
      "tensor([[0.4660]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03340000000000004, 0.03480000000000005, 0.028800000000000048]\n",
      "tensor([[0.3630]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0012000000000000344, -0.014399999999999968, 0.009000000000000064]\n",
      "tensor([[0.4151]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009599999999999997, 0.017399999999999916, 0.02299999999999991]\n",
      "tensor([[0.4112]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01920000000000005, -0.004400000000000015, -0.0041999999999999815]\n",
      "tensor([[0.3447]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017400000000000027, 0.008000000000000007, 0.012799999999999978]\n",
      "tensor([[0.3834]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007800000000000029, -0.008000000000000007, -0.007399999999999962]\n",
      "tensor([[0.4418]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009599999999999997, 0.02059999999999995, 0.014600000000000057]\n",
      "tensor([[0.4464]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0005999999999999894, -0.006800000000000084, 0.012599999999999945]\n",
      "tensor([[0.3677]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.027599999999999902, 0.02839999999999998]\n",
      "tensor([[0.2920]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01200000000000001, -0.00019999999999997797, 0.004400000000000015]\n",
      "tensor([[0.4474]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023799999999999988, 0.040200000000000014, 0.02579999999999999]\n",
      "tensor([[0.3367]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010000000000000009, 0.02980000000000005, 0.029400000000000037]\n",
      "tensor([[0.4240]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.04519999999999996, 0.015399999999999914, 0.029199999999999948]\n",
      "tensor([[0.3798]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02839999999999998, 0.020999999999999908, 0.01579999999999998]\n",
      "tensor([[0.4530]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03620000000000001, 0.019799999999999984, 0.024399999999999977]\n",
      "tensor([[0.4819]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, 0.0010000000000000564, 0.02479999999999999]\n",
      "tensor([[0.5051]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018399999999999972, 0.03059999999999996, 0.015200000000000047]\n",
      "tensor([[0.4656]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012399999999999967, 0.010399999999999965, 0.024799999999999933]\n",
      "tensor([[0.5695]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0038000000000000256, 0.0038000000000000256, 0.0015999999999999903]\n",
      "tensor([[0.4723]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014999999999999958, -0.003400000000000014, -0.007000000000000062]\n",
      "tensor([[0.2897]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00040000000000006697, 0.011400000000000021, 0.012600000000000056]\n",
      "tensor([[0.4440]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015800000000000036, 0.013600000000000001, 0.008000000000000007]\n",
      "tensor([[0.4698]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005600000000000049, 0.01419999999999999, 0.015400000000000025]\n",
      "tensor([[0.4814]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0040000000000000036, -0.0044000000000000705, -0.021000000000000074]\n",
      "tensor([[0.3453]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0008000000000000784, 0.003199999999999925, -0.010800000000000087]\n",
      "tensor([[0.4434]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0011999999999999234, 0.006399999999999961, 0.0398]\n",
      "tensor([[0.5350]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016600000000000004, -0.009999999999999953, 0.0024000000000000132]\n",
      "tensor([[0.3804]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013199999999999934, -0.011399999999999966, -0.006999999999999951]\n",
      "tensor([[0.4313]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00940000000000002, -0.005600000000000049, 0.007199999999999929]\n",
      "tensor([[0.3955]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023799999999999988, 0.022600000000000064, -0.004599999999999993]\n",
      "tensor([[0.4191]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.033399999999999985, 0.04139999999999999, 0.025599999999999956]\n",
      "tensor([[0.4028]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020799999999999985, 0.021599999999999953, 0.010999999999999954]\n",
      "tensor([[0.4871]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0008000000000000784, 0.00020000000000003348, 0.00280000000000008]\n",
      "tensor([[0.5131]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.026000000000000023, 0.023400000000000032, 0.03919999999999996]\n",
      "tensor([[0.4713]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006800000000000084, -0.0044000000000000705, -0.005599999999999994]\n",
      "tensor([[0.3772]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020600000000000007, 0.02460000000000001, 0.02200000000000002]\n",
      "tensor([[0.3683]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000023, -0.002799999999999969, -0.020000000000000018]\n",
      "tensor([[0.3092]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013399999999999967, 0.023599999999999954, 0.029199999999999948]\n",
      "tensor([[0.3958]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004799999999999971, 0.00979999999999992, 0.013599999999999945]\n",
      "tensor([[0.3373]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008599999999999997, 0.011399999999999966, 0.008599999999999997]\n",
      "tensor([[0.4518]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01040000000000002, -0.008199999999999985, 0.0040000000000000036]\n",
      "tensor([[0.4008]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0116, -0.011400000000000021, -0.014000000000000012]\n",
      "tensor([[0.4295]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007400000000000018, 0.020999999999999963, 0.027200000000000057]\n",
      "tensor([[0.4017]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.027200000000000057, 0.0016000000000000458, 0.009599999999999997]\n",
      "tensor([[0.4700]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000079, -0.007599999999999996, 0.009600000000000053]\n",
      "tensor([[0.4816]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01679999999999998, 0.027800000000000047, 0.012200000000000044]\n",
      "tensor([[0.3487]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00019999999999997797, 0.006199999999999983, -0.009000000000000064]\n",
      "tensor([[0.4960]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01639999999999997, -0.010000000000000009, -0.026000000000000023]\n",
      "tensor([[0.3626]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007399999999999962, -0.008000000000000007, 0.010200000000000042]\n",
      "tensor([[0.4367]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0034000000000000696, 0.016600000000000004, 0.02920000000000006]\n",
      "tensor([[0.4572]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008999999999999952, 0.010999999999999954, 0.016199999999999992]\n",
      "tensor([[0.4626]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.012199999999999989, 0.003599999999999992, -0.0036000000000000476]\n",
      "tensor([[0.4467]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.033600000000000074, 0.03839999999999999, 0.05020000000000002]\n",
      "tensor([[0.4118]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02479999999999999, 0.0043999999999999595, 0.041599999999999915]\n",
      "tensor([[0.3390]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007799999999999974, 0.003400000000000014, 0.003599999999999992]\n",
      "tensor([[0.4179]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.016800000000000093, 0.011199999999999932, -0.0038000000000000256]\n",
      "tensor([[0.4510]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0041999999999999815, 0.0024000000000000687, 0.003599999999999992]\n",
      "tensor([[0.3889]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0235999999999999, 0.02839999999999998, 0.025199999999999945]\n",
      "tensor([[0.4258]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018000000000000016, 0.01579999999999998, 0.03660000000000008]\n",
      "tensor([[0.4857]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02079999999999993, 0.011799999999999977, 0.030999999999999917]\n",
      "tensor([[0.4027]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0008000000000000784, 0.009000000000000064, 0.00720000000000004]\n",
      "tensor([[0.4515]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023799999999999988, 0.05059999999999998, 0.038799999999999946]\n",
      "tensor([[0.3741]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03140000000000004, 0.025800000000000045, 0.027200000000000057]\n",
      "tensor([[0.4064]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013000000000000067, 0.025800000000000045, 0.0126]\n",
      "tensor([[0.4259]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, 0.02900000000000008, 0.01940000000000003]\n",
      "tensor([[0.4597]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.043800000000000006, 0.038000000000000034, 0.025800000000000045]\n",
      "tensor([[0.4935]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02339999999999992, 0.016600000000000004, -0.0010000000000000564]\n",
      "tensor([[0.3755]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009399999999999908, 0.0026000000000001022, 0.000200000000000089]\n",
      "tensor([[0.4421]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005599999999999994, -0.01200000000000001, 0.002599999999999991]\n",
      "tensor([[0.3802]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008199999999999985, 0.0018000000000000238, 0.009200000000000041]\n",
      "tensor([[0.4210]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011799999999999922, 0.01479999999999998, 0.0024000000000000132]\n",
      "tensor([[0.3118]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016800000000000037, 0.021600000000000008, 0.010199999999999987]\n",
      "tensor([[0.3526]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03839999999999999, 0.0242, 0.0255999999999999]\n",
      "tensor([[0.4368]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007400000000000018, -0.002999999999999947, 0.00040000000000006697]\n",
      "tensor([[0.5320]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01479999999999998, 0.013800000000000034, 0.0]\n",
      "tensor([[0.5267]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0023999999999999577, 0.003200000000000036, -0.007199999999999929]\n",
      "tensor([[0.4296]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016400000000000026, -0.005599999999999994, 0.02040000000000003]\n",
      "tensor([[0.4585]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01899999999999996, -0.01540000000000008, 0.005599999999999994]\n",
      "tensor([[0.4234]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.027400000000000035, 0.015400000000000025, 0.02059999999999995]\n",
      "tensor([[0.4763]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004600000000000104, 0.014000000000000012, 0.005200000000000038]\n",
      "tensor([[0.3690]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015200000000000047, 0.029400000000000037, 0.019600000000000062]\n",
      "tensor([[0.5272]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0041999999999999815, 0.010599999999999943, 0.0012000000000000344]\n",
      "tensor([[0.4191]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016000000000000014, 0.015599999999999947, -0.0028000000000000247]\n",
      "tensor([[0.4374]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0036000000000000476, -0.00040000000000001146, -0.0034000000000000696]\n",
      "tensor([[0.3307]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.030399999999999983, 0.03340000000000004, 0.03360000000000002]\n",
      "tensor([[0.4228]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022600000000000064, 0.017799999999999983, 0.017400000000000027]\n",
      "tensor([[0.4804]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.000200000000000089, 0.02479999999999999, 0.03539999999999993]\n",
      "tensor([[0.3760]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017600000000000005, -0.014999999999999958, 0.0012000000000000344]\n",
      "tensor([[0.3597]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02779999999999999, 0.016799999999999926, 0.03319999999999995]\n",
      "tensor([[0.4075]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020600000000000007, 0.0, 0.019200000000000106]\n",
      "tensor([[0.3828]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007199999999999984, -0.006800000000000028, 0.009399999999999964]\n",
      "tensor([[0.4885]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.030799999999999994, 0.008400000000000019, 0.015399999999999914]\n",
      "tensor([[0.3878]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0242, 0.030000000000000027, 0.03159999999999996]\n",
      "tensor([[0.3659]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021600000000000008, 0.015200000000000047, 0.018399999999999972]\n",
      "tensor([[0.4788]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022399999999999975, 0.013600000000000001, 0.014000000000000012]\n",
      "tensor([[0.3171]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015799999999999925, 0.03379999999999994, 0.030799999999999994]\n",
      "tensor([[0.4941]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018600000000000005, 0.03960000000000008, 0.012400000000000022]\n",
      "Training [5%]\tLoss: -0.4964\n",
      "tensor([[0.4530]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013599999999999945, -0.006999999999999951, 0.003599999999999992]\n",
      "tensor([[0.3493]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006799999999999973, 0.00759999999999994, 0.002999999999999947]\n",
      "tensor([[0.4048]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03579999999999994, 0.03859999999999997, 0.03699999999999998]\n",
      "tensor([[0.4886]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0040000000000000036, -0.007400000000000018, 0.005800000000000027]\n",
      "tensor([[0.3948]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007199999999999929, 0.00919999999999993, 0.01979999999999993]\n",
      "tensor([[0.3966]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000023, 0.0026000000000000467, 0.011400000000000021]\n",
      "tensor([[0.4863]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018199999999999994, 0.030000000000000027, 0.004800000000000082]\n",
      "tensor([[0.3031]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.002999999999999947, 0.008999999999999952, -0.00379999999999997]\n",
      "tensor([[0.4067]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008200000000000096, -0.011599999999999944, -0.005199999999999927]\n",
      "tensor([[0.3901]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006799999999999973, 0.023400000000000032, 0.02859999999999996]\n",
      "tensor([[0.2837]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.012400000000000078, 0.0038000000000000256]\n",
      "tensor([[0.4279]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03140000000000004, 0.020400000000000085, 0.006400000000000072]\n",
      "tensor([[0.4093]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008799999999999975, 0.01479999999999998, 0.024399999999999977]\n",
      "tensor([[0.4748]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.027600000000000013, 0.01639999999999997, 0.027199999999999946]\n",
      "tensor([[0.4792]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003199999999999925, -0.012799999999999978, -0.011199999999999932]\n",
      "tensor([[0.4659]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.032399999999999984, 0.014400000000000024, 0.0040000000000000036]\n",
      "tensor([[0.3447]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015600000000000003, -0.0041999999999999815, 0.01200000000000001]\n",
      "tensor([[0.4496]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0016000000000000458, 0.0036000000000000476, 0.021200000000000052]\n",
      "tensor([[0.4490]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01959999999999995, -0.0015999999999999348, 0.00040000000000006697]\n",
      "tensor([[0.4502]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0020000000000000018, -0.011000000000000065, 0.015199999999999936]\n",
      "tensor([[0.4575]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02360000000000001, 0.015199999999999936, 0.01139999999999991]\n",
      "tensor([[0.3712]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014400000000000024, 0.02200000000000002, 0.025800000000000045]\n",
      "tensor([[0.4748]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01679999999999998, -0.012199999999999989, -0.0016000000000000458]\n",
      "tensor([[0.3580]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02200000000000002, 0.023000000000000076, 0.047200000000000075]\n",
      "tensor([[0.4465]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017199999999999938, 0.007400000000000018, 0.010399999999999965]\n",
      "tensor([[0.3504]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003200000000000036, -0.007599999999999996, -0.01579999999999998]\n",
      "tensor([[0.3934]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.034399999999999986, 0.019600000000000006, 0.00940000000000002]\n",
      "tensor([[0.4798]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020799999999999985, 0.009200000000000041, 0.008199999999999985]\n",
      "tensor([[0.4423]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0235999999999999, 0.015599999999999892, 0.017799999999999983]\n",
      "tensor([[0.2251]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0027999999999999137, -0.0013999999999998458, 0.011800000000000033]\n",
      "tensor([[0.5154]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0018000000000000238, 0.0006000000000000449, 0.013600000000000001]\n",
      "tensor([[0.3226]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006599999999999995, 0.00019999999999997797, 0.003200000000000036]\n",
      "tensor([[0.4826]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019399999999999973, 0.0013999999999999568, -0.0023999999999999577]\n",
      "tensor([[0.4394]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012999999999999956, 0.007400000000000018, 0.007400000000000018]\n",
      "tensor([[0.4062]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.011200000000000043, -0.002599999999999991, -0.020999999999999963]\n",
      "tensor([[0.3194]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012999999999999956, 0.010599999999999943, 0.01919999999999994]\n",
      "tensor([[0.4836]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02460000000000001, 0.005600000000000049, -0.0048000000000000265]\n",
      "tensor([[0.4653]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005599999999999994, 0.00040000000000001146, 0.010199999999999987]\n",
      "tensor([[0.3928]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007799999999999974, 0.0013999999999999568, -0.006000000000000005]\n",
      "tensor([[0.4779]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008599999999999997, 0.013800000000000034, 0.004400000000000015]\n",
      "tensor([[0.5168]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0022000000000000353, 0.01040000000000002, 0.00919999999999993]\n",
      "tensor([[0.4832]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02920000000000006, -0.0015999999999999348, 0.007599999999999996]\n",
      "tensor([[0.4926]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008600000000000052, 0.02260000000000001, 0.020799999999999985]\n",
      "tensor([[0.3134]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.023000000000000076, -0.00500000000000006, -0.027200000000000057]\n",
      "tensor([[0.4602]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0042000000000000925, -0.003400000000000014, 0.01699999999999996]\n",
      "tensor([[0.2855]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000079, -0.006399999999999961, 0.0010000000000000564]\n",
      "tensor([[0.2851]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.031799999999999995, 0.029600000000000015, 0.024599999999999955]\n",
      "tensor([[0.4101]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012399999999999967, 0.012599999999999945, 0.01639999999999997]\n",
      "tensor([[0.5232]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011200000000000043, 0.012799999999999978, 0.01980000000000004]\n",
      "tensor([[0.5045]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016800000000000093, 0.03280000000000005, 0.029400000000000037]\n",
      "tensor([[0.5535]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010399999999999965, 0.0, 0.008000000000000007]\n",
      "tensor([[0.4973]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025400000000000034, 0.015000000000000069, 0.035200000000000065]\n",
      "tensor([[0.4522]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0038000000000000256, 0.004599999999999993, 0.029799999999999938]\n",
      "tensor([[0.4826]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006800000000000028, 0.0024000000000000132, 0.008799999999999975]\n",
      "tensor([[0.4849]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0126, 0.004799999999999971, 0.018199999999999994]\n",
      "tensor([[0.4943]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01700000000000007, -0.0007999999999999674, 0.009200000000000041]\n",
      "tensor([[0.5016]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008199999999999985, 0.008199999999999985, 0.010999999999999954]\n",
      "tensor([[0.4116]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02579999999999999, 0.01660000000000006, 0.03480000000000005]\n",
      "tensor([[0.4988]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00039999999999995595, 0.02119999999999994, -0.006400000000000017]\n",
      "tensor([[0.4181]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03479999999999994, 0.033199999999999896, 0.022599999999999953]\n",
      "tensor([[0.3594]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006200000000000094, -0.013400000000000023, 0.0015999999999999348]\n",
      "tensor([[0.5129]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00019999999999997797, -0.006400000000000017, 0.010000000000000009]\n",
      "tensor([[0.3991]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, -0.005600000000000049, 0.011400000000000021]\n",
      "tensor([[0.2945]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013799999999999979, -0.013600000000000001, -0.014799999999999924]\n",
      "tensor([[0.4705]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022799999999999987, 0.023399999999999976, 0.01739999999999997]\n",
      "tensor([[0.3938]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0262, 0.023599999999999954, 0.011599999999999944]\n",
      "tensor([[0.5192]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011200000000000043, -0.0043999999999999595, -0.005400000000000016]\n",
      "tensor([[0.3863]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014400000000000024, -0.0020000000000000018, 0.025000000000000078]\n",
      "tensor([[0.4445]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0018000000000000238, 0.00940000000000002, 0.007599999999999996]\n",
      "tensor([[0.4544]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00379999999999997, 0.019799999999999984, 0.010199999999999987]\n",
      "tensor([[0.4862]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012800000000000034, 0.01579999999999998, -0.002999999999999947]\n",
      "tensor([[0.4151]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025199999999999945, 0.028799999999999937, 0.041599999999999915]\n",
      "tensor([[0.4887]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008199999999999985, 0.002999999999999947, -0.0020000000000000018]\n",
      "tensor([[0.4255]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0038000000000000256, 0.012199999999999989, 0.022199999999999998]\n",
      "tensor([[0.4351]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004400000000000015, 0.006999999999999951, 0.02179999999999993]\n",
      "tensor([[0.4917]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020199999999999996, 0.033199999999999896, 0.029799999999999993]\n",
      "tensor([[0.4484]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03139999999999993, 0.02339999999999992, 0.027399999999999924]\n",
      "tensor([[0.3976]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01480000000000009, 0.038000000000000034, 0.04360000000000003]\n",
      "tensor([[0.4502]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0116, 0.004599999999999993, -0.009200000000000041]\n",
      "tensor([[0.3674]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022800000000000098, -0.0041999999999999815, 0.00720000000000004]\n",
      "tensor([[0.4751]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017799999999999983, 0.025999999999999968, 0.021999999999999964]\n",
      "tensor([[0.4128]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02200000000000002, 0.0014000000000000123, 0.03160000000000002]\n",
      "tensor([[0.4383]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01139999999999991, 0.017199999999999938, 0.013600000000000001]\n",
      "tensor([[0.5280]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016799999999999926, 0.0025999999999999357, -0.00040000000000001146]\n",
      "tensor([[0.4220]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0041999999999999815, 0.0007999999999999674, 0.0126]\n",
      "tensor([[0.4992]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024400000000000033, 0.02980000000000005, 0.029400000000000093]\n",
      "tensor([[0.4526]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0116, 0.012199999999999989, -0.0036000000000000476]\n",
      "tensor([[0.4224]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01200000000000001, 0.0126, 0.0005999999999999894]\n",
      "tensor([[0.5383]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004599999999999993, -0.007800000000000029, -0.0040000000000000036]\n",
      "tensor([[0.4464]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02999999999999997, 0.027600000000000013, 0.023799999999999988]\n",
      "tensor([[0.3833]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011000000000000065, 0.016600000000000004, 0.011200000000000099]\n",
      "tensor([[0.3042]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019399999999999917, 0.022599999999999953, 0.03219999999999995]\n",
      "tensor([[0.4372]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010000000000000009, -0.0023999999999999577, 0.005199999999999982]\n",
      "tensor([[0.4359]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013000000000000067, -0.009399999999999908, -0.0037999999999999146]\n",
      "tensor([[0.4977]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03379999999999994, 0.012400000000000022, 0.01679999999999998]\n",
      "tensor([[0.4356]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013800000000000034, 0.007800000000000029, 0.033600000000000074]\n",
      "tensor([[0.3877]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02119999999999994, 0.020000000000000018, 0.01959999999999995]\n",
      "tensor([[0.4693]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022399999999999975, 0.02119999999999994, 0.0009999999999999454]\n",
      "tensor([[0.4142]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006599999999999939, 0.009599999999999997, 0.0018000000000000238]\n",
      "tensor([[0.4778]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013800000000000034, -0.0040000000000000036, -0.00720000000000004]\n",
      "Training [10%]\tLoss: -0.4977\n",
      "tensor([[0.4175]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0022000000000000353, 0.037400000000000044, -0.0041999999999999815]\n",
      "tensor([[0.4488]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0036000000000000476, 0.007800000000000029, -0.008799999999999919]\n",
      "tensor([[0.3803]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024599999999999955, 0.00880000000000003, 0.022199999999999998]\n",
      "tensor([[0.3534]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010000000000000009, 0.0035999999999999366, 0.02260000000000001]\n",
      "tensor([[0.3636]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008400000000000019, 0.023199999999999943, 0.02899999999999997]\n",
      "tensor([[0.4154]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0023999999999999577, 0.008199999999999985, 0.008399999999999963]\n",
      "tensor([[0.5022]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.002599999999999991, 0.016400000000000026, 0.0034000000000000696]\n",
      "tensor([[0.5134]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010600000000000054, -0.0009999999999999454, -0.0005999999999999894]\n",
      "tensor([[0.4360]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.004799999999999971, 0.013199999999999934]\n",
      "tensor([[0.4294]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010799999999999976, 0.008799999999999975, 0.007800000000000029]\n",
      "tensor([[0.4345]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005800000000000027, 0.016199999999999992, 0.03639999999999999]\n",
      "tensor([[0.4095]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00379999999999997, 0.015800000000000036, -0.00379999999999997]\n",
      "tensor([[0.3867]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03379999999999994, 0.023199999999999943, 0.020999999999999963]\n",
      "tensor([[0.4311]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020199999999999996, 0.007199999999999929, 0.0009999999999999454]\n",
      "tensor([[0.3226]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000023, 0.004999999999999949, -0.004799999999999971]\n",
      "tensor([[0.5284]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006599999999999995, 0.018199999999999994, 0.010800000000000087]\n",
      "tensor([[0.4286]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.015200000000000047, 0.01040000000000002]\n",
      "tensor([[0.4806]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0021999999999999797, -0.0016000000000000458, 0.026799999999999935]\n",
      "tensor([[0.4520]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.018399999999999972, 0.00720000000000004, 0.009599999999999997]\n",
      "tensor([[0.4762]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02700000000000008, 0.02839999999999998, 0.018000000000000016]\n",
      "tensor([[0.4740]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.04239999999999999, 0.023400000000000087, 0.04420000000000002]\n",
      "tensor([[0.4217]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01419999999999999, -0.0033999999999999586, 0.013600000000000001]\n",
      "tensor([[0.3988]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0126, 0.010000000000000009, -0.01419999999999999]\n",
      "tensor([[0.3959]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008199999999999985, 0.002799999999999969, 0.012400000000000022]\n",
      "tensor([[0.4649]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006800000000000084, -0.010399999999999965, 0.009600000000000053]\n",
      "tensor([[0.4180]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0024000000000000687, 0.004400000000000015, -0.008000000000000007]\n",
      "tensor([[0.4081]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009399999999999908, 0.0014000000000000123, -0.010199999999999987]\n",
      "tensor([[0.3690]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006799999999999973, 0.012399999999999967, 0.0010000000000000564]\n",
      "tensor([[0.4701]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0358, 0.025000000000000022, 0.010600000000000054]\n",
      "tensor([[0.4175]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0027999999999999137, 0.010199999999999987, 0.006400000000000017]\n",
      "tensor([[0.3342]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.03919999999999996, 0.029599999999999904]\n",
      "tensor([[0.4558]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008400000000000019, 0.020600000000000007, -0.008799999999999919]\n",
      "tensor([[0.4061]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01200000000000001, -0.02479999999999999, -0.015600000000000058]\n",
      "tensor([[0.4039]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.011799999999999977, -0.01720000000000005, -0.009599999999999997]\n",
      "tensor([[0.4612]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0126, 0.014399999999999968, 0.022399999999999975]\n",
      "tensor([[0.5059]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025399999999999923, 0.029399999999999926, 0.038799999999999946]\n",
      "tensor([[0.4496]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008199999999999985, 0.0018000000000000238, 0.02479999999999999]\n",
      "tensor([[0.4885]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.035199999999999954, 0.012999999999999956, 0.03620000000000001]\n",
      "tensor([[0.4969]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01419999999999999, 0.015800000000000036, 0.011800000000000033]\n",
      "tensor([[0.4921]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006000000000000005, -0.005199999999999927, -0.004999999999999949]\n",
      "tensor([[0.3893]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011400000000000077, -0.01079999999999992, 0.0016000000000000458]\n",
      "tensor([[0.5482]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.021400000000000086, -0.017400000000000082, -0.014400000000000024]\n",
      "tensor([[0.3799]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0014000000000000679, -0.0034000000000000696, 0.010599999999999943]\n",
      "tensor([[0.5154]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02560000000000001, 0.013799999999999979, 0.003599999999999992]\n",
      "tensor([[0.4700]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019200000000000106, -0.005199999999999927, 0.021000000000000074]\n",
      "tensor([[0.4198]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022199999999999998, 0.03060000000000007, 0.023200000000000054]\n",
      "tensor([[0.4868]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022199999999999998, 0.03059999999999996, 0.01699999999999996]\n",
      "tensor([[0.3736]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017199999999999938, 0.009399999999999964, 0.022399999999999975]\n",
      "tensor([[0.4467]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.027200000000000057, 0.03380000000000005, 0.008000000000000007]\n",
      "tensor([[0.3622]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019600000000000006, 0.017400000000000027, 0.020399999999999974]\n",
      "tensor([[0.4517]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015600000000000058, 0.018000000000000016, -0.006399999999999961]\n",
      "tensor([[0.4423]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01799999999999996, -0.007000000000000062, -0.0008000000000000784]\n",
      "tensor([[0.4827]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0011999999999999234, 0.003199999999999925, 0.020000000000000018]\n",
      "tensor([[0.4659]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0262, 0.03260000000000002, 0.007800000000000029]\n",
      "tensor([[0.4414]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009599999999999997, 0.0242, 0.018399999999999972]\n",
      "tensor([[0.4242]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005400000000000071, -0.014000000000000012, -0.002599999999999991]\n",
      "tensor([[0.4961]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00500000000000006, 0.00500000000000006, 0.013800000000000034]\n",
      "tensor([[0.4322]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.035599999999999965, 0.011199999999999988, 0.019199999999999995]\n",
      "tensor([[0.3955]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017600000000000005, 0.011799999999999977, 0.018199999999999994]\n",
      "tensor([[0.4396]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0018000000000000238, -0.0116, 0.01479999999999998]\n",
      "tensor([[0.4152]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.034399999999999986, 0.026000000000000023, 0.054200000000000026]\n",
      "tensor([[0.4504]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020999999999999908, 0.0129999999999999, -0.0036000000000000476]\n",
      "tensor([[0.4271]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008999999999999952, 0.006999999999999951, 0.0022000000000000353]\n",
      "tensor([[0.4889]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009800000000000031, -0.004999999999999949, 0.013800000000000034]\n",
      "tensor([[0.5017]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00759999999999994, 0.0040000000000000036, 0.03319999999999995]\n",
      "tensor([[0.4567]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03200000000000003, 0.032200000000000006, 0.035200000000000065]\n",
      "tensor([[0.3980]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013799999999999979, 0.006599999999999939, 0.029599999999999904]\n",
      "tensor([[0.3762]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0025999999999999357, 0.009000000000000064, 0.013200000000000045]\n",
      "tensor([[0.4321]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.03179999999999994, 0.023799999999999932]\n",
      "tensor([[0.4786]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00500000000000006, 0.016199999999999992, 0.0023999999999999577]\n",
      "tensor([[0.3512]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.0024000000000000687, 0.005599999999999994]\n",
      "tensor([[0.4555]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.036599999999999966, 0.034399999999999986, 0.018399999999999972]\n",
      "tensor([[0.3981]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0262, 0.026599999999999957, 0.03259999999999996]\n",
      "tensor([[0.2540]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024999999999999967, 0.003400000000000014, 0.013800000000000034]\n",
      "tensor([[0.4864]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0040000000000000036, 0.0126, 0.007399999999999907]\n",
      "tensor([[0.5424]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02140000000000003, 0.01200000000000001, 0.008199999999999985]\n",
      "tensor([[0.5041]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.016199999999999992, -0.023199999999999943, -0.010399999999999965]\n",
      "tensor([[0.4656]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015400000000000025, 0.043999999999999984, 0.013799999999999979]\n",
      "tensor([[0.3949]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01899999999999996, 0.010000000000000009, 0.025399999999999978]\n",
      "tensor([[0.3708]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008800000000000086, 0.017199999999999938, -0.005600000000000049]\n",
      "tensor([[0.5100]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005200000000000038, 0.01479999999999998, 0.010999999999999954]\n",
      "tensor([[0.5484]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023200000000000054, 0.022199999999999998, 0.0010000000000000564]\n",
      "tensor([[0.4163]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.020199999999999996, -0.0023999999999999577, -0.008799999999999975]\n",
      "tensor([[0.4427]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021000000000000074, 0.016000000000000014, 0.019000000000000072]\n",
      "tensor([[0.4774]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013000000000000067, 0.0037999999999999146, 0.018799999999999983]\n",
      "tensor([[0.4852]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010000000000000009, -0.0015999999999999348, -0.005800000000000027]\n",
      "tensor([[0.4745]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.030600000000000016, 0.01319999999999999, 0.02699999999999997]\n",
      "tensor([[0.3425]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.026599999999999957, 0.026799999999999935, 0.009599999999999997]\n",
      "tensor([[0.5562]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014799999999999924, 0.02059999999999995, 0.014599999999999946]\n",
      "tensor([[0.4098]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020799999999999985, 0.01139999999999991, 0.00979999999999992]\n",
      "tensor([[0.4058]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003000000000000058, 0.0037999999999999146, 0.002799999999999969]\n",
      "tensor([[0.4404]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0021999999999999797, 0.007400000000000018, -0.006799999999999973]\n",
      "tensor([[0.5263]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008799999999999975, 0.0038000000000000256, 0.0018000000000000238]\n",
      "tensor([[0.4558]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007000000000000062, 0.006800000000000084, 0.0038000000000000256]\n",
      "tensor([[0.4891]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01040000000000002, 0.004599999999999993, 0.012800000000000089]\n",
      "tensor([[0.4503]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008400000000000019, 0.0013999999999999568, 0.015800000000000036]\n",
      "tensor([[0.3522]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02639999999999998, 0.028800000000000048, 0.027400000000000035]\n",
      "tensor([[0.3928]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03339999999999993, 0.0408, 0.02699999999999997]\n",
      "tensor([[0.3482]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023000000000000076, 0.012800000000000089, 0.003200000000000036]\n",
      "tensor([[0.4279]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006199999999999983, 0.0044000000000000705, 0.011200000000000043]\n",
      "Training [15%]\tLoss: -0.5074\n",
      "tensor([[0.4452]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018600000000000005, 0.021399999999999975, 0.015599999999999947]\n",
      "tensor([[0.4510]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0007999999999999674, 0.02579999999999999, 0.021000000000000074]\n",
      "tensor([[0.4220]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004599999999999993, 0.01979999999999993, -0.014800000000000035]\n",
      "tensor([[0.4048]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003200000000000036, 0.013599999999999945, 0.0020000000000000018]\n",
      "tensor([[0.4105]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.033400000000000096, 0.010800000000000087, 0.033000000000000085]\n",
      "tensor([[0.3934]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0028000000000000247, 0.016800000000000037, 0.013000000000000012]\n",
      "tensor([[0.4156]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00660000000000005, -0.005199999999999982, -0.007199999999999984]\n",
      "tensor([[0.3655]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014399999999999968, 0.00019999999999997797, 0.017799999999999927]\n",
      "tensor([[0.5073]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0034000000000000696, 0.031400000000000095, 0.03640000000000004]\n",
      "tensor([[0.5241]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.04360000000000003, 0.04459999999999997, 0.03079999999999994]\n",
      "tensor([[0.4249]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010799999999999976, -0.010800000000000087, 0.012999999999999956]\n",
      "tensor([[0.4678]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005600000000000049, 0.01699999999999996, 0.019600000000000062]\n",
      "tensor([[0.5863]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00019999999999997797, -0.013000000000000067, 0.004400000000000015]\n",
      "tensor([[0.3629]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005800000000000027, -0.005800000000000027, 0.018799999999999983]\n",
      "tensor([[0.3433]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004599999999999993, 0.011199999999999932, 0.011599999999999944]\n",
      "tensor([[0.4027]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.027600000000000013, 0.0042000000000000925, 0.00280000000000008]\n",
      "tensor([[0.4252]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00040000000000001146, 0.006599999999999939, -0.006200000000000039]\n",
      "tensor([[0.4853]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03260000000000007, 0.016000000000000014, 0.02779999999999999]\n",
      "tensor([[0.4323]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022599999999999953, 0.007199999999999929, -0.0020000000000000018]\n",
      "tensor([[0.5067]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0013999999999999568, 0.011199999999999932, 0.010000000000000009]\n",
      "tensor([[0.4665]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00919999999999993, 0.024599999999999955, 0.005799999999999972]\n",
      "tensor([[0.4830]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.030399999999999983, 0.01700000000000007, 0.021000000000000074]\n",
      "tensor([[0.3721]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01479999999999998, 0.006599999999999995, 0.00720000000000004]\n",
      "tensor([[0.5652]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.015400000000000025, 0.0024000000000000132, 0.006999999999999951]\n",
      "tensor([[0.4608]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0262, 0.01639999999999997, 0.006199999999999983]\n",
      "tensor([[0.3737]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03660000000000002, 0.04800000000000004, 0.04099999999999998]\n",
      "tensor([[0.4791]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010399999999999965, 0.019999999999999962, 0.025400000000000034]\n",
      "tensor([[0.4537]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004599999999999993, 0.004799999999999971, 0.016199999999999992]\n",
      "tensor([[0.4776]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00020000000000003348, 0.008999999999999897, -0.004200000000000037]\n",
      "tensor([[0.4366]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003199999999999925, 0.027400000000000035, 0.010199999999999987]\n",
      "tensor([[0.4172]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.002599999999999991, 0.0025999999999999357, 0.0020000000000000018]\n",
      "tensor([[0.5227]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.016200000000000103, -0.01980000000000004, -0.012800000000000089]\n",
      "tensor([[0.4431]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0014000000000000123, 0.008199999999999985, 0.01759999999999995]\n",
      "tensor([[0.4705]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.042800000000000005, 0.040000000000000036, 0.020600000000000007]\n",
      "tensor([[0.5065]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01940000000000003, 0.02140000000000003, 0.015800000000000036]\n",
      "tensor([[0.3564]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0255999999999999, 0.005199999999999927, 0.015199999999999936]\n",
      "tensor([[0.4332]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010000000000000009, -0.005599999999999994, 0.017199999999999993]\n",
      "tensor([[0.4928]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03299999999999992, 0.02839999999999998, 0.02200000000000002]\n",
      "tensor([[0.5224]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0023999999999999577, -0.00039999999999995595, -0.0013999999999999013]\n",
      "tensor([[0.3904]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006800000000000028, 0.011999999999999955, 0.025400000000000034]\n",
      "tensor([[0.5202]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011600000000000055, 0.022799999999999987, -0.0045999999999999375]\n",
      "tensor([[0.5038]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012799999999999923, 0.016599999999999948, 0.018399999999999972]\n",
      "tensor([[0.4319]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006800000000000084, 0.016000000000000014, 0.03200000000000003]\n",
      "tensor([[0.4496]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012999999999999956, 0.008999999999999952, 0.013800000000000034]\n",
      "tensor([[0.5795]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023199999999999943, 0.009799999999999975, 0.004999999999999949]\n",
      "tensor([[0.5306]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011400000000000021, 0.010600000000000054, 0.0242]\n",
      "tensor([[0.3865]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0017999999999999128, 0.0046000000000000485, -0.0041999999999999815]\n",
      "tensor([[0.3763]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.029000000000000026, 0.021600000000000008, 0.032200000000000006]\n",
      "tensor([[0.4653]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02639999999999998, 0.037799999999999945, 0.01979999999999993]\n",
      "tensor([[0.4667]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03319999999999995, 0.0262, 0.012799999999999978]\n",
      "tensor([[0.5073]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02980000000000005, 0.01820000000000005, 0.005600000000000049]\n",
      "tensor([[0.5904]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023199999999999943, 0.018199999999999994, 0.015800000000000036]\n",
      "tensor([[0.4287]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01699999999999996, 0.009799999999999975, 0.025200000000000056]\n",
      "tensor([[0.4807]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007199999999999929, 0.02339999999999992, 0.01699999999999996]\n",
      "tensor([[0.4922]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008400000000000019, -0.008000000000000007, 0.006399999999999961]\n",
      "tensor([[0.5330]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.032999999999999974, -0.006399999999999961, 0.006599999999999995]\n",
      "tensor([[0.4035]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011799999999999977, -0.02460000000000001, 0.0014000000000000123]\n",
      "tensor([[0.4092]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006599999999999939, 0.017600000000000005, 0.007199999999999929]\n",
      "tensor([[0.4365]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0116, 0.004799999999999971, -0.0040000000000000036]\n",
      "tensor([[0.6021]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013000000000000012, -0.008599999999999997, 0.015400000000000025]\n",
      "tensor([[0.4681]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01200000000000001, 0.039600000000000024, 0.01860000000000006]\n",
      "tensor([[0.4622]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.027599999999999902, 0.01699999999999996, 0.0381999999999999]\n",
      "tensor([[0.4625]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019399999999999917, 0.021799999999999986, 0.012599999999999945]\n",
      "tensor([[0.4512]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009599999999999942, 0.0021999999999999797, 0.03579999999999994]\n",
      "tensor([[0.5167]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005399999999999905, -0.0022000000000000908, 0.007799999999999918]\n",
      "tensor([[0.6191]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021400000000000086, 0.020199999999999996, 0.02639999999999998]\n",
      "tensor([[0.4186]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017000000000000015, 0.02579999999999999, 0.023999999999999966]\n",
      "tensor([[0.5051]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004799999999999971, 0.0021999999999999797, 0.02400000000000002]\n",
      "tensor([[0.5180]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00040000000000001146, 0.011799999999999977, 0.012799999999999923]\n",
      "tensor([[0.5442]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02119999999999994, -0.0034000000000000696, 0.003599999999999992]\n",
      "tensor([[0.4687]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009599999999999997, 0.030999999999999972, 0.02899999999999997]\n",
      "tensor([[0.4655]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021799999999999986, 0.038199999999999956, 0.027199999999999946]\n",
      "tensor([[0.4891]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011800000000000033, 0.010599999999999998, 0.008800000000000086]\n",
      "tensor([[0.4208]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0044000000000000705, -0.0041999999999999815, -0.006399999999999961]\n",
      "tensor([[0.3825]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006999999999999951, 0.012400000000000078, 0.03880000000000006]\n",
      "tensor([[0.4386]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024399999999999977, 0.01639999999999997, 0.023400000000000032]\n",
      "tensor([[0.5047]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00759999999999994, 0.0013999999999999568, -0.005200000000000038]\n",
      "tensor([[0.6385]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003000000000000058, -0.00040000000000001146, 0.014000000000000012]\n",
      "tensor([[0.4247]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022600000000000064, 0.003400000000000014, 0.011799999999999977]\n",
      "tensor([[0.5012]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020000000000000018, 0.042200000000000015, 0.009400000000000075]\n",
      "tensor([[0.4108]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02679999999999999, 0.0126, 0.0242]\n",
      "tensor([[0.4861]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.031000000000000083, 0.015800000000000036, 0.01540000000000008]\n",
      "tensor([[0.5317]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.002999999999999947, 0.006000000000000005, -0.0041999999999999815]\n",
      "tensor([[0.4124]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.032399999999999984, 0.005800000000000027, 0.02839999999999998]\n",
      "tensor([[0.5796]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0012000000000000344, 0.018799999999999983, -0.006599999999999995]\n",
      "tensor([[0.4680]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.030399999999999983, 0.015400000000000025, 0.012800000000000034]\n",
      "tensor([[0.4534]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01639999999999997, 0.0338, 0.024399999999999977]\n",
      "tensor([[0.4628]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0034000000000000696, 0.03620000000000001, -0.010999999999999954]\n",
      "tensor([[0.4883]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021600000000000008, 0.03120000000000006, 0.012600000000000056]\n",
      "tensor([[0.4045]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01579999999999998, 0.01859999999999995, 0.0006000000000000449]\n",
      "tensor([[0.4735]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004200000000000037, 0.010999999999999954, 0.011399999999999966]\n",
      "tensor([[0.4157]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003000000000000058, 0.00660000000000005, -0.008400000000000019]\n",
      "tensor([[0.5056]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003000000000000058, -0.026000000000000023, -0.003400000000000014]\n",
      "tensor([[0.4159]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007599999999999996, 0.011599999999999944, 0.011599999999999944]\n",
      "tensor([[0.4667]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0016000000000000458, -0.005800000000000027, 0.00720000000000004]\n",
      "tensor([[0.4197]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017400000000000027, -0.0013999999999999568, 0.005599999999999994]\n",
      "tensor([[0.3693]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.014999999999999958, 0.007400000000000018, -0.021399999999999975]\n",
      "tensor([[0.4118]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012199999999999989, 0.022599999999999953, -0.0044000000000000705]\n",
      "tensor([[0.3873]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006999999999999951, 0.020000000000000018, 0.00280000000000008]\n",
      "tensor([[0.4769]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005400000000000071, -0.0009999999999999454, 0.020399999999999974]\n",
      "Training [20%]\tLoss: -0.5110\n",
      "tensor([[0.4436]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.034599999999999964, 0.01699999999999996, 0.020999999999999963]\n",
      "tensor([[0.4077]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01720000000000005, -0.012199999999999989, 0.0024000000000000687]\n",
      "tensor([[0.5162]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012399999999999967, 0.025200000000000056, 0.014399999999999968]\n",
      "tensor([[0.5207]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0043999999999999595, 0.014999999999999958, 0.0021999999999999797]\n",
      "tensor([[0.4832]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006599999999999995, 0.0026000000000000467, 0.006199999999999983]\n",
      "tensor([[0.5558]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012199999999999989, 0.017799999999999983, -0.00019999999999997797]\n",
      "tensor([[0.5017]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0033999999999999586, -0.0046000000000000485, 0.00539999999999996]\n",
      "tensor([[0.3083]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0047999999999999154, 0.007599999999999996, 0.012399999999999967]\n",
      "tensor([[0.5055]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00940000000000002, 0.01640000000000008, 0.015200000000000047]\n",
      "tensor([[0.4148]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014600000000000057, 0.013600000000000001, 0.014600000000000057]\n",
      "tensor([[0.4219]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023199999999999943, 0.029399999999999926, 0.030399999999999983]\n",
      "tensor([[0.3726]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005599999999999938, 0.006400000000000017, 0.009599999999999942]\n",
      "tensor([[0.4815]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013199999999999934, 0.011599999999999944, 0.023599999999999954]\n",
      "tensor([[0.4367]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.037200000000000066, 0.017400000000000082, -0.006399999999999961]\n",
      "tensor([[0.3826]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0041999999999999815, 0.0255999999999999, 0.018600000000000005]\n",
      "tensor([[0.5473]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004999999999999949, -0.002599999999999991, 0.0116]\n",
      "tensor([[0.5024]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, -0.0015999999999999348, -0.0035999999999999366]\n",
      "tensor([[0.5645]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.020000000000000018, -0.024999999999999967, 0.013600000000000001]\n",
      "tensor([[0.3703]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011400000000000021, 0.011799999999999977, -0.010999999999999954]\n",
      "tensor([[0.4220]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0126, 0.010599999999999998, 0.01040000000000002]\n",
      "tensor([[0.5004]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000023, 0.021600000000000008, 0.019799999999999984]\n",
      "tensor([[0.4994]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00919999999999993, -0.017399999999999916, -0.008599999999999997]\n",
      "tensor([[0.5049]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01040000000000002, -0.02200000000000002, 0.008399999999999963]\n",
      "tensor([[0.3981]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.014399999999999968, -0.006400000000000017, -0.017800000000000038]\n",
      "tensor([[0.4783]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013600000000000001, 0.015400000000000025, 0.03340000000000004]\n",
      "tensor([[0.4437]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009400000000000075, 0.004800000000000082, 0.018400000000000027]\n",
      "tensor([[0.4331]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.027399999999999924, 0.027599999999999958, 0.03159999999999996]\n",
      "tensor([[0.4241]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012799999999999978, 0.018799999999999983, 0.02119999999999994]\n",
      "tensor([[0.4787]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.016000000000000014, 0.003400000000000014, -0.009600000000000053]\n",
      "tensor([[0.5029]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018199999999999994, -0.0018000000000000238, 0.013600000000000001]\n",
      "tensor([[0.4263]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013199999999999934, -0.007400000000000073, -0.008599999999999997]\n",
      "tensor([[0.5114]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014399999999999968, 0.005799999999999972, 0.013799999999999979]\n",
      "tensor([[0.4912]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.012799999999999978, -0.01040000000000002, -0.0013999999999999568]\n",
      "tensor([[0.4692]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.042200000000000015, 0.027400000000000035, 0.016199999999999992]\n",
      "tensor([[0.5707]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018400000000000027, 0.023200000000000054, 0.01200000000000001]\n",
      "tensor([[0.3975]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.037200000000000066, 0.03199999999999997, 0.024600000000000066]\n",
      "tensor([[0.3633]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015400000000000025, 0.011799999999999977, 0.023400000000000032]\n",
      "tensor([[0.4457]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00280000000000008, -0.0041999999999999815, 0.0034000000000000696]\n",
      "tensor([[0.6420]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0023999999999999577, -0.011000000000000065, -0.01700000000000007]\n",
      "tensor([[0.5161]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005800000000000027, -0.021600000000000008, 0.009800000000000031]\n",
      "tensor([[0.4695]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0019999999999999463, -0.005200000000000038, 0.009399999999999964]\n",
      "tensor([[0.3410]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00820000000000004, 0.013400000000000023, 0.014399999999999968]\n",
      "tensor([[0.4153]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.05980000000000002, 0.039400000000000046, 0.0398]\n",
      "tensor([[0.4471]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0043999999999999595, 0.018799999999999983, -0.0122000000000001]\n",
      "tensor([[0.4282]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00020000000000003348, -0.013400000000000079, -0.0016000000000000458]\n",
      "tensor([[0.4450]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008000000000000007, 0.00720000000000004, 0.014600000000000057]\n",
      "tensor([[0.3878]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, -0.00019999999999997797, 0.013399999999999967]\n",
      "tensor([[0.5935]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003399999999999903, 0.0045999999999999375, 0.012599999999999945]\n",
      "tensor([[0.5069]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007400000000000018, 0.006000000000000005, 0.006599999999999939]\n",
      "tensor([[0.5299]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.002599999999999991, 0.006400000000000017, -0.008400000000000074]\n",
      "tensor([[0.4057]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012400000000000078, 0.006200000000000094, 0.00940000000000002]\n",
      "tensor([[0.5001]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01200000000000001, 0.02639999999999998, 0.03140000000000004]\n",
      "tensor([[0.3205]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004799999999999971, 0.014599999999999946, 0.006000000000000005]\n",
      "tensor([[0.4963]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023799999999999988, 0.022600000000000064, 0.032399999999999984]\n",
      "tensor([[0.4168]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0006000000000001005, 0.020199999999999996, 0.003400000000000014]\n",
      "tensor([[0.3986]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025200000000000056, 0.008800000000000086, 0.009800000000000031]\n",
      "tensor([[0.4603]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0009999999999999454, 0.017199999999999938, 0.00979999999999992]\n",
      "tensor([[0.4151]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02779999999999999, 0.013399999999999912, 0.00019999999999997797]\n",
      "tensor([[0.4832]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.041800000000000004, 0.039600000000000024, 0.02779999999999999]\n",
      "tensor([[0.4563]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006199999999999983, -0.005799999999999972, 0.0033999999999999586]\n",
      "tensor([[0.4403]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018199999999999994, 0.034399999999999986, 0.01919999999999994]\n",
      "tensor([[0.5489]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0015999999999999348, 0.005199999999999927, 0.014399999999999968]\n",
      "tensor([[0.5844]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0036000000000000476, 0.01479999999999998, 0.00020000000000003348]\n",
      "tensor([[0.4505]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0011999999999999234, 0.005599999999999994, -0.008799999999999975]\n",
      "tensor([[0.4540]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015200000000000047, 0.03700000000000003, 0.03060000000000007]\n",
      "tensor([[0.5770]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017400000000000027, 0.010000000000000009, 0.01940000000000003]\n",
      "tensor([[0.3774]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006199999999999983, 0.03200000000000003, 0.01880000000000004]\n",
      "tensor([[0.4692]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023800000000000043, 0.0008000000000000784, 0.012800000000000089]\n",
      "tensor([[0.5357]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0338, -0.010000000000000009, 0.019600000000000006]\n",
      "tensor([[0.4593]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0026000000000000467, 0.03820000000000001, 0.014000000000000012]\n",
      "tensor([[0.5040]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028799999999999992, 0.03259999999999996, 0.027400000000000035]\n",
      "tensor([[0.4157]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0009999999999999454, 0.005200000000000038, 0.0008000000000000784]\n",
      "tensor([[0.3341]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014600000000000057, 0.020000000000000018, 0.015200000000000047]\n",
      "tensor([[0.3714]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005400000000000016, 0.0022000000000000908, 0.0008000000000000784]\n",
      "tensor([[0.4585]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015399999999999914, 0.013600000000000001, 0.007799999999999974]\n",
      "tensor([[0.4761]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.026800000000000046, 0.019600000000000006, -0.004999999999999949]\n",
      "tensor([[0.4465]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01899999999999996, 0.007800000000000029, 0.0043999999999999595]\n",
      "tensor([[0.4506]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.010999999999999954, 0.017800000000000038]\n",
      "tensor([[0.2756]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0021999999999999797, 0.006800000000000084, -0.015399999999999914]\n",
      "tensor([[0.5526]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.033600000000000074, 0.02900000000000008, 0.024400000000000033]\n",
      "tensor([[0.4476]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.029600000000000015, 0.020199999999999996, 0.018199999999999994]\n",
      "tensor([[0.4137]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01959999999999995, 0.0, 0.035200000000000065]\n",
      "tensor([[0.5679]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.009000000000000064, -0.002999999999999947]\n",
      "tensor([[0.4475]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0262, 0.02639999999999998, 0.029600000000000015]\n",
      "tensor([[0.4089]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005799999999999972, -0.022600000000000064, -0.019799999999999984]\n",
      "tensor([[0.4163]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0020000000000000018, 0.0012000000000000344, -0.0023999999999999577]\n",
      "tensor([[0.4331]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011399999999999966, 0.008199999999999985, -0.003200000000000036]\n",
      "tensor([[0.5197]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0017999999999999128, -0.006800000000000084, 0.0040000000000000036]\n",
      "tensor([[0.4787]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003599999999999992, -0.0020000000000000018, 0.014599999999999946]\n",
      "tensor([[0.5125]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02860000000000007, 0.013400000000000023, 0.03420000000000001]\n",
      "tensor([[0.4799]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017800000000000038, 0.022199999999999998, 0.01479999999999998]\n",
      "tensor([[0.4236]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016400000000000026, 0.030000000000000027, 0.025600000000000067]\n",
      "tensor([[0.4375]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00940000000000002, -0.0020000000000000018, 0.013600000000000001]\n",
      "tensor([[0.3863]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010200000000000042, -0.007799999999999974, 0.025200000000000056]\n",
      "tensor([[0.3612]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015400000000000025, 0.005799999999999972, -0.009800000000000031]\n",
      "tensor([[0.3635]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013200000000000045, -0.0024000000000000687, 0.0040000000000000036]\n",
      "tensor([[0.4793]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0038000000000000256, 0.020000000000000018, 0.007800000000000029]\n",
      "tensor([[0.5782]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008000000000000007, 0.006399999999999961, -0.008199999999999985]\n",
      "tensor([[0.4604]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0015999999999999903, -0.0006000000000000449, 0.01200000000000001]\n",
      "tensor([[0.4720]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003399999999999903, -0.010199999999999987, 0.0040000000000000036]\n",
      "Training [25%]\tLoss: -0.5230\n",
      "tensor([[0.4272]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0014000000000000679, 0.012199999999999989, -0.005800000000000027]\n",
      "tensor([[0.5130]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0040000000000000036, 0.008000000000000007, -0.0010000000000000564]\n",
      "tensor([[0.4510]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0018000000000000238, 0.01440000000000008, 0.0040000000000000036]\n",
      "tensor([[0.3734]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018199999999999994, 0.003000000000000058, 0.015200000000000047]\n",
      "tensor([[0.2999]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01060000000000011, -0.008200000000000096, -0.008800000000000086]\n",
      "tensor([[0.4171]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0129999999999999, 0.014599999999999946, 0.010399999999999965]\n",
      "tensor([[0.4737]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.026799999999999935, 0.010999999999999954, 0.016000000000000014]\n",
      "tensor([[0.5082]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01540000000000008, 0.016000000000000014, 0.0036000000000000476]\n",
      "tensor([[0.3717]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0014000000000000123, 0.0022000000000000353, 0.008400000000000019]\n",
      "tensor([[0.4218]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022600000000000064, 0.04100000000000009, 0.025400000000000034]\n",
      "tensor([[0.3393]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0012000000000000344, 0.0037999999999999146, 0.00040000000000001146]\n",
      "tensor([[0.4870]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00500000000000006, 0.0126, 0.004400000000000015]\n",
      "tensor([[0.6009]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.032399999999999984, 0.030799999999999994, 0.01760000000000006]\n",
      "tensor([[0.5759]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0038000000000000256, 0.0040000000000000036, 0.006199999999999983]\n",
      "tensor([[0.2426]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0008000000000001339, -0.006400000000000183, 0.016199999999999937]\n",
      "tensor([[0.3744]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008599999999999997, 0.00660000000000005, -0.007399999999999962]\n",
      "tensor([[0.3946]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0035999999999999366, 0.007400000000000018, -0.00040000000000001146]\n",
      "tensor([[0.5597]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004400000000000015, -0.014799999999999924, -0.007599999999999996]\n",
      "tensor([[0.3213]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006400000000000017, 0.013800000000000034, 0.009399999999999964]\n",
      "tensor([[0.4429]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00660000000000005, 0.018000000000000016, 0.02639999999999998]\n",
      "tensor([[0.4119]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022199999999999998, 0.01040000000000002, 0.016600000000000004]\n",
      "tensor([[0.3994]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00820000000000004, -0.0020000000000000018, 0.007200000000000095]\n",
      "tensor([[0.3869]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017399999999999916, 0.02079999999999993, 0.025999999999999968]\n",
      "tensor([[0.4627]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012199999999999989, 0.038799999999999946, 0.021600000000000008]\n",
      "tensor([[0.3856]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0020000000000000018, 0.015799999999999925, 0.002999999999999947]\n",
      "tensor([[0.4287]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, -0.013800000000000034, 0.011999999999999955]\n",
      "tensor([[0.3154]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01899999999999996, 0.010999999999999954, -0.009400000000000075]\n",
      "tensor([[0.5023]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03999999999999998, 0.023799999999999988, 0.035999999999999976]\n",
      "tensor([[0.4316]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006800000000000084, 0.025200000000000056, 0.04200000000000004]\n",
      "tensor([[0.5459]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009399999999999908, 0.020399999999999974, -0.015000000000000069]\n",
      "tensor([[0.4474]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02119999999999994, 0.020199999999999996, 0.018799999999999928]\n",
      "tensor([[0.4348]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0033999999999999586, 0.01700000000000007, -0.010000000000000009]\n",
      "tensor([[0.4002]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0036000000000000476, -0.0007999999999999674, 0.006799999999999973]\n",
      "tensor([[0.4277]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0026000000000000467, 0.013600000000000001, 0.019799999999999984]\n",
      "tensor([[0.5889]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021000000000000074, 0.0038000000000000256, 0.0126]\n",
      "tensor([[0.4849]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0016000000000000458, -0.008199999999999985, -0.009200000000000041]\n",
      "tensor([[0.4721]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018199999999999994, 0.024399999999999977, 0.015200000000000047]\n",
      "tensor([[0.5155]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, -0.0021999999999999797, 0.021600000000000008]\n",
      "tensor([[0.5081]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03760000000000002, 0.021200000000000052, 0.012799999999999978]\n",
      "tensor([[0.4110]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0026000000000000467, 0.005199999999999982, 0.006999999999999951]\n",
      "tensor([[0.5478]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009800000000000031, 0.03060000000000007, 0.03080000000000005]\n",
      "tensor([[0.3604]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0024000000000000687, 0.016199999999999992, 0.009599999999999942]\n",
      "tensor([[0.4913]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00660000000000005, 0.011000000000000065, 0.013600000000000001]\n",
      "tensor([[0.5698]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03420000000000001, 0.03640000000000004, 0.0470000000000001]\n",
      "tensor([[0.4234]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018199999999999994, 0.018000000000000016, 0.008599999999999997]\n",
      "tensor([[0.4298]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.027199999999999946, 0.010199999999999987, 0.0026000000000000467]\n",
      "tensor([[0.4355]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005400000000000016, -0.00039999999999995595, 0.0012000000000000344]\n",
      "tensor([[0.4877]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0022000000000000353, -0.00820000000000004, 0.016599999999999948]\n",
      "tensor([[0.4902]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0028000000000000247, -0.0005999999999999894, -0.010000000000000009]\n",
      "tensor([[0.4522]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004999999999999949, 0.005799999999999916, -0.0015999999999999903]\n",
      "tensor([[0.4902]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.02240000000000003, -0.033399999999999985, -0.030799999999999994]\n",
      "tensor([[0.3822]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0005999999999999894, 0.013200000000000045, 0.003000000000000058]\n",
      "tensor([[0.4360]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0014000000000000123, 0.01679999999999998, 0.0005999999999999894]\n",
      "tensor([[0.4394]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005600000000000049, 0.01699999999999996, 0.013199999999999934]\n",
      "tensor([[0.4193]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007800000000000029, 0.011200000000000043, 0.015400000000000025]\n",
      "tensor([[0.5658]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01660000000000006, 0.013799999999999979, 0.00940000000000002]\n",
      "tensor([[0.4495]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000023, 0.03119999999999995, 0.010599999999999943]\n",
      "tensor([[0.2352]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022199999999999998, 0.014000000000000012, 0.014000000000000012]\n",
      "tensor([[0.4446]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022199999999999998, 0.011800000000000033, 0.04099999999999998]\n",
      "tensor([[0.3503]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014200000000000101, 0.01060000000000011, 0.023200000000000054]\n",
      "tensor([[0.5734]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0116, 0.005199999999999927, 0.012399999999999967]\n",
      "tensor([[0.5078]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022199999999999998, 0.03400000000000003, 0.027800000000000047]\n",
      "tensor([[0.6115]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008600000000000052, 0.01679999999999998, -0.0008000000000000784]\n",
      "tensor([[0.5430]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.012800000000000034, -0.008400000000000074, -0.011200000000000043]\n",
      "tensor([[0.4172]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000023, 0.03139999999999993, 0.028999999999999915]\n",
      "tensor([[0.4923]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022199999999999998, 0.006199999999999983, -0.0015999999999999348]\n",
      "tensor([[0.3250]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01759999999999995, -0.01479999999999998, 0.0021999999999999797]\n",
      "tensor([[0.5458]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00720000000000004, -0.00019999999999997797, -0.0024000000000000132]\n",
      "tensor([[0.3727]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010000000000000009, 0.009800000000000031, 0.0262]\n",
      "tensor([[0.5044]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010800000000000032, 0.020399999999999974, 0.005200000000000038]\n",
      "tensor([[0.5439]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018399999999999972, 0.03579999999999994, -0.005800000000000027]\n",
      "tensor([[0.4688]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0045999999999999375, 0.023600000000000065, 0.023400000000000032]\n",
      "tensor([[0.4792]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013000000000000067, 0.014000000000000012, 0.008000000000000007]\n",
      "tensor([[0.6369]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0015999999999999903, 0.0007999999999999119, -0.005800000000000027]\n",
      "tensor([[0.4376]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008599999999999997, -0.018000000000000016, -0.00039999999999995595]\n",
      "tensor([[0.5455]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012199999999999989, 0.021400000000000086, 0.025400000000000034]\n",
      "tensor([[0.4658]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003400000000000014, 0.003000000000000058, 0.002599999999999991]\n",
      "tensor([[0.6246]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0005999999999999894, 0.00759999999999994, 0.011599999999999944]\n",
      "tensor([[0.4117]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0005999999999999894, -0.0009999999999999454, 0.0024000000000000687]\n",
      "tensor([[0.5307]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0005999999999999894, 0.020400000000000085, 0.031000000000000083]\n",
      "tensor([[0.3885]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.032200000000000006, 0.02860000000000007, 0.014800000000000035]\n",
      "tensor([[0.4033]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00940000000000002, 0.01200000000000001, 0.004599999999999993]\n",
      "tensor([[0.4618]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007400000000000073, 0.005800000000000027, -0.006399999999999961]\n",
      "tensor([[0.4652]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0036000000000000476, 0.0026000000000001022, 0.022400000000000087]\n",
      "tensor([[0.4344]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005400000000000016, 0.0020000000000000018, -0.0007999999999999674]\n",
      "tensor([[0.3995]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0022000000000000353, 0.010000000000000009, 0.009799999999999975]\n",
      "tensor([[0.3976]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015800000000000036, 0.026000000000000023, 0.010800000000000087]\n",
      "tensor([[0.3583]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0013999999999999568, -0.00019999999999997797, 0.015400000000000025]\n",
      "tensor([[0.4652]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0038000000000000256, 0.00940000000000002, 0.021600000000000008]\n",
      "tensor([[0.4957]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0016000000000000458, 0.002999999999999947, -0.012600000000000056]\n",
      "tensor([[0.4010]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0338, 0.018399999999999972, 0.032200000000000006]\n",
      "tensor([[0.4396]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.019600000000000006, 0.01639999999999997, 0.010799999999999976]\n",
      "tensor([[0.2586]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017199999999999938, -0.005200000000000038, 0.014399999999999968]\n",
      "tensor([[0.3878]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.032200000000000006, 0.0013999999999999568, 0.012999999999999956]\n",
      "tensor([[0.4717]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00940000000000002, -0.018399999999999972, -0.009200000000000041]\n",
      "tensor([[0.4517]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0034000000000000696, -0.006000000000000005, 0.002799999999999969]\n",
      "tensor([[0.5025]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03700000000000009, 0.00940000000000002, 0.025400000000000034]\n",
      "tensor([[0.4781]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004599999999999993, 0.014600000000000057, 0.0040000000000000036]\n",
      "tensor([[0.4425]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006399999999999961, 0.01699999999999996, 0.01419999999999999]\n",
      "tensor([[0.3560]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00040000000000001146, 0.0010000000000000564, -0.0014000000000000123]\n",
      "Training [30%]\tLoss: -0.5334\n",
      "tensor([[0.5354]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0016000000000000458, 0.005200000000000038, -0.0005999999999999339]\n",
      "tensor([[0.4403]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00020000000000003348, 0.013799999999999979, 0.015600000000000003]\n",
      "tensor([[0.3752]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009000000000000064, 0.006000000000000005, 0.010800000000000087]\n",
      "tensor([[0.3848]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024999999999999967, 0.01739999999999997, 0.002799999999999969]\n",
      "tensor([[0.5867]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016000000000000014, -0.00019999999999997797, -0.0041999999999999815]\n",
      "tensor([[0.3644]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009800000000000031, 0.033000000000000085, 0.013800000000000034]\n",
      "tensor([[0.3747]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0009999999999999454, 0.0, 0.011199999999999988]\n",
      "tensor([[0.4617]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006399999999999961, 0.006000000000000005, 0.010199999999999987]\n",
      "tensor([[0.4594]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028799999999999992, 0.0040000000000000036, 0.010999999999999954]\n",
      "tensor([[0.4126]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006799999999999973, 0.015200000000000047, -0.007399999999999962]\n",
      "tensor([[0.3997]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.002999999999999947, 0.0035999999999999366, 0.008199999999999985]\n",
      "tensor([[0.4635]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011199999999999932, -0.0020000000000000018, 0.019999999999999962]\n",
      "tensor([[0.3391]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0, -0.0021999999999999797, 0.015000000000000069]\n",
      "tensor([[0.5021]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.015199999999999936, -0.024599999999999955, 0.0018000000000000238]\n",
      "tensor([[0.4160]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004599999999999993, 0.02479999999999999, 0.011399999999999966]\n",
      "tensor([[0.5637]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0040000000000000036, 0.03240000000000004, 0.02700000000000008]\n",
      "tensor([[0.6051]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0338, 0.025999999999999968, 0.022800000000000042]\n",
      "tensor([[0.4586]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008999999999999952, 0.018000000000000016, 0.00919999999999993]\n",
      "tensor([[0.5735]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015199999999999936, 0.02560000000000001, 0.02779999999999999]\n",
      "tensor([[0.3972]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03820000000000001, 0.03119999999999995, 0.015600000000000058]\n",
      "tensor([[0.4207]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020000000000000018, 0.0012000000000000344, 0.014600000000000057]\n",
      "tensor([[0.6023]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011200000000000043, 0.027400000000000035, 0.0044000000000000705]\n",
      "tensor([[0.3768]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02579999999999999, 0.02139999999999992, 0.01079999999999992]\n",
      "tensor([[0.5239]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0040000000000000036, 0.008999999999999952, 0.0038000000000000256]\n",
      "tensor([[0.4387]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004400000000000015, 0.032200000000000006, -0.007199999999999929]\n",
      "tensor([[0.4177]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018000000000000016, 0.016000000000000014, 0.013600000000000001]\n",
      "tensor([[0.5030]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005200000000000038, 0.008599999999999941, 0.012199999999999989]\n",
      "tensor([[0.3605]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010999999999999954, 0.008599999999999997, -0.0006000000000000449]\n",
      "tensor([[0.5913]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0018000000000000238, 0.0126, -0.00940000000000002]\n",
      "tensor([[0.4297]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00379999999999997, 0.019000000000000017, 0.030399999999999983]\n",
      "tensor([[0.3750]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.030000000000000027, 0.01859999999999995, 0.014399999999999968]\n",
      "tensor([[0.4985]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023799999999999932, 0.002799999999999969, 0.02399999999999991]\n",
      "tensor([[0.4406]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017800000000000038, 0.04360000000000003, 0.0368]\n",
      "tensor([[0.5534]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008000000000000007, -0.005800000000000027, -0.013400000000000023]\n",
      "tensor([[0.5590]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0255999999999999, 0.023199999999999943, 0.027799999999999936]\n",
      "tensor([[0.4029]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.034399999999999986, -0.005400000000000016, 0.008400000000000019]\n",
      "tensor([[0.4420]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01920000000000005, 0.005800000000000027, 0.005599999999999994]\n",
      "tensor([[0.4302]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0016000000000000458, 0.007599999999999996, 0.022599999999999953]\n",
      "tensor([[0.4300]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003399999999999903, 0.012999999999999956, 0.022199999999999998]\n",
      "tensor([[0.4218]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00040000000000001146, -0.0024000000000000132, 0.015600000000000003]\n",
      "tensor([[0.5124]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03080000000000005, 0.029400000000000037, 0.029000000000000026]\n",
      "tensor([[0.4693]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00280000000000008, -0.016800000000000093, -0.017400000000000027]\n",
      "tensor([[0.5198]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00720000000000004, 0.007800000000000029, -0.008000000000000007]\n",
      "tensor([[0.4205]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014400000000000024, 0.033600000000000074, 0.02639999999999998]\n",
      "tensor([[0.5699]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006199999999999983, 0.006400000000000072, 0.008600000000000052]\n",
      "tensor([[0.3105]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011800000000000033, 0.01639999999999997, -0.008599999999999941]\n",
      "tensor([[0.6161]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007800000000000029, 0.007800000000000029, 0.02460000000000001]\n",
      "tensor([[0.4158]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007400000000000018, 0.017800000000000038, 0.015400000000000025]\n",
      "tensor([[0.4079]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03119999999999995, 0.0368, 0.02839999999999998]\n",
      "tensor([[0.4951]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.027400000000000035, 0.0034000000000000696]\n",
      "tensor([[0.5157]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.02920000000000006, -0.02920000000000006, -0.03920000000000007]\n",
      "tensor([[0.3486]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014999999999999958, 0.01139999999999991, -0.011800000000000033]\n",
      "tensor([[0.3506]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0027999999999999137, 0.005199999999999927, 0.0116]\n",
      "tensor([[0.5185]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006400000000000072, 0.006199999999999983, -0.008199999999999985]\n",
      "tensor([[0.4124]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00019999999999997797, 0.013200000000000045, 0.020399999999999974]\n",
      "tensor([[0.4719]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016600000000000004, 0.02839999999999998, 0.021000000000000074]\n",
      "tensor([[0.4927]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02139999999999992, -0.009400000000000075, 0.01799999999999996]\n",
      "tensor([[0.3735]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0022000000000000908, 0.013999999999999901, -0.010800000000000087]\n",
      "tensor([[0.5808]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01540000000000008, 0.026000000000000023, -0.006599999999999939]\n",
      "tensor([[0.4001]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010000000000000009, 0.03200000000000003, 0.013799999999999979]\n",
      "tensor([[0.3628]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.018000000000000016, 0.016799999999999926, 0.010599999999999943]\n",
      "tensor([[0.5073]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.021799999999999986, -0.0242, -0.0116]\n",
      "tensor([[0.5471]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01479999999999998, 0.02699999999999997, 0.004400000000000015]\n",
      "tensor([[0.5868]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020199999999999996, 0.01720000000000005, 0.006799999999999973]\n",
      "tensor([[0.3763]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.014000000000000012, -0.012999999999999956, 0.025000000000000022]\n",
      "tensor([[0.4049]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014400000000000024, 0.02400000000000002, 0.022799999999999987]\n",
      "tensor([[0.5657]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0040000000000000036, -0.017600000000000005, 0.006599999999999995]\n",
      "tensor([[0.4010]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017799999999999983, 0.013999999999999957, 0.01419999999999999]\n",
      "tensor([[0.4701]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003000000000000058, 0.010800000000000032, 0.011000000000000065]\n",
      "tensor([[0.4550]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0007999999999999674, -0.002599999999999991, 0.020000000000000018]\n",
      "tensor([[0.5179]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0116, 0.018799999999999928, 0.014599999999999946]\n",
      "tensor([[0.5926]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00039999999999995595, 0.0018000000000000238, 0.01200000000000001]\n",
      "tensor([[0.5139]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006000000000000005, 0.006799999999999917, 0.0040000000000000036]\n",
      "tensor([[0.3377]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01419999999999999, 0.011200000000000043, 0.015600000000000003]\n",
      "tensor([[0.4351]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01200000000000001, 0.012400000000000022, 0.006199999999999983]\n",
      "tensor([[0.3693]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0013999999999999568, 0.0012000000000000344, -0.008999999999999952]\n",
      "tensor([[0.3182]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03400000000000003, 0.028200000000000003, 0.018199999999999994]\n",
      "tensor([[0.4342]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007799999999999974, 0.018400000000000027, -0.0021999999999999797]\n",
      "tensor([[0.4361]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011199999999999932, -0.0020000000000000018, 0.008999999999999952]\n",
      "tensor([[0.4820]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01700000000000007, 0.026600000000000013, 0.020000000000000018]\n",
      "tensor([[0.4740]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0006000000000001005, 0.004800000000000082, 0.00500000000000006]\n",
      "tensor([[0.5197]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00660000000000005, -0.017800000000000038, -0.005400000000000016]\n",
      "tensor([[0.5760]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018199999999999994, 0.041000000000000036, 0.02860000000000007]\n",
      "tensor([[0.3548]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03059999999999996, 0.01479999999999998, 0.0242]\n",
      "tensor([[0.3103]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005199999999999927, 0.013199999999999934, 0.010199999999999987]\n",
      "tensor([[0.2804]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0009999999999999454, 0.003200000000000036, 0.020600000000000007]\n",
      "tensor([[0.6328]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020799999999999985, -0.003599999999999992, 0.00820000000000004]\n",
      "tensor([[0.4436]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.02360000000000001, -0.0023999999999999577, -0.007599999999999996]\n",
      "tensor([[0.3590]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0040000000000000036, 0.011400000000000077, 0.006599999999999995]\n",
      "tensor([[0.2284]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006999999999999895, 0.005399999999999849, 0.02739999999999987]\n",
      "tensor([[0.3230]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006800000000000084, -0.0009999999999999454, 0.018400000000000083]\n",
      "tensor([[0.3438]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023600000000000065, 0.01899999999999996, 0.01720000000000005]\n",
      "tensor([[0.4626]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028799999999999937, 0.025399999999999923, 0.016599999999999948]\n",
      "tensor([[0.5126]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, 0.008200000000000096, -0.009599999999999942]\n",
      "tensor([[0.4032]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0038000000000000256, 0.014599999999999946, 0.0005999999999999894]\n",
      "tensor([[0.4050]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013399999999999912, 0.013999999999999957, 0.022599999999999953]\n",
      "tensor([[0.5522]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021999999999999964, 0.0007999999999999119, 0.029799999999999993]\n",
      "tensor([[0.4018]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.015200000000000047, -0.008400000000000074, -0.011800000000000033]\n",
      "tensor([[0.4280]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006799999999999973, -0.00040000000000006697, -0.00720000000000004]\n",
      "tensor([[0.5334]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01200000000000001, 0.0036000000000000476, 0.022199999999999998]\n",
      "Training [35%]\tLoss: -0.5428\n",
      "tensor([[0.3241]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0019999999999998908, 0.007799999999999918, -0.003200000000000036]\n",
      "tensor([[0.4784]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00979999999999992, 0.026600000000000013, 0.01679999999999998]\n",
      "tensor([[0.5041]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02760000000000007, 0.018600000000000005, 0.008000000000000007]\n",
      "tensor([[0.3391]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0010000000000000564, -0.015599999999999947, 0.0020000000000000018]\n",
      "tensor([[0.3883]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02040000000000003, 0.0008000000000000784, 0.02740000000000009]\n",
      "tensor([[0.4689]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0024000000000000132, -0.014799999999999924, -0.005799999999999972]\n",
      "tensor([[0.4224]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003200000000000036, 0.017400000000000027, 0.02859999999999996]\n",
      "tensor([[0.5345]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02180000000000004, -0.00039999999999995595, -0.00919999999999993]\n",
      "tensor([[0.4848]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0045999999999999375, -0.0041999999999999815, -0.010399999999999965]\n",
      "tensor([[0.5441]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.04200000000000004, 0.030000000000000027, 0.016000000000000014]\n",
      "tensor([[0.2704]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010599999999999998, 0.020800000000000096, 0.014200000000000046]\n",
      "tensor([[0.2951]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0126, 0.01739999999999997, -0.0026000000000000467]\n",
      "tensor([[0.4728]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, 0.005600000000000049, 0.017400000000000027]\n",
      "tensor([[0.4397]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013800000000000034, 0.013800000000000034, -0.0047999999999999154]\n",
      "tensor([[0.4409]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008599999999999997, 0.0, -0.008599999999999997]\n",
      "tensor([[0.3372]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005399999999999905, -0.00280000000000008, -0.013000000000000067]\n",
      "tensor([[0.4228]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.027199999999999946, 0.010000000000000009, 0.012199999999999989]\n",
      "tensor([[0.4466]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.012399999999999967, 0.00019999999999997797, 0.009600000000000053]\n",
      "tensor([[0.4759]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007600000000000051, 0.030600000000000016, 0.010799999999999976]\n",
      "tensor([[0.5022]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003000000000000058, 0.005400000000000071, 0.006800000000000084]\n",
      "tensor([[0.5249]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014600000000000002, -0.010600000000000054, -0.009599999999999997]\n",
      "tensor([[0.5196]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02900000000000008, 0.00720000000000004, 0.0378]\n",
      "tensor([[0.4050]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018399999999999972, 0.008999999999999897, 0.02119999999999994]\n",
      "tensor([[0.5860]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008600000000000052, 0.0015999999999999903, 0.0021999999999999797]\n",
      "tensor([[0.3754]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018199999999999994, 0.03480000000000005, 0.029400000000000037]\n",
      "tensor([[0.4228]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00500000000000006, -0.008999999999999952, 0.013600000000000001]\n",
      "tensor([[0.3682]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.038199999999999956, 0.026800000000000046, 0.021600000000000008]\n",
      "tensor([[0.4070]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007399999999999962, 0.02260000000000001, 0.013599999999999945]\n",
      "tensor([[0.5522]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008599999999999941, 0.013999999999999957, 0.02639999999999998]\n",
      "tensor([[0.3468]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0038000000000000256, -0.008799999999999975, -0.006599999999999939]\n",
      "tensor([[0.5535]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004599999999999993, 0.026000000000000023, 0.026000000000000023]\n",
      "tensor([[0.3598]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021799999999999986, 0.008999999999999952, 0.018199999999999994]\n",
      "tensor([[0.5444]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003000000000000058, -0.0005999999999999894, 0.008000000000000007]\n",
      "tensor([[0.5112]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01940000000000003, 0.009200000000000041, 0.015000000000000069]\n",
      "tensor([[0.4050]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0011999999999999234, 0.0021999999999999797, -0.00040000000000001146]\n",
      "tensor([[0.3986]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007800000000000029, -0.0126, -0.014999999999999958]\n",
      "tensor([[0.4132]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013199999999999934, 0.01419999999999999, 0.014599999999999946]\n",
      "tensor([[0.3821]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03200000000000003, 0.0262, 0.04580000000000006]\n",
      "tensor([[0.4763]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.04860000000000009, 0.05020000000000002, 0.008200000000000096]\n",
      "tensor([[0.5101]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017600000000000005, 0.025200000000000056, 0.007400000000000018]\n",
      "tensor([[0.4354]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000023, 0.021600000000000008, 0.006799999999999973]\n",
      "tensor([[0.4425]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.015800000000000036, 0.024399999999999977, 0.002999999999999947]\n",
      "tensor([[0.4474]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03620000000000001, 0.0043999999999999595, -0.004599999999999993]\n",
      "tensor([[0.5907]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005800000000000027, -0.008599999999999997, 0.005800000000000027]\n",
      "tensor([[0.5033]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004799999999999971, -0.006999999999999951, -0.002599999999999991]\n",
      "tensor([[0.4711]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01040000000000002, -0.0024000000000000132, 0.013200000000000045]\n",
      "tensor([[0.5283]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016600000000000004, 0.018199999999999994, 0.009800000000000031]\n",
      "tensor([[0.4155]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0015999999999999903, -0.0027999999999999137, 0.01419999999999999]\n",
      "tensor([[0.4856]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00019999999999997797, -0.010600000000000054, -0.009200000000000041]\n",
      "tensor([[0.5027]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011399999999999966, 0.023799999999999932, 0.0031999999999999806]\n",
      "tensor([[0.3742]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017400000000000082, 0.018000000000000016, 0.02540000000000009]\n",
      "tensor([[0.3567]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004999999999999949, -0.010000000000000009, 0.0014000000000000123]\n",
      "tensor([[0.3273]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006000000000000005, -0.017600000000000005, -0.0012000000000000344]\n",
      "tensor([[0.5084]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012800000000000034, 0.008000000000000007, 0.02560000000000001]\n",
      "tensor([[0.2914]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005200000000000038, 0.0034000000000000696, -0.0014000000000000123]\n",
      "tensor([[0.3363]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005799999999999916, -0.01700000000000007, 0.00019999999999997797]\n",
      "tensor([[0.5143]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008000000000000007, -0.0041999999999999815, -0.007199999999999929]\n",
      "tensor([[0.5112]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005200000000000038, 0.0018000000000000238, 0.00500000000000006]\n",
      "tensor([[0.7241]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0040000000000000036, 0.0008000000000000229, 0.007400000000000018]\n",
      "tensor([[0.4832]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0020000000000000018, -0.008599999999999997, 0.006400000000000072]\n",
      "tensor([[0.4001]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021600000000000008, 0.015600000000000003, 0.021600000000000008]\n",
      "tensor([[0.4483]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007399999999999962, 0.016600000000000004, 0.009599999999999942]\n",
      "tensor([[0.5422]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010599999999999943, 0.02339999999999992, 0.016000000000000014]\n",
      "tensor([[0.5648]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025200000000000056, 0.0484, 0.03639999999999999]\n",
      "tensor([[0.5473]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005400000000000016, -0.008199999999999985, -0.0016000000000000458]\n",
      "tensor([[0.4572]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013000000000000067, -0.007000000000000062, -0.010800000000000087]\n",
      "tensor([[0.4359]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0041999999999999815, 0.00940000000000002, 0.01480000000000009]\n",
      "tensor([[0.3160]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010400000000000076, -0.006399999999999961, -0.0043999999999999595]\n",
      "tensor([[0.5292]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0018000000000000238, -0.018000000000000016, -0.014600000000000002]\n",
      "tensor([[0.5600]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.027399999999999924, 0.02199999999999991, 0.020999999999999963]\n",
      "tensor([[0.4657]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011400000000000021, -0.005400000000000016, 0.00039999999999995595]\n",
      "tensor([[0.5417]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008600000000000052, -0.006000000000000005, 0.015600000000000003]\n",
      "tensor([[0.2345]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016799999999999926, 0.009799999999999809, 0.023599999999999843]\n",
      "tensor([[0.3926]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015400000000000025, 0.008400000000000074, 0.0026000000000000467]\n",
      "tensor([[0.4328]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010399999999999965, 0.0044000000000000705, 0.011000000000000065]\n",
      "tensor([[0.4393]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.009599999999999997, 0.017600000000000005]\n",
      "tensor([[0.3018]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02579999999999999, 0.021200000000000052, 0.006400000000000072]\n",
      "tensor([[0.5610]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006200000000000094, 0.005999999999999894, -0.008000000000000007]\n",
      "tensor([[0.6775]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0005999999999999894, -0.004999999999999949, 0.006599999999999995]\n",
      "tensor([[0.6248]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005199999999999927, 0.008999999999999952, 0.007799999999999974]\n",
      "tensor([[0.4450]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0015999999999999903, 0.010600000000000054, -0.010000000000000009]\n",
      "tensor([[0.5383]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0036000000000000476, -0.013800000000000034, -0.0041999999999999815]\n",
      "tensor([[0.5868]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010599999999999998, 0.007400000000000073, 0.013400000000000079]\n",
      "tensor([[0.5548]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0026000000000000467, 0.017600000000000005, 0.012400000000000078]\n",
      "tensor([[0.4512]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013600000000000001, 0.013599999999999945, 0.013199999999999934]\n",
      "tensor([[0.6550]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004999999999999893, 0.0020000000000000018, -0.01540000000000008]\n",
      "tensor([[0.6384]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.021399999999999975, -0.00759999999999994, -0.02240000000000003]\n",
      "tensor([[0.4011]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03639999999999999, 0.017799999999999983, 0.026599999999999957]\n",
      "tensor([[0.4739]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0038000000000000256, 0.0010000000000000564, 0.004599999999999993]\n",
      "tensor([[0.3925]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.011599999999999944, -0.011399999999999966, 0.010600000000000054]\n",
      "tensor([[0.4547]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004599999999999993, 0.022399999999999975, 0.012799999999999978]\n",
      "tensor([[0.4972]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028400000000000036, -0.005599999999999994, 0.03240000000000004]\n",
      "tensor([[0.4851]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028800000000000103, 0.013000000000000067, 0.023800000000000043]\n",
      "tensor([[0.4553]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011800000000000033, 0.012799999999999978, 0.022199999999999998]\n",
      "tensor([[0.4563]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.013599999999999945, -0.0040000000000000036]\n",
      "tensor([[0.6359]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024799999999999933, 0.013799999999999979, 0.01139999999999991]\n",
      "tensor([[0.5213]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.046599999999999975, 0.019600000000000062, 0.013400000000000079]\n",
      "tensor([[0.4589]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021200000000000052, 0.0006000000000001005, 0.020199999999999996]\n",
      "tensor([[0.3985]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03340000000000004, 0.0358, 0.03320000000000006]\n",
      "tensor([[0.4141]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01919999999999994, 0.006000000000000005, 0.03139999999999993]\n",
      "Training [40%]\tLoss: -0.5483\n",
      "tensor([[0.4679]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02200000000000002, 0.03260000000000002, 0.0010000000000000564]\n",
      "tensor([[0.4105]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021000000000000074, 0.0022000000000000353, 0.008800000000000086]\n",
      "tensor([[0.5618]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.029600000000000015, 0.025999999999999968, 0.017000000000000015]\n",
      "tensor([[0.4173]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0021999999999999797, 0.008799999999999975, 0.024399999999999977]\n",
      "tensor([[0.4816]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01820000000000005, 0.016600000000000004, 0.008599999999999997]\n",
      "tensor([[0.5652]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0040000000000000036, 0.019399999999999973, 0.02679999999999999]\n",
      "tensor([[0.5191]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03639999999999999, 0.03160000000000002, 0.041600000000000026]\n",
      "tensor([[0.5253]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016000000000000014, 0.02200000000000002, 0.03600000000000003]\n",
      "tensor([[0.4893]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003599999999999992, 0.007000000000000062, 0.008400000000000074]\n",
      "tensor([[0.4681]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005200000000000038, -0.0035999999999999366, 0.00660000000000005]\n",
      "tensor([[0.5667]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007600000000000051, -0.0023999999999999577, 0.010800000000000087]\n",
      "tensor([[0.5458]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02400000000000002, -0.0033999999999999586, 0.0042000000000000925]\n",
      "tensor([[0.5434]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0005999999999999339, 0.023200000000000054, 0.007800000000000029]\n",
      "tensor([[0.3828]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017800000000000038, 0.006599999999999995, 0.03860000000000002]\n",
      "tensor([[0.5580]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014600000000000002, 0.02639999999999998, 0.020600000000000007]\n",
      "tensor([[0.5473]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007400000000000018, -0.005200000000000038, 0.027600000000000013]\n",
      "tensor([[0.2586]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006399999999999961, -0.0116, -0.00040000000000006697]\n",
      "tensor([[0.5302]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0005999999999999894, 0.0045999999999999375, 0.014399999999999968]\n",
      "tensor([[0.4483]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013400000000000023, 0.0020000000000000018, -0.0006000000000000449]\n",
      "tensor([[0.3830]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011800000000000033, -0.006399999999999961, 0.006599999999999939]\n",
      "tensor([[0.4939]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015800000000000036, 0.02699999999999997, 0.017800000000000038]\n",
      "tensor([[0.4511]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007600000000000051, 0.027400000000000035, 0.015400000000000025]\n",
      "tensor([[0.3159]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013600000000000001, 0.020199999999999996, 0.029600000000000015]\n",
      "tensor([[0.4186]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019799999999999984, 0.03999999999999998, 0.019600000000000006]\n",
      "tensor([[0.5399]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00500000000000006, 0.004999999999999949, 0.016000000000000014]\n",
      "tensor([[0.3266]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0038000000000000256, 0.0023999999999999577, -0.016599999999999948]\n",
      "tensor([[0.4671]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005800000000000027, -0.01040000000000002, 0.005400000000000016]\n",
      "tensor([[0.5170]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.04119999999999996, 0.030200000000000005, 0.046599999999999975]\n",
      "tensor([[0.6236]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011399999999999966, -0.006000000000000005, -0.010000000000000009]\n",
      "tensor([[0.5051]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.015199999999999936, -0.006399999999999961, -0.012999999999999956]\n",
      "tensor([[0.3784]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0021999999999999797, 0.016000000000000014, 0.009200000000000041]\n",
      "tensor([[0.5376]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018199999999999994, 0.029600000000000015, -0.012400000000000022]\n",
      "tensor([[0.4880]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.017199999999999938, -0.011400000000000021, -0.030000000000000027]\n",
      "tensor([[0.5804]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01139999999999991, 0.007399999999999907, 0.006599999999999939]\n",
      "tensor([[0.5147]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0035999999999999366, 0.016199999999999992, 0.010799999999999976]\n",
      "tensor([[0.4869]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01699999999999996, 0.01859999999999995, 0.008799999999999975]\n",
      "tensor([[0.3374]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005599999999999994, 0.00539999999999996, 0.008400000000000019]\n",
      "tensor([[0.3379]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005400000000000071, -0.0020000000000000018, 0.007000000000000062]\n",
      "tensor([[0.3894]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010399999999999965, 0.011799999999999977, -0.005599999999999938]\n",
      "tensor([[0.4096]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0009999999999999454, 0.007000000000000062, 0.01720000000000005]\n",
      "tensor([[0.4895]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008799999999999975, 0.0464, 0.035199999999999954]\n",
      "tensor([[0.2988]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0005999999999999894, -0.011599999999999944, 0.003200000000000036]\n",
      "tensor([[0.4218]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010400000000000076, 0.03160000000000002, -0.006399999999999961]\n",
      "tensor([[0.3955]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003400000000000014, -0.00919999999999993, -0.0005999999999999894]\n",
      "tensor([[0.5879]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006799999999999917, 0.012800000000000089, -0.0017999999999999683]\n",
      "tensor([[0.3673]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.022399999999999975, -0.015199999999999936, 0.013000000000000067]\n",
      "tensor([[0.4783]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.000200000000000089, 0.0036000000000000476, 0.0]\n",
      "tensor([[0.5275]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025400000000000034, 0.039600000000000024, 0.02920000000000006]\n",
      "tensor([[0.4645]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03299999999999992, 0.016199999999999992, 0.029799999999999993]\n",
      "tensor([[0.4906]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003000000000000058, 0.0013999999999999568, -0.0012000000000000344]\n",
      "tensor([[0.3331]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0026000000000000467, 0.01920000000000005, 0.003000000000000058]\n",
      "tensor([[0.4530]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01940000000000003, 0.0015999999999999903, 0.027200000000000057]\n",
      "tensor([[0.3908]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00940000000000002, -0.0014000000000000123, 0.006199999999999983]\n",
      "tensor([[0.4123]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.002799999999999969, -0.005400000000000016, 0.0041999999999999815]\n",
      "tensor([[0.5475]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, -0.0005999999999999339, 0.010199999999999987]\n",
      "tensor([[0.3832]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008000000000000007, 0.0020000000000000018, 0.01419999999999999]\n",
      "tensor([[0.4550]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014800000000000035, 0.012600000000000056, 0.007599999999999996]\n",
      "tensor([[0.3771]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006199999999999983, 0.007600000000000051, 0.006199999999999983]\n",
      "tensor([[0.4339]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013600000000000001, 0.008000000000000007, 0.01480000000000009]\n",
      "tensor([[0.3666]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0028000000000000247, -0.003200000000000036, 0.023599999999999954]\n",
      "tensor([[0.3029]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.014999999999999958, 0.0014000000000000123, 0.0122000000000001]\n",
      "tensor([[0.4968]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025999999999999968, 0.023799999999999988, 0.03079999999999994]\n",
      "tensor([[0.4445]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.032200000000000006, 0.030999999999999972, 0.028000000000000025]\n",
      "tensor([[0.5780]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00019999999999997797, 0.007599999999999996, 0.006800000000000028]\n",
      "tensor([[0.5047]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009599999999999942, -0.014000000000000012, 0.004799999999999971]\n",
      "tensor([[0.3208]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011400000000000077, 0.0022000000000000353, -0.0047999999999999154]\n",
      "tensor([[0.3447]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006799999999999973, 0.012199999999999989, 0.014999999999999958]\n",
      "tensor([[0.2495]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01459999999999989, 0.009999999999999842, 0.011799999999999866]\n",
      "tensor([[0.4765]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003200000000000036, -0.00379999999999997, -0.011799999999999977]\n",
      "tensor([[0.3478]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006999999999999951, -0.003200000000000036, 0.016199999999999992]\n",
      "tensor([[0.5856]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.034399999999999986, 0.027600000000000013, 0.010799999999999976]\n",
      "tensor([[0.4011]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017600000000000005, 0.008199999999999985, 0.010599999999999943]\n",
      "tensor([[0.5512]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024399999999999977, 0.012199999999999989, 0.019399999999999917]\n",
      "tensor([[0.2957]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00019999999999997797, 0.02080000000000004, 0.019600000000000006]\n",
      "tensor([[0.6313]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00280000000000008, 0.0132000000000001, -0.01079999999999992]\n",
      "tensor([[0.4079]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022799999999999987, 0.027599999999999958, 0.018400000000000027]\n",
      "tensor([[0.4792]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012400000000000078, 0.024399999999999977, 0.013200000000000045]\n",
      "tensor([[0.4283]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003200000000000036, 0.013799999999999979, 0.02279999999999993]\n",
      "tensor([[0.3378]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0021999999999999797, 0.0041999999999999815, -0.0020000000000000018]\n",
      "tensor([[0.3578]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013000000000000067, 0.016599999999999948, 0.01940000000000003]\n",
      "tensor([[0.3952]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.016199999999999992, 0.017400000000000027, 0.011800000000000033]\n",
      "tensor([[0.5260]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02119999999999994, 0.0040000000000000036, -0.0022000000000000353]\n",
      "tensor([[0.3231]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01639999999999997, 0.02399999999999991, 0.03319999999999995]\n",
      "tensor([[0.4862]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007599999999999996, -0.0013999999999999568, -0.004200000000000037]\n",
      "tensor([[0.5817]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013800000000000034, 0.0010000000000000564, -0.01679999999999998]\n",
      "tensor([[0.4179]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00940000000000002, 0.016600000000000004, 0.010599999999999998]\n",
      "tensor([[0.5782]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008999999999999952, 0.006199999999999983, 0.006000000000000005]\n",
      "tensor([[0.5256]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03120000000000006, 0.03500000000000009, 0.004800000000000082]\n",
      "tensor([[0.4740]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.018199999999999994, -0.0013999999999999013, -0.0011999999999999234]\n",
      "tensor([[0.4966]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02839999999999998, 0.027799999999999936, 0.008999999999999952]\n",
      "tensor([[0.6265]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022199999999999998, 0.04260000000000008, 0.02360000000000001]\n",
      "tensor([[0.5226]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013000000000000067, 0.00280000000000008, 0.02080000000000004]\n",
      "tensor([[0.4442]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014999999999999958, 0.032200000000000006, 0.026000000000000023]\n",
      "tensor([[0.3176]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.023199999999999943, 0.0040000000000000036, 0.002799999999999969]\n",
      "tensor([[0.4974]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023000000000000076, 0.0008000000000000784, 0.013200000000000045]\n",
      "tensor([[0.3497]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02639999999999998, 0.01859999999999995, 0.020000000000000018]\n",
      "tensor([[0.3842]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005599999999999994, -0.0020000000000000018, 0.004400000000000015]\n",
      "tensor([[0.5082]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018000000000000016, 0.01540000000000008, 0.034999999999999976]\n",
      "tensor([[0.4859]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00039999999999995595, 0.007800000000000029, -0.007400000000000018]\n",
      "tensor([[0.5659]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011000000000000065, 0.005799999999999972, 0.014800000000000035]\n",
      "Training [45%]\tLoss: -0.5368\n",
      "tensor([[0.4652]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005199999999999927, 0.007000000000000062, -0.0043999999999999595]\n",
      "tensor([[0.5035]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020800000000000096, 0.021200000000000052, 0.015600000000000003]\n",
      "tensor([[0.3921]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003400000000000014, 0.0007999999999999674, 0.008399999999999963]\n",
      "tensor([[0.4933]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00720000000000004, 0.010000000000000009, 0.018399999999999972]\n",
      "tensor([[0.5186]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0042000000000000925, 0.017800000000000038, 0.021000000000000074]\n",
      "tensor([[0.4786]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010800000000000087, -0.013000000000000067, -0.00500000000000006]\n",
      "tensor([[0.4712]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0038000000000000256, -0.010199999999999987, 0.0008000000000000784]\n",
      "tensor([[0.5849]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02700000000000008, 0.02200000000000002, 0.04920000000000008]\n",
      "tensor([[0.5042]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0005999999999999894, -0.0047999999999999154, 0.006400000000000017]\n",
      "tensor([[0.4517]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.010399999999999965, 0.010799999999999976]\n",
      "tensor([[0.2722]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, -0.006399999999999961, 0.018000000000000016]\n",
      "tensor([[0.2138]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01980000000000004, 0.009000000000000119, 0.013000000000000123]\n",
      "tensor([[0.4302]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03559999999999991, 0.0255999999999999, 0.0262]\n",
      "tensor([[0.4572]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03059999999999996, 0.010000000000000009, 0.009399999999999908]\n",
      "tensor([[0.5201]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00720000000000004, 0.007400000000000018, 0.006799999999999973]\n",
      "tensor([[0.4746]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012799999999999923, -0.012400000000000022, -0.008800000000000086]\n",
      "tensor([[0.4924]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008600000000000052, 0.03200000000000003, 0.01200000000000001]\n",
      "tensor([[0.2812]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.005200000000000038, 0.008999999999999952]\n",
      "tensor([[0.6315]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00040000000000006697, 0.0046000000000000485, 0.010000000000000009]\n",
      "tensor([[0.5516]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02679999999999999, 0.030600000000000016, 0.014400000000000024]\n",
      "tensor([[0.4234]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008399999999999963, 0.03160000000000002, 0.02140000000000003]\n",
      "tensor([[0.4203]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008199999999999985, 0.00039999999999995595, -0.009200000000000041]\n",
      "tensor([[0.5204]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003999999999999948, 0.009400000000000075, 0.02400000000000002]\n",
      "tensor([[0.4764]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01480000000000009, 0.0, -0.011200000000000043]\n",
      "tensor([[0.4443]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0242, 0.0013999999999999568, 0.0033999999999999586]\n",
      "tensor([[0.3500]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019600000000000062, 0.030200000000000005, 0.0354000000000001]\n",
      "tensor([[0.5124]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.002599999999999991, -0.015199999999999936, -0.01739999999999997]\n",
      "tensor([[0.4705]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014200000000000046, 0.006599999999999995, 0.002999999999999947]\n",
      "tensor([[0.5136]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022600000000000064, 0.016000000000000014, 0.020600000000000063]\n",
      "tensor([[0.5944]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024399999999999977, -0.0026000000000000467, 0.0005999999999999894]\n",
      "tensor([[0.4310]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024399999999999977, 0.015799999999999925, 0.01679999999999998]\n",
      "tensor([[0.4752]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01660000000000006, 0.01660000000000006, -0.004799999999999971]\n",
      "tensor([[0.4198]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022800000000000098, 0.01419999999999999, 0.024600000000000066]\n",
      "tensor([[0.5038]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008199999999999985, 0.007399999999999907, 0.013600000000000001]\n",
      "tensor([[0.4236]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01040000000000002, -0.019999999999999962, -0.010599999999999943]\n",
      "tensor([[0.4531]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021600000000000008, 0.028000000000000025, 0.013600000000000001]\n",
      "tensor([[0.4160]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009800000000000031, 0.0031999999999999806, -0.00019999999999997797]\n",
      "tensor([[0.5145]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.022199999999999998, 0.00019999999999997797, 0.0]\n",
      "tensor([[0.4596]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006400000000000017, 0.0025999999999999357, -0.01479999999999998]\n",
      "tensor([[0.3879]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.015199999999999936, 0.011799999999999977]\n",
      "tensor([[0.3671]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009000000000000064, 0.021200000000000052, -0.0009999999999999454]\n",
      "tensor([[0.4119]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011199999999999932, 0.029399999999999926, 0.034999999999999976]\n",
      "tensor([[0.4430]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021200000000000052, 0.015400000000000025, 0.03140000000000004]\n",
      "tensor([[0.5754]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006199999999999983, 0.004999999999999949, 0.011799999999999977]\n",
      "tensor([[0.3939]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01980000000000004, 0.027599999999999958, 0.013599999999999945]\n",
      "tensor([[0.5412]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005600000000000049, -0.006000000000000005, -0.009200000000000041]\n",
      "tensor([[0.4592]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00280000000000008, 0.005399999999999905, 0.002599999999999991]\n",
      "tensor([[0.5298]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023599999999999954, 0.030999999999999972, 0.02119999999999994]\n",
      "tensor([[0.5221]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.030399999999999983, 0.02839999999999998, 0.02140000000000003]\n",
      "tensor([[0.3955]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02140000000000003, 0.009000000000000064, 0.012600000000000056]\n",
      "tensor([[0.5483]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0015999999999999903, 0.017400000000000027, 0.010999999999999954]\n",
      "tensor([[0.2900]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01679999999999998, 0.004200000000000037, 0.0022000000000000353]\n",
      "tensor([[0.4166]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0016000000000000458, -0.015199999999999991, 0.008199999999999985]\n",
      "tensor([[0.5270]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0022000000000000353, -0.0010000000000000564, -0.0022000000000000353]\n",
      "tensor([[0.4749]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025000000000000078, 0.026600000000000013, 0.032200000000000006]\n",
      "tensor([[0.4943]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017600000000000005, 0.009799999999999975, 0.022800000000000042]\n",
      "tensor([[0.3131]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.00979999999999992, 0.0037999999999999146]\n",
      "tensor([[0.4861]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020199999999999996, 0.01540000000000008, 0.018400000000000027]\n",
      "tensor([[0.4535]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0021999999999999797, 0.0014000000000000123, -0.009600000000000053]\n",
      "tensor([[0.4259]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0008000000000000784, -0.01419999999999999, 0.017400000000000027]\n",
      "tensor([[0.5222]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028799999999999992, 0.024399999999999977, 0.00940000000000002]\n",
      "tensor([[0.4713]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01479999999999998, 0.003399999999999903, 0.010399999999999965]\n",
      "tensor([[0.5087]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03399999999999992, 0.01539999999999997, 0.0015999999999999348]\n",
      "tensor([[0.5910]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03560000000000002, 0.027200000000000057, 0.03140000000000004]\n",
      "tensor([[0.4536]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016599999999999948, 0.005599999999999994, 0.0043999999999999595]\n",
      "tensor([[0.5023]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0008000000000000229, 0.003200000000000036, 0.029600000000000015]\n",
      "tensor([[0.5496]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0018000000000000238, 0.006200000000000039, 0.004400000000000015]\n",
      "tensor([[0.5773]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01200000000000001, 0.007800000000000029, 0.0033999999999999586]\n",
      "tensor([[0.6060]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.033000000000000085, 0.03120000000000006, 0.023600000000000065]\n",
      "tensor([[0.3649]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006399999999999961, 0.018199999999999994, 0.014000000000000012]\n",
      "tensor([[0.4537]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018399999999999972, 0.017800000000000038, 0.02200000000000002]\n",
      "tensor([[0.3655]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008000000000000007, 0.008199999999999985, 0.029799999999999938]\n",
      "tensor([[0.5991]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023400000000000032, 0.012800000000000034, 0.032200000000000006]\n",
      "tensor([[0.4273]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011400000000000021, 0.012799999999999923, 0.01940000000000003]\n",
      "tensor([[0.4330]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0126, 0.010199999999999987, -0.022600000000000064]\n",
      "tensor([[0.3980]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005600000000000049, -0.0012000000000000899, 0.0021999999999999797]\n",
      "tensor([[0.5059]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012799999999999923, 0.008599999999999941, 0.002999999999999947]\n",
      "tensor([[0.5283]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018000000000000016, -0.011800000000000033, 0.013600000000000056]\n",
      "tensor([[0.3758]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013799999999999979, -0.008800000000000086, 0.016599999999999948]\n",
      "tensor([[0.5266]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019600000000000006, 0.023200000000000054, 0.015200000000000047]\n",
      "tensor([[0.5821]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011200000000000043, 0.017800000000000038, -0.0126]\n",
      "tensor([[0.5135]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014800000000000035, 0.005800000000000027, 0.0044000000000000705]\n",
      "tensor([[0.4686]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025399999999999923, 0.03479999999999994, 0.015600000000000003]\n",
      "tensor([[0.2916]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0026000000000000467, 0.025400000000000034, 0.022599999999999953]\n",
      "tensor([[0.6159]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0014000000000000123, 0.0009999999999999454, 0.002999999999999947]\n",
      "tensor([[0.4578]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010599999999999998, 0.006400000000000017, 0.027200000000000057]\n",
      "tensor([[0.3512]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00660000000000005, 0.014000000000000012, -0.003199999999999925]\n",
      "tensor([[0.5312]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011800000000000033, -0.02260000000000001, -0.01479999999999998]\n",
      "tensor([[0.5920]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01539999999999997, -0.014200000000000046, -0.0022000000000000353]\n",
      "tensor([[0.3482]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0013999999999999568, -0.005199999999999927, 0.011800000000000033]\n",
      "tensor([[0.4166]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005400000000000016, 0.003400000000000014, 0.025400000000000034]\n",
      "tensor([[0.4004]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019000000000000072, 0.014000000000000012, 0.025800000000000045]\n",
      "tensor([[0.6587]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01980000000000004, 0.016800000000000093, 0.032400000000000095]\n",
      "tensor([[0.3900]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0040000000000000036, 0.003599999999999992, 0.008999999999999952]\n",
      "tensor([[0.5490]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008400000000000019, 0.007799999999999918, 0.013799999999999923]\n",
      "tensor([[0.4315]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006199999999999983, 0.003200000000000036, 0.0007999999999999674]\n",
      "tensor([[0.6215]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006400000000000072, 0.01699999999999996, 0.012999999999999956]\n",
      "tensor([[0.4765]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0031999999999999806, 0.002999999999999947, 0.022999999999999965]\n",
      "tensor([[0.3795]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006800000000000084, 0.022199999999999998, 0.00660000000000005]\n",
      "tensor([[0.4938]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0015999999999999903, -0.004599999999999993, 0.012399999999999967]\n",
      "Training [50%]\tLoss: -0.5474\n",
      "tensor([[0.5046]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024999999999999967, 0.0388, 0.03059999999999996]\n",
      "tensor([[0.2395]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0132000000000001, -0.0020000000000000018, 0.005799999999999805]\n",
      "tensor([[0.4260]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004799999999999971, -0.01920000000000005, -0.0041999999999999815]\n",
      "tensor([[0.4161]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0116, -0.012200000000000044, 0.0040000000000000036]\n",
      "tensor([[0.3649]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.023200000000000054, 0.01200000000000001, -0.021200000000000052]\n",
      "tensor([[0.6997]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025800000000000045, 0.014399999999999968, 0.028799999999999992]\n",
      "tensor([[0.4124]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016600000000000004, 0.0126, 0.035200000000000065]\n",
      "tensor([[0.3813]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007800000000000029, 0.00020000000000003348, -0.007199999999999929]\n",
      "tensor([[0.5385]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.002999999999999947, -0.0017999999999999683, -0.006599999999999939]\n",
      "tensor([[0.4568]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02760000000000007, 0.04880000000000001, 0.023800000000000043]\n",
      "tensor([[0.4838]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0040000000000000036, 0.0023999999999999577, 0.014399999999999968]\n",
      "tensor([[0.5837]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005800000000000027, -0.01699999999999996, -0.006199999999999983]\n",
      "tensor([[0.5591]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003200000000000036, -0.014600000000000057, -0.008600000000000052]\n",
      "tensor([[0.5343]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007400000000000018, -0.01479999999999998, 0.02200000000000002]\n",
      "tensor([[0.4688]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.015800000000000036, -0.007400000000000018, -0.011200000000000043]\n",
      "tensor([[0.5833]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017199999999999938, 0.016000000000000014, 0.0015999999999999348]\n",
      "tensor([[0.3581]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.012199999999999989, -0.017199999999999938, -0.0025999999999999357]\n",
      "tensor([[0.4500]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0021999999999999797, -0.01479999999999998, 0.005599999999999994]\n",
      "tensor([[0.4790]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019400000000000084, 0.02180000000000004, 0.03180000000000005]\n",
      "tensor([[0.4164]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02679999999999999, 0.04360000000000003, 0.01700000000000007]\n",
      "tensor([[0.4336]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0007999999999999674, 0.02200000000000002, 0.006599999999999995]\n",
      "tensor([[0.5813]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022199999999999998, 0.03400000000000003, 0.044800000000000006]\n",
      "tensor([[0.6141]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02540000000000009, 0.009000000000000064, 0.0010000000000000564]\n",
      "tensor([[0.5315]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00039999999999995595, 0.021400000000000086, 0.004600000000000104]\n",
      "tensor([[0.5093]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025600000000000067, 0.013000000000000067, 0.0034000000000000696]\n",
      "tensor([[0.3512]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03999999999999998, 0.01419999999999999, 0.02860000000000007]\n",
      "tensor([[0.4819]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02200000000000002, 0.011800000000000033, 0.017800000000000038]\n",
      "tensor([[0.3914]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008399999999999963, 0.005200000000000038, -0.010599999999999998]\n",
      "tensor([[0.3383]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01899999999999996, 0.015799999999999925, 0.025599999999999956]\n",
      "tensor([[0.5791]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02200000000000002, -0.0037999999999999146, 0.007400000000000018]\n",
      "tensor([[0.4990]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02839999999999998, 0.006799999999999973, 0.009800000000000031]\n",
      "tensor([[0.4728]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01899999999999996, 0.01419999999999999, 0.028799999999999992]\n",
      "tensor([[0.3764]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010799999999999976, 0.018400000000000083, 0.006199999999999983]\n",
      "tensor([[0.2184]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012199999999999989, 0.01959999999999984, 0.015799999999999814]\n",
      "tensor([[0.4222]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0005999999999999894, 0.005199999999999927, 0.016799999999999926]\n",
      "tensor([[0.4777]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014799999999999924, 0.02579999999999999, 0.01200000000000001]\n",
      "tensor([[0.4589]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025000000000000078, 0.013400000000000079, 0.010200000000000042]\n",
      "tensor([[0.6027]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014399999999999968, -0.015200000000000047, -0.0041999999999999815]\n",
      "tensor([[0.3785]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018800000000000094, 0.012400000000000078, 0.009599999999999997]\n",
      "tensor([[0.4763]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0026000000000001022, 0.01700000000000007, 0.015600000000000003]\n",
      "tensor([[0.5721]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010999999999999954, 0.015199999999999936, -0.016200000000000103]\n",
      "tensor([[0.5700]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, -0.0035999999999999366, -0.012199999999999989]\n",
      "tensor([[0.2476]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009799999999999864, 0.0129999999999999, 0.015399999999999914]\n",
      "tensor([[0.4822]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008600000000000052, 0.009000000000000064, 0.006000000000000005]\n",
      "tensor([[0.3218]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0013999999999999013, 0.017800000000000038, -0.0040000000000000036]\n",
      "tensor([[0.4245]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012799999999999978, 0.024399999999999977, 0.023800000000000043]\n",
      "tensor([[0.4306]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007000000000000062, -0.010599999999999943, 0.0126]\n",
      "tensor([[0.4596]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008799999999999975, 0.0014000000000000123, 0.011199999999999932]\n",
      "tensor([[0.4107]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007400000000000018, 0.015400000000000025, -0.020999999999999963]\n",
      "tensor([[0.4940]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017800000000000038, 0.046599999999999975, 0.03140000000000004]\n",
      "tensor([[0.4447]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.016799999999999926, 0.0020000000000000018, 0.0010000000000000564]\n",
      "tensor([[0.2844]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01540000000000008, 0.009000000000000064, 0.019000000000000072]\n",
      "tensor([[0.4210]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00979999999999992, 0.02639999999999998, 0.01679999999999998]\n",
      "tensor([[0.4903]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02200000000000002, 0.03199999999999997, 0.020600000000000063]\n",
      "tensor([[0.6187]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00280000000000008, -0.004600000000000104, -0.004400000000000015]\n",
      "tensor([[0.4613]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0116, -0.026800000000000046, -0.01940000000000003]\n",
      "tensor([[0.7126]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004400000000000015, -0.0014000000000000679, -0.0038000000000000256]\n",
      "tensor([[0.3862]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015000000000000069, 0.011000000000000065, 0.017800000000000038]\n",
      "tensor([[0.4676]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008800000000000086, -0.01540000000000008, 0.015199999999999936]\n",
      "tensor([[0.4883]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01700000000000007, 0.010000000000000009, 0.020600000000000063]\n",
      "tensor([[0.3800]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017199999999999938, 0.00039999999999995595, -0.0007999999999999674]\n",
      "tensor([[0.2609]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007399999999999907, 0.028200000000000003, 0.007599999999999996]\n",
      "tensor([[0.5060]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016000000000000014, -0.0005999999999999894, 0.014599999999999946]\n",
      "tensor([[0.5205]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.031000000000000028, 0.029799999999999993, 0.008400000000000074]\n",
      "tensor([[0.5952]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.011599999999999944, 0.021000000000000074, 0.0010000000000000564]\n",
      "tensor([[0.2911]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008599999999999997, 0.0011999999999999234, 0.01079999999999992]\n",
      "tensor([[0.4821]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0005999999999999339, 0.02180000000000004, 0.0132000000000001]\n",
      "tensor([[0.1382]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007600000000000051, -0.006399999999999961, 0.01200000000000001]\n",
      "tensor([[0.5658]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013600000000000001, 0.010199999999999987, 0.026599999999999957]\n",
      "tensor([[0.5747]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009000000000000064, 0.006599999999999995, 0.015600000000000058]\n",
      "tensor([[0.1940]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025000000000000133, 0.015000000000000124, 0.015800000000000036]\n",
      "tensor([[0.4150]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006999999999999951, 0.004799999999999971, 0.009800000000000031]\n",
      "tensor([[0.3585]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010599999999999998, 0.018600000000000005, 0.006400000000000017]\n",
      "tensor([[0.1792]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0030000000000001137, 0.0027999999999999137, -0.0028000000000001357]\n",
      "tensor([[0.5106]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006799999999999973, 0.02339999999999992, 0.0015999999999999348]\n",
      "tensor([[0.5584]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000023, 0.03119999999999995, 0.03420000000000001]\n",
      "tensor([[0.3568]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.026000000000000023, 0.02400000000000002, 0.027400000000000035]\n",
      "tensor([[0.4710]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015600000000000058, 0.02960000000000007, 0.023200000000000054]\n",
      "tensor([[0.5564]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006999999999999951, 0.027400000000000035, 0.006999999999999951]\n",
      "tensor([[0.2987]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009200000000000041, 0.00940000000000002, 0.00720000000000004]\n",
      "tensor([[0.5639]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009599999999999997, 0.012400000000000078, 0.012199999999999989]\n",
      "tensor([[0.5190]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014599999999999946, 0.010999999999999954, 0.012399999999999967]\n",
      "tensor([[0.3227]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018399999999999972, 0.007000000000000062, -0.007599999999999996]\n",
      "tensor([[0.6887]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019400000000000084, 0.009200000000000097, -0.006999999999999951]\n",
      "tensor([[0.5671]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007199999999999929, 0.010799999999999976, -0.012400000000000078]\n",
      "tensor([[0.5591]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004799999999999971, -0.005799999999999972, -0.008199999999999985]\n",
      "tensor([[0.3532]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.002599999999999991, -0.010999999999999954, -0.013599999999999945]\n",
      "tensor([[0.4957]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02200000000000002, 0.03260000000000002, 0.038000000000000034]\n",
      "tensor([[0.4897]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019399999999999917, 0.011799999999999977, 0.008799999999999919]\n",
      "tensor([[0.3711]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00919999999999993, 0.01980000000000004, 0.003000000000000058]\n",
      "tensor([[0.4229]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.002799999999999969, -0.0042000000000000925, -0.0022000000000000908]\n",
      "tensor([[0.3784]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.015799999999999925, 0.0046000000000000485, 0.015000000000000069]\n",
      "tensor([[0.5653]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019999999999999962, 0.00039999999999995595, 0.00379999999999997]\n",
      "tensor([[0.5432]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009799999999999975, 0.013799999999999979, -0.0034000000000000696]\n",
      "tensor([[0.4161]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004400000000000015, -0.020000000000000018, 0.006199999999999983]\n",
      "tensor([[0.6530]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003599999999999992, 0.01859999999999995, 0.012799999999999923]\n",
      "tensor([[0.4541]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019000000000000072, 0.0044000000000000705, 0.010000000000000009]\n",
      "tensor([[0.4386]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0024000000000000132, 0.0005999999999999894, 0.02140000000000003]\n",
      "tensor([[0.3926]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0037999999999999146, -0.005399999999999905, -0.020399999999999974]\n",
      "tensor([[0.4034]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00039999999999995595, 0.026600000000000013, -0.0011999999999999234]\n",
      "Training [55%]\tLoss: -0.5556\n",
      "tensor([[0.4682]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008400000000000074, 0.0014000000000000123, -0.0035999999999999366]\n",
      "tensor([[0.7205]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007799999999999974, 0.014200000000000046, -0.0020000000000000018]\n",
      "tensor([[0.1785]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.014000000000000012, -0.0047999999999999154, -0.009600000000000053]\n",
      "tensor([[0.4546]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009800000000000031, -0.00720000000000004, -0.018600000000000005]\n",
      "tensor([[0.2523]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007199999999999929, -0.011800000000000088, 0.02080000000000004]\n",
      "tensor([[0.5500]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.020600000000000063, -0.0021999999999999797, 0.006000000000000005]\n",
      "tensor([[0.5145]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014800000000000035, 0.006800000000000084, 0.011000000000000065]\n",
      "tensor([[0.5308]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012999999999999956, 0.020399999999999974, -0.00040000000000006697]\n",
      "tensor([[0.4555]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.011000000000000065, 0.004999999999999949, 0.007799999999999974]\n",
      "tensor([[0.4833]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01679999999999998, -0.007799999999999918, -0.010999999999999954]\n",
      "tensor([[0.2119]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, -0.0021999999999999797, -0.005800000000000027]\n",
      "tensor([[0.5919]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004400000000000015, 0.025000000000000078, -0.006000000000000005]\n",
      "tensor([[0.5004]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02779999999999999, 0.022199999999999998, 0.042200000000000015]\n",
      "tensor([[0.6209]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010000000000000009, 0.00039999999999995595, -0.0018000000000000238]\n",
      "tensor([[0.3447]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01940000000000003, 0.002999999999999947, 0.015199999999999936]\n",
      "tensor([[0.6029]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008000000000000007, 0.013000000000000067, -0.0012000000000000344]\n",
      "tensor([[0.3375]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0047999999999999154, 0.01859999999999995, 0.017799999999999983]\n",
      "tensor([[0.3531]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023999999999999966, 0.031000000000000028, 0.00500000000000006]\n",
      "tensor([[0.4296]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020199999999999996, 0.02980000000000005, 0.0014000000000000679]\n",
      "tensor([[0.2649]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005399999999999905, 0.03339999999999993, 0.0041999999999999815]\n",
      "tensor([[0.4414]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.038799999999999946, 0.009599999999999997, 0.010999999999999954]\n",
      "tensor([[0.2547]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0024000000000000132, 0.008799999999999975, 0.009599999999999942]\n",
      "tensor([[0.3341]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0015999999999999348, -0.007199999999999929, -0.0021999999999999797]\n",
      "tensor([[0.5148]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018000000000000016, 0.02119999999999994, 0.008000000000000007]\n",
      "tensor([[0.5627]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003599999999999992, 0.006800000000000084, 0.028799999999999992]\n",
      "tensor([[0.3845]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018400000000000083, -0.0015999999999999348, 0.016000000000000014]\n",
      "tensor([[0.4242]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005799999999999972, 0.005599999999999994, 0.0045999999999999375]\n",
      "tensor([[0.4299]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02440000000000009, 0.013400000000000023, -0.003199999999999925]\n",
      "tensor([[0.3576]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008400000000000019, -0.008399999999999963, 0.03319999999999995]\n",
      "tensor([[0.4889]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007600000000000051, -0.003400000000000014, -0.002799999999999969]\n",
      "tensor([[0.2747]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0037999999999999146, 0.017399999999999916, -0.000200000000000089]\n",
      "tensor([[0.6368]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.04579999999999995, 0.029199999999999948, 0.03420000000000001]\n",
      "tensor([[0.3791]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023400000000000032, 0.03140000000000004, 0.03340000000000004]\n",
      "tensor([[0.3260]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004800000000000082, 0.010400000000000076, 0.013799999999999979]\n",
      "tensor([[0.7007]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020799999999999985, 0.009200000000000041, 0.010599999999999998]\n",
      "tensor([[0.5992]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01639999999999997, 0.000200000000000089, -0.0005999999999999894]\n",
      "tensor([[0.5145]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013200000000000045, 0.015000000000000069, -0.006000000000000005]\n",
      "tensor([[0.5861]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012800000000000089, 0.023799999999999988, 0.0020000000000000018]\n",
      "tensor([[0.5517]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009399999999999964, 0.023400000000000032, 0.00379999999999997]\n",
      "tensor([[0.5445]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008799999999999919, -0.013400000000000023, -0.003199999999999925]\n",
      "tensor([[0.4182]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003200000000000036, -0.004800000000000082, -0.005800000000000027]\n",
      "tensor([[0.3146]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005200000000000038, 0.008399999999999963, -0.006799999999999973]\n",
      "tensor([[0.5756]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.020999999999999963, -0.015400000000000025, -0.004999999999999949]\n",
      "tensor([[0.4322]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01419999999999999, 0.027800000000000047, 0.0022000000000000353]\n",
      "tensor([[0.4800]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008400000000000019, 0.0036000000000000476, 0.0034000000000000696]\n",
      "tensor([[0.4969]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00040000000000001146, 0.007599999999999996, 0.0025999999999999357]\n",
      "tensor([[0.6262]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.017199999999999938, -0.006799999999999917, -0.020999999999999908]\n",
      "tensor([[0.3163]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02299999999999991, 0.013600000000000001, 0.02859999999999996]\n",
      "tensor([[0.3294]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0024000000000000132, 0.0041999999999999815, 0.011199999999999932]\n",
      "tensor([[0.7988]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005400000000000071, 0.007600000000000051, -0.0047999999999999154]\n",
      "tensor([[0.4495]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008599999999999941, -0.0242, 0.0015999999999999903]\n",
      "tensor([[0.4992]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003599999999999992, 0.00280000000000008, -0.0025999999999999357]\n",
      "tensor([[0.6312]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00019999999999997797, -0.0021999999999999797, -0.005799999999999972]\n",
      "tensor([[0.4497]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021200000000000052, 0.03120000000000006, 0.015000000000000069]\n",
      "tensor([[0.2683]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006399999999999961, -0.006399999999999961, 0.0020000000000000018]\n",
      "tensor([[0.4304]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006599999999999995, -0.0038000000000000256, 0.011200000000000043]\n",
      "tensor([[0.3837]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017199999999999938, 0.007199999999999929, 0.016000000000000014]\n",
      "tensor([[0.5317]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003199999999999925, -0.011599999999999944, -0.008399999999999963]\n",
      "tensor([[0.5025]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004999999999999949, 0.012600000000000056, 0.0248000000000001]\n",
      "tensor([[0.3726]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0011999999999999234, 0.006400000000000017, 0.004799999999999971]\n",
      "tensor([[0.2778]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.006199999999999983, 0.01699999999999996]\n",
      "tensor([[0.5225]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01200000000000001, 0.032200000000000006, 0.02360000000000001]\n",
      "tensor([[0.5833]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009399999999999964, 0.014400000000000024, 0.03119999999999995]\n",
      "tensor([[0.3463]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014399999999999968, 0.017999999999999905, 0.006999999999999951]\n",
      "tensor([[0.5109]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017399999999999916, 0.00039999999999995595, 0.019399999999999917]\n",
      "tensor([[0.6483]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.002799999999999969, 0.0024000000000000132, -0.0040000000000000036]\n",
      "tensor([[0.3795]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.026600000000000068, 0.01920000000000005, 0.032200000000000006]\n",
      "tensor([[0.5021]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007800000000000029, 0.015200000000000047, 0.013800000000000034]\n",
      "tensor([[0.6874]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024599999999999955, 0.03839999999999999, 0.028000000000000025]\n",
      "tensor([[0.4871]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003000000000000058, 0.006200000000000039, 0.008800000000000086]\n",
      "tensor([[0.2940]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004599999999999993, 0.029399999999999926, 0.02040000000000003]\n",
      "tensor([[0.1826]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010599999999999943, 0.017400000000000082, -0.0038000000000000256]\n",
      "tensor([[0.3597]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013600000000000056, -0.002599999999999991, -0.004200000000000037]\n",
      "tensor([[0.6157]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008999999999999897, -0.011400000000000077, 0.018199999999999994]\n",
      "tensor([[0.4090]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009599999999999942, 0.013800000000000034, 0.008000000000000007]\n",
      "tensor([[0.3789]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0045999999999999375, 0.020199999999999996, 0.02839999999999998]\n",
      "tensor([[0.3000]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011599999999999944, 0.014000000000000012, -0.012199999999999989]\n",
      "tensor([[0.4445]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012399999999999967, 0.018199999999999994, 0.02579999999999999]\n",
      "tensor([[0.4882]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008599999999999997, -0.004200000000000037, 0.011799999999999977]\n",
      "tensor([[0.4182]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003599999999999992, -0.014600000000000002, 0.0011999999999999234]\n",
      "tensor([[0.5248]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005199999999999927, 0.0037999999999999146, 0.007399999999999962]\n",
      "tensor([[0.5603]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028200000000000003, 0.023799999999999988, 0.008000000000000007]\n",
      "tensor([[0.5086]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005800000000000027, -0.0022000000000000908, -0.009200000000000041]\n",
      "tensor([[0.5663]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007000000000000062, 0.0116, 0.009999999999999953]\n",
      "tensor([[0.5739]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00820000000000004, 0.005200000000000038, 0.013000000000000067]\n",
      "tensor([[0.3799]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013400000000000079, -0.008400000000000019, 0.006000000000000005]\n",
      "tensor([[0.5110]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00919999999999993, 0.0, -0.0005999999999999894]\n",
      "tensor([[0.4025]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024800000000000044, 0.019000000000000017, 0.03540000000000004]\n",
      "tensor([[0.5428]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02779999999999999, 0.01660000000000006, 0.024600000000000066]\n",
      "tensor([[0.7075]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004999999999999949, 0.010999999999999954, 0.012199999999999989]\n",
      "tensor([[0.6588]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005800000000000027, -0.0016000000000000458, -0.021600000000000008]\n",
      "tensor([[0.3229]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015400000000000025, -0.0126, 0.003200000000000036]\n",
      "tensor([[0.6465]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024399999999999977, 0.03799999999999998, 0.027600000000000013]\n",
      "tensor([[0.3592]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005199999999999982, 0.0006000000000000449, -0.006999999999999951]\n",
      "tensor([[0.2905]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006400000000000017, -0.0116, 0.0388]\n",
      "tensor([[0.3352]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008599999999999997, -0.01200000000000001, 0.006799999999999973]\n",
      "tensor([[0.4901]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020799999999999985, -0.006000000000000005, 0.013600000000000056]\n",
      "tensor([[0.5050]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003599999999999992, 0.03319999999999995, 0.010000000000000009]\n",
      "tensor([[0.6498]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022999999999999965, 0.006999999999999951, -0.010000000000000009]\n",
      "tensor([[0.3645]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0006000000000000449, 0.013799999999999923, 0.005199999999999927]\n",
      "Training [60%]\tLoss: -0.5912\n",
      "tensor([[0.4016]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00019999999999997797, 0.009599999999999997, 0.00500000000000006]\n",
      "tensor([[0.2110]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01639999999999997, -0.012199999999999989, -0.006599999999999939]\n",
      "tensor([[0.4940]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012199999999999989, -0.0015999999999999903, 0.013400000000000023]\n",
      "tensor([[0.5310]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011999999999999955, 0.013399999999999912, 0.0017999999999999683]\n",
      "tensor([[0.5749]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003400000000000014, 0.00500000000000006, 0.010000000000000009]\n",
      "tensor([[0.6909]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0015999999999999903, -0.013599999999999945, -0.008000000000000007]\n",
      "tensor([[0.3803]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009000000000000008, 0.007799999999999974, 0.00880000000000003]\n",
      "tensor([[0.1402]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007400000000000073, 0.021600000000000064, 0.019200000000000106]\n",
      "tensor([[0.6797]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012800000000000034, 0.017000000000000015, 0.00880000000000003]\n",
      "tensor([[0.4807]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011199999999999932, 0.008199999999999985, 0.019799999999999984]\n",
      "tensor([[0.1600]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006000000000000005, 0.0129999999999999, -0.0020000000000000018]\n",
      "tensor([[0.3300]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0006000000000000449, -0.008999999999999952, 0.013799999999999979]\n",
      "tensor([[0.6885]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01200000000000001, 0.0016000000000000458, 0.010799999999999976]\n",
      "tensor([[0.3381]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011200000000000043, -0.0037999999999999146, -0.014399999999999968]\n",
      "tensor([[0.5505]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0010000000000000564, 0.006799999999999973, 0.02760000000000007]\n",
      "tensor([[0.5278]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010599999999999998, 0.020399999999999974, 0.00539999999999996]\n",
      "tensor([[0.4528]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028200000000000003, 0.005600000000000049, -0.00019999999999997797]\n",
      "tensor([[0.4326]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0009999999999999454, 0.01419999999999999, 0.020600000000000007]\n",
      "tensor([[0.6093]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0022000000000000908, -0.0041999999999999815, 0.009200000000000041]\n",
      "tensor([[0.4433]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00820000000000004, -0.01540000000000008, -0.0016000000000000458]\n",
      "tensor([[0.4948]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011199999999999932, 0.02499999999999991, 0.02079999999999993]\n",
      "tensor([[0.6095]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00019999999999997797, 0.007799999999999918, 0.011399999999999966]\n",
      "tensor([[0.6871]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02200000000000002, 0.03839999999999999, 0.03799999999999992]\n",
      "tensor([[0.3934]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009799999999999975, 0.0026000000000000467, 0.011200000000000043]\n",
      "tensor([[0.5691]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0021999999999999797, -0.0020000000000000018, 0.02339999999999992]\n",
      "tensor([[0.6290]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008599999999999941, -0.0038000000000000256, -0.00500000000000006]\n",
      "tensor([[0.4653]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008399999999999963, 0.019999999999999907, 0.015199999999999936]\n",
      "tensor([[0.2824]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0126, 0.0262, 0.009800000000000031]\n",
      "tensor([[0.6160]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009600000000000053, 0.011200000000000043, 0.002799999999999969]\n",
      "tensor([[0.7163]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019999999999999907, 0.005799999999999916, -0.006200000000000094]\n",
      "tensor([[0.7256]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0116, 0.011799999999999977, -0.008000000000000007]\n",
      "tensor([[0.5087]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03979999999999995, 0.02119999999999994, 0.02260000000000001]\n",
      "tensor([[0.3643]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010400000000000076, -0.02400000000000002, -0.00919999999999993]\n",
      "tensor([[0.4450]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006000000000000005, -0.005799999999999916, -0.006399999999999961]\n",
      "tensor([[0.4792]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008199999999999985, -0.0041999999999999815, 0.0048000000000000265]\n",
      "tensor([[0.2988]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007599999999999996, 0.017799999999999983, 0.02400000000000002]\n",
      "tensor([[0.3093]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009599999999999997, 0.013399999999999912, 0.010599999999999943]\n",
      "tensor([[0.5279]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0033999999999999586, 0.008599999999999997, 0.016600000000000004]\n",
      "tensor([[0.5285]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006199999999999983, 0.0021999999999999797, 0.0010000000000000564]\n",
      "tensor([[0.4694]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0041999999999999815, 0.006000000000000005, 0.007199999999999929]\n",
      "tensor([[0.3521]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.019399999999999973, -0.0031999999999999806, 0.007799999999999974]\n",
      "tensor([[0.5807]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009200000000000041, -0.0005999999999999339, 0.0036000000000000476]\n",
      "tensor([[0.4041]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02839999999999998, 0.03299999999999992, 0.02119999999999994]\n",
      "tensor([[0.5709]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021799999999999986, 0.005200000000000038, 0.024399999999999977]\n",
      "tensor([[0.4793]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0262, 0.04200000000000004, 0.011400000000000021]\n",
      "tensor([[0.4439]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008400000000000074, 0.0020000000000000018, 0.011000000000000065]\n",
      "tensor([[0.3392]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0017999999999999128, -0.0037999999999999146, 0.013800000000000034]\n",
      "tensor([[0.4130]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012199999999999989, 0.029199999999999948, 0.01539999999999997]\n",
      "tensor([[0.2176]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0031999999999998696, -0.007400000000000073, -0.010199999999999987]\n",
      "tensor([[0.5004]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005199999999999927, -0.00539999999999996, -0.00979999999999992]\n",
      "tensor([[0.1890]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00019999999999997797, 0.009400000000000075, -0.0031999999999998696]\n",
      "tensor([[0.6070]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0014000000000000679, -0.0017999999999999683, 0.00040000000000001146]\n",
      "tensor([[0.3585]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011799999999999922, 0.0041999999999999815, 0.014400000000000024]\n",
      "tensor([[0.5548]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010000000000000009, 0.0020000000000000018, 0.013200000000000045]\n",
      "tensor([[0.3324]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02899999999999997, 0.010999999999999954, 0.010599999999999998]\n",
      "tensor([[0.6117]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008599999999999997, -0.011200000000000043, -0.0034000000000000696]\n",
      "tensor([[0.4042]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009800000000000031, -0.0016000000000000458, 0.01200000000000001]\n",
      "tensor([[0.5986]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013600000000000001, 0.02119999999999994, 0.017199999999999938]\n",
      "tensor([[0.5647]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.02079999999999993, 0.005800000000000027, 0.012800000000000089]\n",
      "tensor([[0.1642]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.007400000000000073, -0.005400000000000071]\n",
      "tensor([[0.6042]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004599999999999993, -0.00759999999999994, 0.013000000000000067]\n",
      "tensor([[0.4901]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000079, 0.005600000000000049, -0.0043999999999999595]\n",
      "tensor([[0.2553]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006800000000000028, 0.019000000000000017, 0.02799999999999997]\n",
      "tensor([[0.3832]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.029400000000000037, 0.025400000000000034, 0.023200000000000054]\n",
      "tensor([[0.4600]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017400000000000027, 0.016199999999999992, 0.005400000000000016]\n",
      "tensor([[0.5383]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008599999999999997, 0.020999999999999963, 0.0016000000000000458]\n",
      "tensor([[0.4282]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0010000000000000564, -0.006599999999999995, 0.0009999999999999454]\n",
      "tensor([[0.1965]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007800000000000029, 0.008399999999999963, 0.0047999999999999154]\n",
      "tensor([[0.5781]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020600000000000063, 0.023800000000000043, -0.005799999999999916]\n",
      "tensor([[0.2346]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.001000000000000112, -0.00039999999999995595, 0.004999999999999893]\n",
      "tensor([[0.3124]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02200000000000002, 0.020199999999999996, 0.022399999999999975]\n",
      "tensor([[0.5098]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0021999999999999797, -0.003400000000000014, -0.015400000000000025]\n",
      "tensor([[0.5798]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0014000000000000679, -0.010199999999999987, 0.006800000000000084]\n",
      "tensor([[0.3634]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03280000000000011, 0.01940000000000003, 0.022400000000000087]\n",
      "tensor([[0.1859]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0036000000000000476, -0.0005999999999999339, 0.023800000000000043]\n",
      "tensor([[0.3553]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003400000000000014, 0.03340000000000004, -0.005199999999999927]\n",
      "tensor([[0.5875]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0041999999999999815, 0.012399999999999967, 0.032200000000000006]\n",
      "tensor([[0.5380]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0018000000000000238, 0.00820000000000004, 0.013399999999999967]\n",
      "tensor([[0.3976]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010400000000000076, -0.004999999999999949, -0.0041999999999999815]\n",
      "tensor([[0.2515]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.014600000000000002, -0.00820000000000004, -0.003199999999999925]\n",
      "tensor([[0.4265]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006400000000000017, 0.003000000000000058, 0.007400000000000073]\n",
      "tensor([[0.3963]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019600000000000062, 0.024399999999999977, 0.025600000000000067]\n",
      "tensor([[0.3525]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017199999999999938, 0.004599999999999993, 0.0005999999999999894]\n",
      "tensor([[0.5541]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014600000000000002, 0.0007999999999999674, 0.016000000000000014]\n",
      "tensor([[0.6409]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0041999999999999815, -0.0032000000000000917, 0.00599999999999995]\n",
      "tensor([[0.6618]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0044000000000000705, 0.01479999999999998, -0.00280000000000008]\n",
      "tensor([[0.3221]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02859999999999996, 0.015599999999999947, 0.02179999999999993]\n",
      "tensor([[0.6290]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008000000000000007, 0.009599999999999997, -0.0012000000000000344]\n",
      "tensor([[0.6173]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025200000000000056, 0.029400000000000037, 0.01940000000000003]\n",
      "tensor([[0.3680]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008000000000000007, -0.0018000000000000238, 0.010199999999999987]\n",
      "tensor([[0.4488]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008000000000000007, 0.003000000000000058, 0.0038000000000000256]\n",
      "tensor([[0.3512]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007400000000000018, 0.005200000000000038, -0.0021999999999999797]\n",
      "tensor([[0.5629]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01860000000000006, 0.02839999999999998, 0.00500000000000006]\n",
      "tensor([[0.3747]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009200000000000041, -0.0028000000000000247, 0.00759999999999994]\n",
      "tensor([[0.4972]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01540000000000008, 0.004400000000000015, 0.014000000000000012]\n",
      "tensor([[0.1765]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0012000000000000899, 0.015600000000000058, 0.015200000000000102]\n",
      "tensor([[0.6203]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018000000000000016, 0.018399999999999972, 0.017400000000000027]\n",
      "tensor([[0.1250]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012599999999999945, 0.0038000000000000256, 0.008799999999999919]\n",
      "tensor([[0.5268]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0017999999999999128, -0.005200000000000038, -0.007000000000000062]\n",
      "tensor([[0.5739]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019600000000000006, 0.027200000000000057, 0.023999999999999966]\n",
      "Training [65%]\tLoss: -0.5953\n",
      "tensor([[0.4301]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009399999999999964, 0.01699999999999996, 0.012999999999999956]\n",
      "tensor([[0.3461]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014399999999999968, 0.01860000000000006, 0.0021999999999999797]\n",
      "tensor([[0.2614]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0048000000000000265, 0.007599999999999996, -0.01699999999999996]\n",
      "tensor([[0.3772]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0011999999999999234, 0.005800000000000027, 0.009600000000000053]\n",
      "tensor([[0.5502]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007599999999999996, 0.013199999999999934, -0.00040000000000001146]\n",
      "tensor([[0.1493]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006599999999999939, 0.016799999999999926, -0.014799999999999924]\n",
      "tensor([[0.7454]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009599999999999997, 0.025400000000000034, 0.013799999999999979]\n",
      "tensor([[0.4532]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017399999999999916, -0.0038000000000000256, 0.01699999999999996]\n",
      "tensor([[0.3516]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.04079999999999995, 0.03639999999999999, 0.029599999999999904]\n",
      "tensor([[0.2916]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012399999999999967, -0.018000000000000016, -0.01539999999999997]\n",
      "tensor([[0.5786]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011200000000000043, 0.022599999999999953, 0.026000000000000023]\n",
      "tensor([[0.6155]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024399999999999977, 0.012199999999999989, 0.0009999999999999454]\n",
      "tensor([[0.6028]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018399999999999972, 0.01639999999999997, 0.004999999999999949]\n",
      "tensor([[0.6429]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006799999999999917, 0.006599999999999939, -0.004400000000000015]\n",
      "tensor([[0.2684]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015600000000000003, 0.025000000000000022, 0.019999999999999962]\n",
      "tensor([[0.2814]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.020999999999999963, -0.009799999999999975, -0.014599999999999946]\n",
      "tensor([[0.4727]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.026000000000000023, 0.007599999999999996, 0.0045999999999999375]\n",
      "tensor([[0.3029]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003400000000000014, -0.0041999999999999815, -0.004999999999999949]\n",
      "tensor([[0.5998]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028200000000000003, 0.030799999999999994, 0.03420000000000001]\n",
      "tensor([[0.4617]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.027800000000000047, 0.006999999999999951, 0.011800000000000033]\n",
      "tensor([[0.4481]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012199999999999989, 0.010199999999999987, 0.028799999999999992]\n",
      "tensor([[0.2834]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015600000000000058, 0.027200000000000057, 0.0010000000000000564]\n",
      "tensor([[0.5274]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016000000000000014, -0.0015999999999999903, -0.008000000000000007]\n",
      "tensor([[0.3853]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008000000000000007, 0.00500000000000006, 0.015000000000000069]\n",
      "tensor([[0.6774]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01720000000000005, -0.003400000000000014, -0.0126]\n",
      "tensor([[0.3530]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006599999999999995, 0.007800000000000029, 0.009600000000000053]\n",
      "tensor([[0.5403]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.046999999999999986, 0.019600000000000006, 0.032999999999999974]\n",
      "tensor([[0.4946]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018799999999999983, 0.021399999999999975, 0.009599999999999942]\n",
      "tensor([[0.5290]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009800000000000031, -0.02020000000000005, 0.008799999999999919]\n",
      "tensor([[0.4298]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008600000000000052, -0.008000000000000007, 0.01700000000000007]\n",
      "tensor([[0.1639]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019799999999999818, 0.005199999999999871, 0.007599999999999829]\n",
      "tensor([[0.5364]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010199999999999987, -0.02079999999999993, -0.0005999999999999339]\n",
      "tensor([[0.1373]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02200000000000002, 0.00019999999999997797, 0.008800000000000141]\n",
      "tensor([[0.4164]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0018000000000000238, 0.005800000000000027, -0.0023999999999999577]\n",
      "tensor([[0.6975]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006199999999999983, 0.012399999999999967, 0.012199999999999989]\n",
      "tensor([[0.3826]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.017399999999999916, 0.010399999999999965]\n",
      "tensor([[0.6658]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0041999999999999815, -0.008599999999999997, -0.004999999999999949]\n",
      "tensor([[0.4953]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021799999999999986, 0.037400000000000044, 0.048800000000000066]\n",
      "tensor([[0.4328]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007000000000000062, -0.006400000000000017, 0.00040000000000006697]\n",
      "tensor([[0.5857]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018399999999999972, 0.008199999999999985, 0.016599999999999948]\n",
      "tensor([[0.4878]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010999999999999954, 0.0005999999999999339, 0.02279999999999993]\n",
      "tensor([[0.5655]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015600000000000003, 0.003400000000000014, 0.012599999999999945]\n",
      "tensor([[0.5943]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0006000000000001005, -0.013200000000000045, 0.00979999999999992]\n",
      "tensor([[0.2878]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008800000000000086, 0.00500000000000006, 0.008600000000000108]\n",
      "tensor([[0.1936]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0034000000000000696, -0.0038000000000000256, 0.0038000000000000256]\n",
      "tensor([[0.3517]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0014000000000000679, 0.007599999999999996, -0.005200000000000038]\n",
      "tensor([[0.5208]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00759999999999994, 0.002799999999999969, 0.0024000000000000132]\n",
      "tensor([[0.6634]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009800000000000031, 0.015600000000000058, 0.013000000000000067]\n",
      "tensor([[0.4013]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01639999999999997, 0.011800000000000033, 0.006400000000000017]\n",
      "tensor([[0.6797]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013999999999999957, 0.0023999999999999577, -0.00539999999999996]\n",
      "tensor([[0.3531]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009999999999999953, 0.006800000000000028, 0.0116]\n",
      "tensor([[0.3381]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005799999999999916, -0.003199999999999925, -0.017799999999999927]\n",
      "tensor([[0.4527]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005800000000000027, 0.003000000000000058, -0.002999999999999947]\n",
      "tensor([[0.3992]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007400000000000018, -0.006599999999999995, 0.0038000000000000256]\n",
      "tensor([[0.5123]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0014000000000000679, -0.01139999999999991, -0.008000000000000007]\n",
      "tensor([[0.7166]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.015200000000000047, 0.0018000000000000238, -0.007800000000000029]\n",
      "tensor([[0.6008]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009800000000000031, -0.008999999999999952, 0.005400000000000016]\n",
      "tensor([[0.3169]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023400000000000032, 0.03620000000000001, 0.022600000000000064]\n",
      "tensor([[0.4341]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02200000000000002, -0.010199999999999987, 0.014999999999999958]\n",
      "tensor([[0.5370]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01679999999999998, 0.012400000000000022, 0.010200000000000042]\n",
      "tensor([[0.3260]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0038000000000000256, 0.023400000000000032, 0.009200000000000041]\n",
      "tensor([[0.5383]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03420000000000001, 0.027400000000000035, 0.02839999999999998]\n",
      "tensor([[0.4313]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013799999999999979, 0.008000000000000007, -0.00500000000000006]\n",
      "tensor([[0.3119]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005599999999999938, -0.023799999999999932, 0.007400000000000018]\n",
      "tensor([[0.6475]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020199999999999996, 0.030399999999999983, 0.01720000000000005]\n",
      "tensor([[0.4046]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00040000000000006697, 0.01660000000000006, 0.013799999999999979]\n",
      "tensor([[0.3340]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028800000000000048, 0.012199999999999989, 0.005599999999999994]\n",
      "tensor([[0.2949]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016600000000000004, 0.02479999999999999, 0.020600000000000007]\n",
      "tensor([[0.7090]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005599999999999994, -0.0009999999999999454, -0.005199999999999982]\n",
      "tensor([[0.4446]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000023, 0.007800000000000029, 0.011200000000000043]\n",
      "tensor([[0.1639]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0029999999999998916, 0.012799999999999923, 0.008999999999999897]\n",
      "tensor([[0.3684]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.04100000000000009, 0.02900000000000008, 0.02440000000000009]\n",
      "tensor([[0.3857]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0021999999999999797, 0.007199999999999929, 0.020600000000000007]\n",
      "tensor([[0.5988]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008599999999999997, 0.005800000000000027, 0.005400000000000016]\n",
      "tensor([[0.3930]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01899999999999996, 0.01200000000000001, 0.0023999999999999577]\n",
      "tensor([[0.4929]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0012000000000000344, 0.012199999999999989, 0.012999999999999956]\n",
      "tensor([[0.3482]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.017199999999999938, -0.00759999999999994, 0.0]\n",
      "tensor([[0.4373]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003000000000000058, 0.006199999999999983, 0.0047999999999999154]\n",
      "tensor([[0.4241]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009199999999999986, 0.00820000000000004, -0.02639999999999998]\n",
      "tensor([[0.2049]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0038000000000000256, 0.0023999999999999577, 0.0050000000000001155]\n",
      "tensor([[0.5583]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0034000000000000696, 0.003400000000000014, -0.009400000000000075]\n",
      "tensor([[0.1917]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01200000000000001, -0.00019999999999997797, -0.0014000000000000679]\n",
      "tensor([[0.6225]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006799999999999973, 0.0, 0.006399999999999961]\n",
      "tensor([[0.4843]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02080000000000004, 0.025400000000000034, 0.029400000000000037]\n",
      "tensor([[0.5176]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.0012000000000000344, -0.005399999999999905]\n",
      "tensor([[0.4719]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01920000000000005, 0.01760000000000006, 0.023000000000000076]\n",
      "tensor([[0.4171]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007799999999999974, 0.0047999999999999154, 0.01579999999999998]\n",
      "tensor([[0.4234]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.009200000000000041, 0.002799999999999969]\n",
      "tensor([[0.2300]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012800000000000145, 0.0262, 0.011400000000000077]\n",
      "tensor([[0.3713]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.017799999999999983, -0.00040000000000001146]\n",
      "tensor([[0.5852]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004600000000000104, -0.007000000000000062, -0.012800000000000089]\n",
      "tensor([[0.5437]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008799999999999975, -0.00759999999999994, -0.014600000000000002]\n",
      "tensor([[0.6750]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0010000000000000564, -0.0008000000000000784, 0.0024000000000000132]\n",
      "tensor([[0.5891]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0014000000000000123, -0.030200000000000005, -0.01979999999999993]\n",
      "tensor([[0.6307]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01539999999999997, 0.014999999999999958, 0.027399999999999924]\n",
      "tensor([[0.5621]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014399999999999968, 0.01979999999999993, -0.0021999999999999797]\n",
      "tensor([[0.5776]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01200000000000001, 0.003400000000000014, 0.00019999999999997797]\n",
      "tensor([[0.7179]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004800000000000082, -0.008799999999999919, 0.014000000000000012]\n",
      "tensor([[0.1369]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0014000000000000679, 0.010399999999999965, 0.0005999999999999339]\n",
      "tensor([[0.6767]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017400000000000027, -0.004799999999999971, 0.013000000000000012]\n",
      "Training [70%]\tLoss: -0.6101\n",
      "tensor([[0.2944]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020999999999999963, 0.030999999999999972, 0.02679999999999999]\n",
      "tensor([[0.3821]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02400000000000002, -0.008000000000000007, -0.003400000000000014]\n",
      "tensor([[0.5127]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02839999999999998, 0.02699999999999997, -0.009200000000000041]\n",
      "tensor([[0.3757]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01959999999999995, 0.007399999999999962, 0.030600000000000016]\n",
      "tensor([[0.3372]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0013999999999999013, -0.014600000000000057, -0.018200000000000105]\n",
      "tensor([[0.4916]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.04239999999999999, -0.05540000000000006, -0.011400000000000021]\n",
      "tensor([[0.3232]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.03319999999999995, 0.011599999999999944]\n",
      "tensor([[0.2382]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0027999999999999137, 0.012199999999999989, 0.008000000000000007]\n",
      "tensor([[0.6996]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006199999999999983, -0.0040000000000000036, 0.015200000000000047]\n",
      "tensor([[0.4153]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0023999999999999577, 0.015600000000000003, -0.0023999999999999577]\n",
      "tensor([[0.3992]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004799999999999971, -0.006799999999999973, 0.015600000000000003]\n",
      "tensor([[0.6051]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006000000000000005, -0.01200000000000001, -0.016000000000000014]\n",
      "tensor([[0.5276]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009599999999999997, 0.009200000000000041, 0.01920000000000005]\n",
      "tensor([[0.5436]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01479999999999998, -0.006799999999999973, -0.0016000000000000458]\n",
      "tensor([[0.7454]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0009999999999999454, -0.008599999999999997, -0.009399999999999908]\n",
      "tensor([[0.7629]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.026599999999999957, 0.02839999999999998, 0.02200000000000002]\n",
      "tensor([[0.3187]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.012199999999999989, 0.006599999999999995, 0.0016000000000000458]\n",
      "tensor([[0.3300]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0020000000000000018, -0.023599999999999954, 0.00019999999999997797]\n",
      "tensor([[0.5342]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004400000000000015, -0.008399999999999963, -0.008599999999999997]\n",
      "tensor([[0.3308]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003200000000000036, 0.030399999999999983, 0.01419999999999999]\n",
      "tensor([[0.4805]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009000000000000064, 0.0038000000000000256, 0.010799999999999976]\n",
      "tensor([[0.1344]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.001000000000000112, -0.0015999999999998238, 0.011400000000000077]\n",
      "tensor([[0.4690]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.020399999999999974, -0.021999999999999964, -0.009399999999999908]\n",
      "tensor([[0.6571]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01639999999999997, 0.01859999999999995, 0.0020000000000000018]\n",
      "tensor([[0.2687]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00280000000000008, 0.003199999999999925, -0.0012000000000000344]\n",
      "tensor([[0.3351]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007000000000000062, -0.010199999999999987, 0.012800000000000089]\n",
      "tensor([[0.5522]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019399999999999917, 0.02859999999999996, 0.010399999999999965]\n",
      "tensor([[0.6346]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021599999999999897, 0.0040000000000000036, 0.0015999999999999348]\n",
      "tensor([[0.2960]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02260000000000001, 0.013399999999999967, 0.01739999999999997]\n",
      "tensor([[0.5619]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02560000000000001, 0.005200000000000038, 0.025400000000000034]\n",
      "tensor([[0.3847]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014999999999999958, 0.03899999999999998, 0.023599999999999954]\n",
      "tensor([[0.4601]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01200000000000001, 0.003400000000000014, 0.0015999999999999903]\n",
      "tensor([[0.6759]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0010000000000000564, 0.01200000000000001, 0.0024000000000000687]\n",
      "tensor([[0.3427]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012199999999999989, 0.010799999999999976, -0.007600000000000051]\n",
      "tensor([[0.6533]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025600000000000067, 0.025600000000000067, 0.018399999999999972]\n",
      "tensor([[0.4047]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007000000000000062, 0.01200000000000001, 0.008200000000000096]\n",
      "tensor([[0.5112]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0126, 0.023200000000000054, 0.020799999999999985]\n",
      "tensor([[0.3751]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005400000000000071, 0.007400000000000073, 0.011600000000000055]\n",
      "tensor([[0.1976]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006399999999999961, 0.012599999999999945, -0.006599999999999939]\n",
      "tensor([[0.5279]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.011200000000000043, 0.013599999999999945, -0.007400000000000018]\n",
      "tensor([[0.5279]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03119999999999995, 0.02240000000000003, 0.020600000000000007]\n",
      "tensor([[0.2576]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0013999999999999013, 0.002999999999999947, 0.009599999999999942]\n",
      "tensor([[0.2400]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0040000000000000036, 0.006399999999999961, 0.0038000000000000256]\n",
      "tensor([[0.5966]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005400000000000071, 0.0040000000000000036, -0.015000000000000069]\n",
      "tensor([[0.4646]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006399999999999961, 0.00919999999999993, -0.0036000000000000476]\n",
      "tensor([[0.5725]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020999999999999963, 0.0358, 0.02140000000000003]\n",
      "tensor([[0.5397]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016000000000000014, 0.013000000000000067, 0.0021999999999999797]\n",
      "tensor([[0.6271]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.011800000000000033, -0.016000000000000014, 0.010399999999999965]\n",
      "tensor([[0.6060]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010999999999999954, -0.012999999999999956, -0.006999999999999951]\n",
      "tensor([[0.2680]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00379999999999997, 0.02339999999999992, 0.01579999999999998]\n",
      "tensor([[0.4827]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0012000000000000899, 0.0043999999999999595, -0.009400000000000075]\n",
      "tensor([[0.5023]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020199999999999996, 0.03160000000000002, 0.030200000000000005]\n",
      "tensor([[0.6057]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007799999999999974, 0.015600000000000003, 0.01079999999999992]\n",
      "tensor([[0.3802]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025000000000000078, 0.01760000000000006, 0.016400000000000026]\n",
      "tensor([[0.4619]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006199999999999983, -0.011799999999999977, -0.0009999999999999454]\n",
      "tensor([[0.4816]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005199999999999982, 0.004599999999999993, -0.00660000000000005]\n",
      "tensor([[0.4117]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008400000000000074, -0.015399999999999914, 0.00660000000000005]\n",
      "tensor([[0.1423]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.026000000000000023, 0.008199999999999985]\n",
      "tensor([[0.5403]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010000000000000009, 0.02400000000000002, 0.0018000000000000238]\n",
      "tensor([[0.4827]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0, -0.0005999999999999894, -0.020199999999999996]\n",
      "tensor([[0.2282]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007200000000000095, 0.012800000000000145, 0.008199999999999985]\n",
      "tensor([[0.2616]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.000200000000000089, -0.010800000000000087, -0.023799999999999988]\n",
      "tensor([[0.6953]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007199999999999984, 0.01959999999999995, 0.037799999999999945]\n",
      "tensor([[0.7140]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004599999999999993, -0.01980000000000004, -0.015599999999999947]\n",
      "tensor([[0.4102]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006199999999999983, 0.0398, 0.02859999999999996]\n",
      "tensor([[0.4766]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018399999999999972, 0.030200000000000005, 0.008000000000000007]\n",
      "tensor([[0.4615]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014799999999999924, 0.01419999999999999, 0.028999999999999915]\n",
      "tensor([[0.3596]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0038000000000000256, 0.0040000000000000036, -0.0043999999999999595]\n",
      "tensor([[0.2336]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014799999999999924, 0.0036000000000000476, 0.0013999999999998458]\n",
      "tensor([[0.5305]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.026599999999999957, 0.02100000000000002, 0.012399999999999967]\n",
      "tensor([[0.5669]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009599999999999942, 0.0014000000000000123, -0.020999999999999963]\n",
      "tensor([[0.7390]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008399999999999963, 0.008000000000000007, 0.004599999999999993]\n",
      "tensor([[0.5035]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011800000000000033, 0.043800000000000006, 0.021600000000000008]\n",
      "tensor([[0.6545]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0, 0.0010000000000000564, 0.013999999999999957]\n",
      "tensor([[0.8381]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.0008000000000001339, 0.0016000000000000458]\n",
      "tensor([[0.4889]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017600000000000005, 0.0007999999999999674, 0.008999999999999952]\n",
      "tensor([[0.2049]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007800000000000029, 0.0048000000000001375, 0.0038000000000000256]\n",
      "tensor([[0.3927]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020399999999999974, 0.008199999999999985, 0.010799999999999976]\n",
      "tensor([[0.5087]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0015999999999999903, 0.01699999999999996, -0.005200000000000038]\n",
      "tensor([[0.3265]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0024000000000000132, -0.005800000000000027, -0.0010000000000000564]\n",
      "tensor([[0.3191]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00280000000000008, 0.005399999999999905, -0.018400000000000083]\n",
      "tensor([[0.1732]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0036000000000000476, 0.008799999999999919, -0.0020000000000000018]\n",
      "tensor([[0.3678]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018799999999999928, 0.007400000000000018, 0.019399999999999917]\n",
      "tensor([[0.5926]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004800000000000082, 0.0009999999999999454, -0.01200000000000001]\n",
      "tensor([[0.5051]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00019999999999997797, 0.010199999999999987, 0.0021999999999999797]\n",
      "tensor([[0.5270]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00019999999999997797, 0.018199999999999994, 0.01799999999999996]\n",
      "tensor([[0.5270]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0235999999999999, 0.019600000000000006, -0.004200000000000037]\n",
      "tensor([[0.3254]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006399999999999961, -0.0010000000000000564, 0.02139999999999992]\n",
      "tensor([[0.6349]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010000000000000009, 0.006199999999999983, -0.012400000000000022]\n",
      "tensor([[0.4578]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007799999999999974, 0.011000000000000065, 0.011600000000000055]\n",
      "tensor([[0.6129]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0009999999999999454, -0.005800000000000027, -0.023200000000000054]\n",
      "tensor([[0.3948]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02479999999999999, 0.016400000000000026, 0.013599999999999945]\n",
      "tensor([[0.3409]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006799999999999917, 0.021600000000000064, 0.019400000000000084]\n",
      "tensor([[0.4513]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03979999999999995, 0.047199999999999964, 0.030400000000000038]\n",
      "tensor([[0.1229]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005600000000000049, 0.010000000000000009, 0.011400000000000077]\n",
      "tensor([[0.2480]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0012000000000000899, -0.0005999999999999339, 0.009600000000000053]\n",
      "tensor([[0.7077]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010000000000000009, -0.021600000000000008, -0.023400000000000032]\n",
      "tensor([[0.3087]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005599999999999994, 0.013400000000000079, 0.004200000000000037]\n",
      "tensor([[0.7086]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028000000000000025, 0.02579999999999999, 0.020399999999999974]\n",
      "tensor([[0.5595]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0020000000000000018, 0.00019999999999997797, 0.0014000000000000123]\n",
      "Training [75%]\tLoss: -0.6143\n",
      "tensor([[0.4372]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0009999999999999454, 0.016400000000000026, 0.020000000000000018]\n",
      "tensor([[0.3378]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009400000000000075, -0.0018000000000000238, -0.006999999999999951]\n",
      "tensor([[0.5055]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022600000000000064, 0.034600000000000075, 0.0242]\n",
      "tensor([[0.5370]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02460000000000001, 0.025800000000000045, 0.016000000000000014]\n",
      "tensor([[0.3913]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009399999999999908, -0.007199999999999929, -0.012999999999999956]\n",
      "tensor([[0.5734]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017600000000000005, 0.009799999999999975, 0.006799999999999917]\n",
      "tensor([[0.3801]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007000000000000062, 0.01760000000000006, 0.020600000000000007]\n",
      "tensor([[0.2713]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017800000000000038, -0.0020000000000000018, 0.01920000000000005]\n",
      "tensor([[0.7499]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010599999999999943, 0.01079999999999992, 0.0018000000000000238]\n",
      "tensor([[0.4154]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017400000000000027, 0.012399999999999967, 0.023400000000000032]\n",
      "tensor([[0.6921]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.023799999999999988, -0.015600000000000003, 0.0011999999999999234]\n",
      "tensor([[0.4451]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03739999999999993, 0.030799999999999994, 0.0235999999999999]\n",
      "tensor([[0.6986]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008999999999999952, 0.006599999999999995, 0.011200000000000043]\n",
      "tensor([[0.5723]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00039999999999995595, -0.019999999999999962, -0.014399999999999968]\n",
      "tensor([[0.6360]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017799999999999983, -0.015800000000000036, 0.01419999999999999]\n",
      "tensor([[0.3205]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021799999999999986, 0.013600000000000001, 0.03600000000000003]\n",
      "tensor([[0.2289]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008799999999999919, 0.011800000000000033, 0.0]\n",
      "tensor([[0.5631]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00720000000000004, -0.00040000000000006697, -0.013000000000000067]\n",
      "tensor([[0.6375]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003000000000000058, -0.010000000000000009, 0.0024000000000000687]\n",
      "tensor([[0.7214]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02139999999999992, 0.006000000000000005, 0.02959999999999996]\n",
      "tensor([[0.3878]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005199999999999982, 0.00820000000000004, 0.012400000000000022]\n",
      "tensor([[0.6716]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0018000000000000238, 0.016400000000000026, -0.005599999999999994]\n",
      "tensor([[0.4209]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006999999999999951, 0.010399999999999965, 0.012199999999999989]\n",
      "tensor([[0.1919]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014600000000000168, 0.0048000000000001375, 0.0038000000000000256]\n",
      "tensor([[0.4820]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0015999999999999903, -0.005799999999999972, 0.013200000000000045]\n",
      "tensor([[0.6461]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011800000000000033, 0.006999999999999951, 0.005400000000000016]\n",
      "tensor([[0.1125]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0035999999999998256, 0.015799999999999814, 0.009799999999999809]\n",
      "tensor([[0.5166]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025400000000000034, 0.028200000000000003, 0.019000000000000072]\n",
      "tensor([[0.3505]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00019999999999997797, -0.003200000000000036, -0.0048000000000000265]\n",
      "tensor([[0.5868]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006199999999999983, -0.00019999999999997797, 0.01700000000000007]\n",
      "tensor([[0.3392]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0008000000000000784, 0.0012000000000000344, -0.0037999999999999146]\n",
      "tensor([[0.5578]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012600000000000056, 0.029400000000000037, 0.006000000000000005]\n",
      "tensor([[0.5189]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013399999999999967, 0.004799999999999971, 0.01040000000000002]\n",
      "tensor([[0.4079]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03200000000000003, 0.015799999999999925, 0.009399999999999964]\n",
      "tensor([[0.7134]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011599999999999944, 0.016000000000000014, -0.010000000000000009]\n",
      "tensor([[0.6114]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004799999999999971, -0.022400000000000087, -0.0010000000000000564]\n",
      "tensor([[0.2935]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010199999999999987, -0.008000000000000007, -0.0040000000000000036]\n",
      "tensor([[0.5320]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.04460000000000003, 0.0016000000000000458, 0.016400000000000026]\n",
      "tensor([[0.3828]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02959999999999996, 0.008400000000000019, 0.022799999999999987]\n",
      "tensor([[0.1864]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0020000000000000018, -0.001000000000000112, 0.0036000000000000476]\n",
      "tensor([[0.5289]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01660000000000006, 0.017199999999999938, -0.010399999999999965]\n",
      "tensor([[0.7843]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007400000000000073, 0.01200000000000001, -0.0047999999999999154]\n",
      "tensor([[0.2331]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0018000000000000238, 0.02200000000000002, 0.014000000000000012]\n",
      "tensor([[0.6894]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0025999999999999357, 0.0043999999999999595, -0.005600000000000049]\n",
      "tensor([[0.6063]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011200000000000043, 0.014600000000000057, 0.01440000000000008]\n",
      "tensor([[0.2627]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008600000000000052, -0.007400000000000018, 0.014399999999999968]\n",
      "tensor([[0.1375]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.0046000000000001595, 0.02080000000000015]\n",
      "tensor([[0.3971]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010999999999999954, 0.022199999999999998, 0.006399999999999961]\n",
      "tensor([[0.8712]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006000000000000005, -0.0025999999999999357, 0.00019999999999997797]\n",
      "tensor([[0.4308]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006800000000000028, 0.016000000000000014, 0.016000000000000014]\n",
      "tensor([[0.3274]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013600000000000001, 0.016999999999999904, 0.03119999999999995]\n",
      "tensor([[0.4599]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018000000000000016, 0.030600000000000016, -0.0009999999999999454]\n",
      "tensor([[0.2662]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.023600000000000065, -0.008199999999999985, -0.0040000000000000036]\n",
      "tensor([[0.1022]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0012000000000000899, -0.010599999999999943, 0.014600000000000168]\n",
      "tensor([[0.3946]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004999999999999949, -0.015399999999999914, -0.014399999999999968]\n",
      "tensor([[0.2951]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006000000000000005, -0.0012000000000000344, 0.016400000000000026]\n",
      "tensor([[0.3880]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007400000000000018, 0.008999999999999952, 0.02059999999999995]\n",
      "tensor([[0.4586]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007400000000000018, -0.005600000000000049, -0.0262]\n",
      "tensor([[0.6998]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00820000000000004, 0.005800000000000027, 0.004200000000000037]\n",
      "tensor([[0.4868]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, 0.021600000000000008, 0.03420000000000001]\n",
      "tensor([[0.6169]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01940000000000003, 0.00720000000000004, 0.006199999999999983]\n",
      "tensor([[0.1802]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006399999999999961, 0.005199999999999871, -0.0014000000000000679]\n",
      "tensor([[0.3422]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016000000000000014, 0.0020000000000000018, 0.013400000000000023]\n",
      "tensor([[0.5621]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014399999999999968, 0.01479999999999998, 0.022199999999999998]\n",
      "tensor([[0.3366]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.002999999999999947, 0.013199999999999934, -0.005400000000000071]\n",
      "tensor([[0.5379]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003200000000000036, 0.020600000000000007, 0.032200000000000006]\n",
      "tensor([[0.4697]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00040000000000001146, -0.018399999999999972, -0.010000000000000009]\n",
      "tensor([[0.5101]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021600000000000008, 0.018000000000000016, 0.010000000000000009]\n",
      "tensor([[0.5097]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00979999999999992, 0.0041999999999999815, 0.006000000000000005]\n",
      "tensor([[0.2301]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01200000000000001, 0.0050000000000001155, -0.0040000000000000036]\n",
      "tensor([[0.5539]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011800000000000033, 0.027600000000000013, -0.010199999999999987]\n",
      "tensor([[0.4172]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.006599999999999939, 0.012799999999999923]\n",
      "tensor([[0.6578]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019399999999999917, 0.015399999999999914, 0.008799999999999975]\n",
      "tensor([[0.6433]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.002599999999999991, 0.013800000000000034, 0.00020000000000003348]\n",
      "tensor([[0.5931]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02779999999999999, 0.033999999999999975, 0.024800000000000044]\n",
      "tensor([[0.4222]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.002599999999999991, 0.0017999999999999683, 0.027399999999999924]\n",
      "tensor([[0.2537]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.024999999999999967, 0.022999999999999965, 0.0024000000000000132]\n",
      "tensor([[0.4178]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005599999999999994, -0.02679999999999999, -0.025199999999999945]\n",
      "tensor([[0.3539]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011600000000000055, 0.007800000000000029, 0.011200000000000043]\n",
      "tensor([[0.4199]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006800000000000084, -0.0046000000000000485, -0.017600000000000005]\n",
      "tensor([[0.5860]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03480000000000005, 0.022600000000000064, 0.02799999999999997]\n",
      "tensor([[0.5239]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0012000000000000344, -0.005400000000000016, -0.0008000000000000229]\n",
      "tensor([[0.4800]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000079, 0.02200000000000002, 0.0020000000000000018]\n",
      "tensor([[0.6494]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003199999999999925, -0.026799999999999935, -0.013600000000000001]\n",
      "tensor([[0.2229]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0038000000000000256, -0.014599999999999946, -0.011199999999999877]\n",
      "tensor([[0.5423]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01940000000000003, 0.018000000000000016, 0.002799999999999969]\n",
      "tensor([[0.6520]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003599999999999992, -0.0024000000000000132, 0.0015999999999999903]\n",
      "tensor([[0.2684]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021600000000000008, -0.01699999999999996, -0.0126]\n",
      "tensor([[0.2832]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0012000000000000344, -0.005400000000000016, 0.005599999999999994]\n",
      "tensor([[0.5115]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0011999999999999234, -0.025399999999999923, 0.0021999999999999797]\n",
      "tensor([[0.3806]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0015999999999999348, 0.014999999999999958, 0.010599999999999998]\n",
      "tensor([[0.1865]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010000000000000009, 0.008199999999999985, 0.007200000000000095]\n",
      "tensor([[0.6847]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014400000000000024, 0.013000000000000067, 0.021600000000000064]\n",
      "tensor([[0.4374]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0015999999999999903, -0.0021999999999999797, 0.006999999999999951]\n",
      "tensor([[0.3549]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0014000000000000679, -0.012999999999999956, 0.015200000000000047]\n",
      "tensor([[0.5434]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.017600000000000005, -0.02180000000000004, -0.02899999999999997]\n",
      "tensor([[0.6037]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020399999999999974, 0.027600000000000013, 0.012999999999999956]\n",
      "tensor([[0.4800]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.025199999999999945, -0.006000000000000005, 0.010599999999999998]\n",
      "tensor([[0.5975]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.022800000000000042, 0.004599999999999993, -0.02779999999999999]\n",
      "tensor([[0.4689]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018400000000000027, 0.010000000000000009, 0.0126]\n",
      "Training [80%]\tLoss: -0.6208\n",
      "tensor([[0.4447]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.027400000000000035, 0.018199999999999994, 0.025400000000000034]\n",
      "tensor([[0.5416]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005799999999999972, -0.004999999999999949, -0.005800000000000027]\n",
      "tensor([[0.5806]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01899999999999996, 0.01980000000000004, 0.014999999999999958]\n",
      "tensor([[0.4524]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005799999999999972, 0.0025999999999999357, -0.0026000000000001022]\n",
      "tensor([[0.4615]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004999999999999949, -0.003000000000000058, 0.009799999999999975]\n",
      "tensor([[0.3099]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013600000000000001, 0.0008000000000000784, 0.01880000000000004]\n",
      "tensor([[0.5753]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.021799999999999986, -0.015200000000000047, 0.0035999999999999366]\n",
      "tensor([[0.5629]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0018000000000000238, -0.01040000000000002, -0.0005999999999999894]\n",
      "tensor([[0.5312]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005800000000000027, 0.010999999999999954, 0.002799999999999969]\n",
      "tensor([[0.3249]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00759999999999994, -0.016199999999999992, -0.012200000000000044]\n",
      "tensor([[0.7289]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011600000000000055, 0.01479999999999998, 0.009200000000000041]\n",
      "tensor([[0.3698]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0040000000000000036, -0.012800000000000089, 0.006599999999999939]\n",
      "tensor([[0.3846]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02839999999999998, 0.00979999999999992, 0.054400000000000004]\n",
      "tensor([[0.2367]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00019999999999997797, -0.005800000000000027, 0.01419999999999999]\n",
      "tensor([[0.6415]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0048000000000000265, -0.004799999999999971, 0.003599999999999992]\n",
      "tensor([[0.3741]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007400000000000018, 0.011600000000000055, 0.027200000000000057]\n",
      "tensor([[0.6380]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008599999999999941, -0.007000000000000062, 0.0043999999999999595]\n",
      "tensor([[0.7554]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017400000000000082, -0.009399999999999853, 0.0016000000000000458]\n",
      "tensor([[0.7718]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.009199999999999875, 0.02519999999999989]\n",
      "tensor([[0.4925]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00040000000000006697, 0.029399999999999926, 0.02859999999999996]\n",
      "tensor([[0.3026]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008799999999999919, 0.0016000000000000458, -0.03079999999999994]\n",
      "tensor([[0.6740]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028799999999999992, 0.0035999999999999366, 0.028799999999999992]\n",
      "tensor([[0.4922]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000023, 0.023999999999999966, 0.019600000000000006]\n",
      "tensor([[0.6524]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.002599999999999991, -0.002999999999999947, -0.002999999999999947]\n",
      "tensor([[0.5212]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022999999999999965, 0.0005999999999999894, 0.0014000000000000123]\n",
      "tensor([[0.5739]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.012999999999999956, 0.0116, 0.0020000000000000018]\n",
      "tensor([[0.1428]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0026000000000001577, -0.006199999999999983, 0.00019999999999997797]\n",
      "tensor([[0.7537]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007400000000000073, 0.0007999999999999119, 0.011199999999999877]\n",
      "tensor([[0.3400]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0116, 0.012800000000000034, 0.0026000000000000467]\n",
      "tensor([[0.2505]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.019799999999999873, -0.019799999999999873, 0.0020000000000000018]\n",
      "tensor([[0.3183]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0235999999999999, 0.023199999999999943, 0.009599999999999997]\n",
      "tensor([[0.6149]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0016000000000000458, -0.008000000000000007, -0.0016000000000000458]\n",
      "tensor([[0.3097]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01540000000000008, 0.015800000000000036, 0.01760000000000006]\n",
      "tensor([[0.4333]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01899999999999996, 0.008799999999999919, 0.006000000000000005]\n",
      "tensor([[0.4645]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.016000000000000014, -0.008800000000000086, -0.016000000000000014]\n",
      "tensor([[0.3156]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009000000000000064, 0.01980000000000004, 0.015200000000000047]\n",
      "tensor([[0.5034]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003000000000000058, -0.013799999999999923, -0.04099999999999998]\n",
      "tensor([[0.7812]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0016000000000000458, 0.0009999999999998899, -0.011800000000000033]\n",
      "tensor([[0.3453]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019399999999999917, 0.020999999999999963, -0.011200000000000043]\n",
      "tensor([[0.6754]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017400000000000027, 0.0005999999999999894, -0.0038000000000000256]\n",
      "tensor([[0.4780]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004200000000000037, 0.015600000000000058, 0.01419999999999999]\n",
      "tensor([[0.2848]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0012000000000000344, -0.00040000000000006697, -0.0042000000000000925]\n",
      "tensor([[0.4352]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00040000000000001146, -0.007400000000000018, 0.006799999999999973]\n",
      "tensor([[0.4780]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.04660000000000003, 0.023200000000000054, 0.022799999999999987]\n",
      "tensor([[0.4475]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008599999999999941, -0.0038000000000000256, 0.02699999999999997]\n",
      "tensor([[0.2566]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00759999999999994, 0.015799999999999925, 0.00759999999999994]\n",
      "tensor([[0.2241]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02180000000000004, 0.022399999999999975, 0.022199999999999998]\n",
      "tensor([[0.3268]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02180000000000004, 0.020600000000000007, 0.00820000000000004]\n",
      "tensor([[0.6506]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018199999999999994, 0.02400000000000002, 0.018000000000000016]\n",
      "tensor([[0.6234]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.018199999999999994, 0.008400000000000074, -0.00539999999999996]\n",
      "tensor([[0.5672]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004599999999999993, -0.020399999999999974, -0.012800000000000034]\n",
      "tensor([[0.7963]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006399999999999961, 0.01519999999999988, 0.006999999999999895]\n",
      "tensor([[0.1731]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007200000000000095, -0.00039999999999995595, -0.013800000000000034]\n",
      "tensor([[0.2395]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0018000000000000238, 0.028199999999999947, 0.0043999999999999595]\n",
      "tensor([[0.9089]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0011999999999998678, -0.007800000000000029, -0.012600000000000167]\n",
      "tensor([[0.6330]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008399999999999963, -0.006399999999999961, -0.01760000000000006]\n",
      "tensor([[0.1271]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008599999999999941, 0.0038000000000000256, 0.013400000000000079]\n",
      "tensor([[0.2275]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016599999999999948, -0.01760000000000006, -0.019000000000000128]\n",
      "tensor([[0.2885]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.014799999999999924, -0.0015999999999999903, -0.012599999999999945]\n",
      "tensor([[0.2825]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03160000000000007, 0.02460000000000001, 0.015800000000000036]\n",
      "tensor([[0.5086]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02119999999999994, 0.02399999999999991, 0.022199999999999998]\n",
      "tensor([[0.1792]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01419999999999999, 0.013800000000000034, 0.0016000000000000458]\n",
      "tensor([[0.1770]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.016800000000000148, 0.0029999999999998916, -0.02100000000000013]\n",
      "tensor([[0.6016]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008599999999999941, 0.012199999999999989, 0.01079999999999992]\n",
      "tensor([[0.6840]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013599999999999945, 0.012999999999999956, 0.030200000000000005]\n",
      "tensor([[0.3540]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009200000000000041, 0.008199999999999985, -0.012399999999999967]\n",
      "tensor([[0.3543]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022600000000000064, 0.025200000000000056, 0.013400000000000023]\n",
      "tensor([[0.7674]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0036000000000000476, -0.00019999999999997797, -0.009399999999999853]\n",
      "tensor([[0.4799]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003400000000000014, 0.020999999999999963, 0.006399999999999961]\n",
      "tensor([[0.7365]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022999999999999965, 0.010799999999999976, 0.00019999999999997797]\n",
      "tensor([[0.4381]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01759999999999995, 0.01979999999999993, 0.003199999999999925]\n",
      "tensor([[0.1624]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007199999999999873, -0.0041999999999999815, -0.014999999999999902]\n",
      "tensor([[0.1576]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008600000000000163, 0.006400000000000183, 0.0040000000000000036]\n",
      "tensor([[0.4792]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01419999999999999, -0.0013999999999999568, 0.015400000000000025]\n",
      "tensor([[0.6578]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018799999999999983, 0.01679999999999998, 0.01639999999999997]\n",
      "tensor([[0.7101]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.017799999999999927, -0.03959999999999991, -0.015399999999999914]\n",
      "tensor([[0.6202]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0126, 0.013000000000000067, -0.009999999999999953]\n",
      "tensor([[0.1399]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.030399999999999983, 0.024399999999999977, 0.019199999999999884]\n",
      "tensor([[0.4511]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019000000000000072, 0.028000000000000025, 0.02440000000000009]\n",
      "tensor([[0.6210]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0007999999999999674, 0.0041999999999999815, 0.03180000000000005]\n",
      "tensor([[0.3116]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0020000000000000018, 0.002799999999999969, 0.013000000000000067]\n",
      "tensor([[0.2884]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006000000000000005, 0.004799999999999971, 0.0018000000000000238]\n",
      "tensor([[0.6500]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011199999999999932, 0.026999999999999913, -0.00280000000000008]\n",
      "tensor([[0.5725]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010199999999999987, 0.00940000000000002, 0.005199999999999927]\n",
      "tensor([[0.3400]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021799999999999986, 0.016800000000000037, 0.012800000000000034]\n",
      "tensor([[0.5780]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007199999999999929, -0.0021999999999999797, -0.0024000000000000132]\n",
      "tensor([[0.3515]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0018000000000000238, 0.011399999999999966, 0.01040000000000002]\n",
      "tensor([[0.5232]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0005999999999999894, 0.003000000000000058, 0.0007999999999999674]\n",
      "tensor([[0.1187]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015599999999999836, 0.019199999999999884, 0.006000000000000005]\n",
      "tensor([[0.4800]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021600000000000064, 0.038000000000000034, 0.03120000000000006]\n",
      "tensor([[0.5138]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005799999999999972, 0.0242, 0.026000000000000023]\n",
      "tensor([[0.2943]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0040000000000000036, -0.002599999999999991, 0.018399999999999972]\n",
      "tensor([[0.5369]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02339999999999992, 0.02200000000000002, 0.03919999999999996]\n",
      "tensor([[0.1701]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015599999999999836, 0.0043999999999999595, -0.0023999999999999577]\n",
      "tensor([[0.2420]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010399999999999965, -0.005600000000000049, 0.008399999999999963]\n",
      "tensor([[0.4915]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006599999999999995, 0.01479999999999998, 0.022399999999999975]\n",
      "tensor([[0.6160]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015400000000000025, 0.018000000000000016, 0.018600000000000005]\n",
      "tensor([[0.4652]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.012199999999999989, -0.009999999999999898, -0.01679999999999998]\n",
      "tensor([[0.5616]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0040000000000000036, -0.01579999999999998, -0.012999999999999956]\n",
      "tensor([[0.3458]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.026599999999999957, 0.03540000000000004, 0.04800000000000004]\n",
      "Training [85%]\tLoss: -0.6410\n",
      "tensor([[0.6995]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.004799999999999971, 0.010799999999999976, 0.01639999999999997]\n",
      "tensor([[0.2041]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011800000000000033, 0.018000000000000016, 0.011800000000000033]\n",
      "tensor([[0.6609]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, 0.01419999999999999, -0.0015999999999999903]\n",
      "tensor([[0.5534]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.027600000000000013, 0.011800000000000033, 0.020000000000000018]\n",
      "tensor([[0.5515]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.04099999999999998, 0.010199999999999987, 0.010399999999999965]\n",
      "tensor([[0.2096]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02200000000000002, 0.009400000000000075, 0.02400000000000002]\n",
      "tensor([[0.7188]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.022999999999999965, -0.011800000000000033, -0.020799999999999985]\n",
      "tensor([[0.1780]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.000600000000000156, -0.01440000000000019, -0.012400000000000189]\n",
      "tensor([[0.2997]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016800000000000037, 0.02080000000000004, 0.01940000000000003]\n",
      "tensor([[0.1373]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012599999999999945, 0.0023999999999999577, 0.012599999999999945]\n",
      "tensor([[0.4472]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013400000000000023, -0.0020000000000000018, 0.00040000000000001146]\n",
      "tensor([[0.3021]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012400000000000022, 0.01200000000000001, 0.006200000000000039]\n",
      "tensor([[0.2737]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02399999999999991, 0.009999999999999898, -0.0020000000000000018]\n",
      "tensor([[0.5113]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0018000000000000238, 0.0006000000000001005, -0.002999999999999947]\n",
      "tensor([[0.4230]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01419999999999999, 0.01419999999999999, -0.009200000000000041]\n",
      "tensor([[0.2090]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006600000000000161, 0.005400000000000071, 0.0044000000000001815]\n",
      "tensor([[0.2782]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004799999999999971, 0.0036000000000000476, 0.0023999999999999577]\n",
      "tensor([[0.4590]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01959999999999995, 0.00040000000000006697, 0.009000000000000064]\n",
      "tensor([[0.6551]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019399999999999917, 0.02119999999999994, 0.020199999999999996]\n",
      "tensor([[0.4741]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.018000000000000016, 0.00660000000000005, 0.00720000000000004]\n",
      "tensor([[0.6636]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00759999999999994, -0.004599999999999993, 0.00019999999999997797]\n",
      "tensor([[0.6369]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.026000000000000023, -0.013600000000000056, -0.015600000000000058]\n",
      "tensor([[0.7010]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003000000000000058, 0.011200000000000043, 0.007000000000000062]\n",
      "tensor([[0.3159]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01679999999999998, -0.002999999999999947, 0.015400000000000025]\n",
      "tensor([[0.2875]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014600000000000002, 0.019400000000000084, 0.0034000000000000696]\n",
      "tensor([[0.8979]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0023999999999999577, 0.0007999999999999119, 0.0016000000000000458]\n",
      "tensor([[0.6441]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, 0.024799999999999933, 0.01940000000000003]\n",
      "tensor([[0.5662]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006400000000000072, 0.0009999999999999454, 0.006799999999999973]\n",
      "tensor([[0.4315]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0010000000000000564, 0.022399999999999975, 0.018799999999999983]\n",
      "tensor([[0.6017]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006799999999999973, 0.027399999999999924, 0.015600000000000003]\n",
      "tensor([[0.3155]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.016199999999999992, 0.0005999999999999894]\n",
      "tensor([[0.1679]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019199999999999884, 0.014599999999999946, -0.00020000000000020002]\n",
      "tensor([[0.4612]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015999999999999903, 0.006599999999999995, -0.0044000000000000705]\n",
      "tensor([[0.3687]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.019799999999999984, 0.006199999999999983, 0.01859999999999995]\n",
      "tensor([[0.5857]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011800000000000033, 0.007600000000000051, 0.006399999999999961]\n",
      "tensor([[0.2639]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008199999999999985, 0.026999999999999913, 0.024599999999999955]\n",
      "tensor([[0.4342]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0016000000000000458, -0.008600000000000052, -0.0020000000000000018]\n",
      "tensor([[0.2010]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017000000000000126, 0.012800000000000145, 0.008800000000000141]\n",
      "tensor([[0.2828]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.028799999999999992, 0.02399999999999991, 0.008599999999999997]\n",
      "tensor([[0.2524]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008400000000000074, 0.014800000000000035, 0.0018000000000000238]\n",
      "tensor([[0.5110]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015199999999999936, -0.00040000000000001146, 0.025400000000000034]\n",
      "tensor([[0.4317]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0045999999999999375, 0.010800000000000087, 0.02260000000000001]\n",
      "tensor([[0.6516]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.011599999999999944, 0.00660000000000005, 0.0038000000000000256]\n",
      "tensor([[0.6729]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0022000000000000908, -0.014200000000000101, 0.007399999999999907]\n",
      "tensor([[0.5372]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01859999999999995, 0.03339999999999993, 0.03539999999999993]\n",
      "tensor([[0.4655]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02839999999999998, 0.014599999999999946, 0.02079999999999993]\n",
      "tensor([[0.3577]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021799999999999986, 0.018000000000000016, 0.04719999999999991]\n",
      "tensor([[0.4480]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0022000000000000908, 0.012199999999999989, 0.008600000000000052]\n",
      "tensor([[0.6019]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00720000000000004, 0.00720000000000004, -0.006000000000000005]\n",
      "tensor([[0.7803]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007600000000000051, 0.014799999999999924, -0.011400000000000077]\n",
      "tensor([[0.4160]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005199999999999982, -0.00940000000000002, -0.00379999999999997]\n",
      "tensor([[0.5809]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010999999999999954, -0.020600000000000007, -0.0038000000000000256]\n",
      "tensor([[0.6063]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011000000000000065, 0.006000000000000005, 0.02440000000000009]\n",
      "tensor([[0.3348]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.030000000000000027, 0.012199999999999989, 0.02140000000000003]\n",
      "tensor([[0.6189]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012799999999999978, 0.006599999999999939, -0.014999999999999958]\n",
      "tensor([[0.2921]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005599999999999994, 0.010599999999999943, 0.004999999999999893]\n",
      "tensor([[0.3868]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007400000000000018, -0.0262, -0.010600000000000054]\n",
      "tensor([[0.3434]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012799999999999978, 0.008400000000000019, 0.01899999999999996]\n",
      "tensor([[0.2585]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004799999999999971, -0.012999999999999956, 0.0006000000000000449]\n",
      "tensor([[0.3395]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0129999999999999, 0.01139999999999991, 0.011799999999999977]\n",
      "tensor([[0.5428]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004799999999999971, 0.028200000000000003, -0.005199999999999927]\n",
      "tensor([[0.3248]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006000000000000005, -0.0005999999999999339, -0.005199999999999927]\n",
      "tensor([[0.3609]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0012000000000000344, -0.0040000000000000036, 0.00720000000000004]\n",
      "tensor([[0.5732]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018799999999999983, 0.00040000000000001146, 0.035199999999999954]\n",
      "tensor([[0.2854]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00500000000000006, 0.008199999999999985, -0.0025999999999999357]\n",
      "tensor([[0.3209]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, 0.010800000000000032, -0.0013999999999999568]\n",
      "tensor([[0.3425]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03419999999999995, 0.02779999999999999, -0.005600000000000049]\n",
      "tensor([[0.4556]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01760000000000006, -0.013600000000000056, 0.005200000000000038]\n",
      "tensor([[0.1904]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0005999999999999339, -0.0132000000000001, 0.0018000000000000238]\n",
      "tensor([[0.3610]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015600000000000058, 0.0020000000000000018, 0.013400000000000079]\n",
      "tensor([[0.5347]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.02639999999999998, -0.022999999999999965, -0.008799999999999975]\n",
      "tensor([[0.2589]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006000000000000005, 0.0040000000000000036, 0.0025999999999999357]\n",
      "tensor([[0.3235]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01579999999999998, 0.02059999999999995, 0.020000000000000018]\n",
      "tensor([[0.6369]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005799999999999972, 0.01919999999999994, 0.02339999999999992]\n",
      "tensor([[0.3695]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020399999999999974, 0.020999999999999963, -0.0122000000000001]\n",
      "tensor([[0.1770]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00020000000000020002, -0.0024000000000001798, 0.0013999999999998458]\n",
      "tensor([[0.3404]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008000000000000007, 0.0031999999999999806, 0.02200000000000002]\n",
      "tensor([[0.6912]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0024000000000000132, -0.01579999999999998, -0.022800000000000042]\n",
      "tensor([[0.2402]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0041999999999999815, -0.0045999999999999375, 0.0028000000000001357]\n",
      "tensor([[0.4363]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014999999999999902, 0.0009999999999999454, 0.00379999999999997]\n",
      "tensor([[0.2386]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010599999999999943, 0.014000000000000012, 0.014799999999999924]\n",
      "tensor([[0.2838]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0015999999999999348, 0.0040000000000000036, 0.0013999999999999013]\n",
      "tensor([[0.3502]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0041999999999999815, 0.023200000000000054, 0.02080000000000004]\n",
      "tensor([[0.5248]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005200000000000038, -0.009599999999999997, 0.002799999999999969]\n",
      "tensor([[0.5515]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.015600000000000003, -0.020999999999999963, -0.026799999999999935]\n",
      "tensor([[0.6315]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010600000000000054, 0.03480000000000005, 0.02400000000000002]\n",
      "tensor([[0.4273]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010199999999999987, 0.010399999999999965, 0.02059999999999995]\n",
      "tensor([[0.3247]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012799999999999978, 0.022199999999999998, 0.0014000000000000679]\n",
      "tensor([[0.0867]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007400000000000073, 0.009600000000000053, 0.006599999999999939]\n",
      "tensor([[0.3727]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0013999999999999568, 0.008999999999999952, -0.0043999999999999595]\n",
      "tensor([[0.0805]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011400000000000077, -0.0021999999999999797, 0.0]\n",
      "tensor([[0.3758]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.036599999999999966, 0.03199999999999997, 0.04059999999999997]\n",
      "tensor([[0.4455]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015600000000000003, 0.006799999999999973, 0.010999999999999954]\n",
      "tensor([[0.4570]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015600000000000003, -0.0021999999999999797, -0.014400000000000024]\n",
      "tensor([[0.6808]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01759999999999995, -0.0040000000000000036, -0.0126]\n",
      "tensor([[0.3003]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01919999999999994, -0.006199999999999983, 0.010000000000000009]\n",
      "tensor([[0.3709]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0040000000000000036, 0.0040000000000000036, 0.0018000000000000238]\n",
      "tensor([[0.6177]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01639999999999997, -0.008600000000000108, 0.011999999999999955]\n",
      "tensor([[0.6908]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02579999999999999, 0.003599999999999992, 0.00379999999999997]\n",
      "tensor([[0.3800]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03259999999999996, 0.037199999999999955, 0.020399999999999974]\n",
      "Training [90%]\tLoss: -0.6266\n",
      "tensor([[0.3545]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.05179999999999996, 0.04139999999999994, 0.041999999999999926]\n",
      "tensor([[0.5272]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.008000000000000007, 0.01479999999999998, 0.01699999999999996]\n",
      "tensor([[0.3934]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0015999999999999903, -0.012999999999999956, 0.005599999999999994]\n",
      "tensor([[0.2165]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0012000000000000899, 0.0020000000000000018, 0.013399999999999856]\n",
      "tensor([[0.4965]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.026599999999999957, 0.022199999999999998, 0.0037999999999999146]\n",
      "tensor([[0.5182]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017400000000000027, 0.006199999999999983, 0.020000000000000018]\n",
      "tensor([[0.1419]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010000000000000009, -0.0023999999999999577, -0.022399999999999975]\n",
      "tensor([[0.2954]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0014000000000000123, -0.0262, 0.01200000000000001]\n",
      "tensor([[0.1276]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017799999999999816, 0.015399999999999858, 0.009399999999999853]\n",
      "tensor([[0.2976]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.020999999999999908, -0.020999999999999908, -0.007599999999999996]\n",
      "tensor([[0.1818]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006000000000000005, 0.0046000000000001595, 0.01100000000000012]\n",
      "tensor([[0.6881]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00500000000000006, 0.0007999999999999674, -0.010600000000000054]\n",
      "tensor([[0.1573]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009800000000000031, -0.0009999999999998899, -0.0041999999999999815]\n",
      "tensor([[0.2417]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0040000000000000036, 0.0007999999999999119, 0.005399999999999849]\n",
      "tensor([[0.2163]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012599999999999945, 0.0047999999999999154, 0.026999999999999913]\n",
      "tensor([[0.4595]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010399999999999965, 0.0015999999999999903, 0.008799999999999919]\n",
      "tensor([[0.6357]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00759999999999994, -0.01440000000000008, -0.006199999999999983]\n",
      "tensor([[0.5008]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006999999999999951, 0.02079999999999993, 0.019999999999999962]\n",
      "tensor([[0.1973]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016199999999999992, 0.0040000000000000036, -0.010600000000000165]\n",
      "tensor([[0.4565]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0005999999999999894, -0.007000000000000062, 0.003599999999999992]\n",
      "tensor([[0.8590]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015600000000000058, 0.024599999999999955, 0.015000000000000124]\n",
      "tensor([[0.2345]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007000000000000117, -0.012800000000000145, -0.0262]\n",
      "tensor([[0.7116]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009600000000000053, 0.0040000000000000036, -0.015800000000000036]\n",
      "tensor([[0.2788]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01959999999999995, 0.01899999999999996, 0.009399999999999908]\n",
      "tensor([[0.1622]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0016000000000000458, -0.0007999999999999119, -0.01540000000000008]\n",
      "tensor([[0.1465]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006800000000000139, 0.0, -0.0025999999999999357]\n",
      "tensor([[0.6158]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0034000000000000696, 0.01079999999999992, -0.016600000000000004]\n",
      "tensor([[0.4907]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0043999999999999595, 0.013799999999999979, -0.00500000000000006]\n",
      "tensor([[0.3958]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.003400000000000014, 0.007800000000000029, -0.0020000000000000018]\n",
      "tensor([[0.3810]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0025999999999999357, 0.003599999999999992, 0.015400000000000025]\n",
      "tensor([[0.4407]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.047200000000000075, 0.03660000000000002, 0.04680000000000001]\n",
      "tensor([[0.2028]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0014000000000000679, 0.006399999999999961, -0.0009999999999998899]\n",
      "tensor([[0.2346]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0018000000000000238, -0.0026000000000001577, -0.016000000000000014]\n",
      "tensor([[0.2698]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.029199999999999948, 0.015599999999999947, 0.007800000000000029]\n",
      "tensor([[0.1555]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.015399999999999858, -0.008199999999999985, -0.009800000000000031]\n",
      "tensor([[0.4068]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.022800000000000098, 0.006599999999999995, -0.0040000000000000036]\n",
      "tensor([[0.3019]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011800000000000033, 0.020800000000000096, 0.006800000000000084]\n",
      "tensor([[0.3069]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03660000000000008, 0.037200000000000066, 0.040000000000000036]\n",
      "tensor([[0.5742]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.019000000000000072, -0.010400000000000076, 0.002599999999999991]\n",
      "tensor([[0.6002]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.002599999999999991, 0.02200000000000002, 0.0014000000000000123]\n",
      "tensor([[0.5937]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013800000000000034, -0.013400000000000023, -0.01720000000000005]\n",
      "tensor([[0.4422]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017799999999999927, 0.006400000000000017, 0.00020000000000003348]\n",
      "tensor([[0.4252]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007399999999999907, 0.018799999999999928, -0.012200000000000044]\n",
      "tensor([[0.6188]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007599999999999996, 0.025399999999999923, 0.010199999999999987]\n",
      "tensor([[0.5520]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006000000000000005, 0.0020000000000000018, -0.000200000000000089]\n",
      "tensor([[0.2632]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005800000000000027, -0.013199999999999934, 0.012199999999999989]\n",
      "tensor([[0.5444]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03140000000000004, 0.037400000000000044, 0.01419999999999999]\n",
      "tensor([[0.5484]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025400000000000034, 0.014000000000000012, 0.022599999999999953]\n",
      "tensor([[0.5946]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006000000000000005, -0.011400000000000077, -0.006599999999999995]\n",
      "tensor([[0.2220]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007800000000000029, 0.016199999999999992, 0.016800000000000148]\n",
      "tensor([[0.6746]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.010000000000000009, 0.004200000000000037, -0.03359999999999991]\n",
      "tensor([[0.5649]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00539999999999996, -0.0007999999999999674, -0.00759999999999994]\n",
      "tensor([[0.4596]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03899999999999998, 0.020000000000000018, 0.02079999999999993]\n",
      "tensor([[0.6811]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.018000000000000016, -0.01639999999999997, -0.034399999999999986]\n",
      "tensor([[0.4424]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007599999999999996, 0.024599999999999955, 0.010999999999999954]\n",
      "tensor([[0.4684]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006800000000000028, -0.016199999999999992, 0.002999999999999947]\n",
      "tensor([[0.4559]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015200000000000047, 0.03160000000000002, 0.01859999999999995]\n",
      "tensor([[0.1692]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018000000000000016, 0.010599999999999943, 0.024399999999999977]\n",
      "tensor([[0.1039]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0050000000000001155, 0.0016000000000000458, -0.008199999999999985]\n",
      "tensor([[0.4955]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003199999999999925, 0.013399999999999912, 0.008999999999999952]\n",
      "tensor([[0.4944]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0021999999999999797, -0.02260000000000001, -0.014999999999999958]\n",
      "tensor([[0.2609]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0025999999999999357, -0.016600000000000004, -0.005800000000000027]\n",
      "tensor([[0.4919]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0007999999999999674, -0.006799999999999973, 0.01859999999999995]\n",
      "tensor([[0.8048]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00019999999999997797, 0.006800000000000139, 0.009400000000000075]\n",
      "tensor([[0.7439]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0020000000000000018, 0.004799999999999971, 0.006799999999999973]\n",
      "tensor([[0.5827]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.002799999999999969, -0.013400000000000023, -0.01859999999999995]\n",
      "tensor([[0.2868]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0041999999999999815, -0.003200000000000036, 0.0023999999999999577]\n",
      "tensor([[0.6547]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0040000000000000036, -0.005599999999999938, -0.009399999999999908]\n",
      "tensor([[0.1097]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016799999999999926, 0.0040000000000000036, -0.0048000000000001375]\n",
      "tensor([[0.0883]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007200000000000095, -0.00020000000000020002, -0.011400000000000077]\n",
      "tensor([[0.6178]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0021999999999999797, 0.0025999999999999357, -0.008000000000000007]\n",
      "tensor([[0.4300]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02260000000000001, 0.017799999999999927, 0.009399999999999908]\n",
      "tensor([[0.3772]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0, -0.0027999999999999137, 0.0024000000000000132]\n",
      "tensor([[0.5698]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.03180000000000005, 0.020600000000000007, 0.030000000000000027]\n",
      "tensor([[0.4533]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007800000000000029, -0.006400000000000072, 0.00759999999999994]\n",
      "tensor([[0.2919]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010999999999999954, -0.0012000000000000344, 0.019999999999999907]\n",
      "tensor([[0.5372]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008999999999999952, 0.005400000000000016, 0.012599999999999945]\n",
      "tensor([[0.4199]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.032999999999999974, 0.023199999999999943, 0.01699999999999996]\n",
      "tensor([[0.2239]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009400000000000075, -0.010199999999999987, -0.010999999999999899]\n",
      "tensor([[0.2694]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02460000000000001, 0.0262, 0.023400000000000087]\n",
      "tensor([[0.1199]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0012000000000000899, 0.0005999999999999339, 0.010999999999999899]\n",
      "tensor([[0.4788]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.020999999999999963, -0.004599999999999993, 0.013800000000000034]\n",
      "tensor([[0.5471]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025399999999999978, 0.0348, 0.01679999999999998]\n",
      "tensor([[0.7222]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01720000000000005, 0.00280000000000008, 0.006000000000000005]\n",
      "tensor([[0.1964]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0007999999999999119, 0.011199999999999877, 0.024399999999999977]\n",
      "tensor([[0.6252]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014400000000000024, 0.011400000000000077, -0.01419999999999999]\n",
      "tensor([[0.5705]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012399999999999967, 0.022199999999999998, 0.010399999999999965]\n",
      "tensor([[0.2251]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02080000000000015, 0.000600000000000156, 0.027800000000000047]\n",
      "tensor([[0.4933]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.023399999999999976, -0.0033999999999999586, 0.003599999999999992]\n",
      "tensor([[0.1667]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018199999999999994, 0.017400000000000082, 0.021400000000000086]\n",
      "tensor([[0.2730]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016599999999999948, 0.0005999999999999339, 0.0262]\n",
      "tensor([[0.4179]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013399999999999912, 0.018199999999999994, 0.018399999999999972]\n",
      "tensor([[0.3604]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0041999999999999815, 0.01139999999999991, -0.003200000000000036]\n",
      "tensor([[0.7030]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.02339999999999992, -0.017199999999999938, -0.00539999999999996]\n",
      "tensor([[0.1621]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005399999999999849, -0.010800000000000143, -0.012399999999999967]\n",
      "tensor([[0.3705]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01419999999999999, 0.0043999999999999595, 0.0009999999999999454]\n",
      "tensor([[0.2326]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006000000000000005, 0.014999999999999902, -0.0052000000000000934]\n",
      "tensor([[0.3202]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0009999999999999454, -0.005200000000000038, -0.01860000000000006]\n",
      "tensor([[0.0889]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013400000000000079, 0.01639999999999997, 0.007400000000000073]\n",
      "tensor([[0.2211]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.026000000000000023, 0.017000000000000126, 0.0034000000000000696]\n",
      "Training [95%]\tLoss: -0.6466\n",
      "tensor([[0.6567]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01480000000000009, -0.00979999999999992, -0.0021999999999999797]\n",
      "tensor([[0.3348]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006799999999999973, 0.01940000000000003, 0.010599999999999998]\n",
      "tensor([[0.4077]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0011999999999999234, -0.010999999999999954, -0.01479999999999998]\n",
      "tensor([[0.6253]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01419999999999999, -0.004599999999999993, -0.0024000000000000132]\n",
      "tensor([[0.3460]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016600000000000004, 0.0034000000000000696, 0.020000000000000018]\n",
      "tensor([[0.3489]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009800000000000031, 0.017400000000000027, -0.006799999999999973]\n",
      "tensor([[0.6371]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0043999999999999595, -0.00720000000000004, -0.008799999999999975]\n",
      "tensor([[0.4750]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.002999999999999947, -0.01079999999999992, -0.006199999999999983]\n",
      "tensor([[0.1196]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012399999999999967, 0.007800000000000029, -0.0021999999999999797]\n",
      "tensor([[0.8138]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006000000000000005, -0.014399999999999968, -0.025599999999999845]\n",
      "tensor([[0.3244]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015600000000000003, 0.03119999999999995, 0.034599999999999964]\n",
      "tensor([[0.4513]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02040000000000003, -0.00040000000000006697, 0.03179999999999994]\n",
      "tensor([[0.0804]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00039999999999995595, -0.0012000000000000899, -0.005400000000000071]\n",
      "tensor([[0.1648]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.021400000000000086, 0.021200000000000108, 0.006600000000000161]\n",
      "tensor([[0.6923]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0043999999999999595, 0.0129999999999999, -0.005600000000000049]\n",
      "tensor([[0.6913]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0040000000000000036, 0.008199999999999985, 0.0015999999999999903]\n",
      "tensor([[0.1358]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00039999999999995595, 0.016000000000000014, -0.0008000000000001339]\n",
      "tensor([[0.3243]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0009999999999999454, -0.00500000000000006, 0.0024000000000000132]\n",
      "tensor([[0.3853]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013199999999999934, -0.04459999999999997, -0.011799999999999977]\n",
      "tensor([[0.4909]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0020000000000000018, 0.005800000000000027, 0.03200000000000003]\n",
      "tensor([[0.6250]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.022399999999999975, -0.022999999999999965, -0.010599999999999998]\n",
      "tensor([[0.3549]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.027200000000000057, -0.003400000000000014, -0.010000000000000009]\n",
      "tensor([[0.2650]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008199999999999985, 0.02400000000000002, -0.0014000000000000679]\n",
      "tensor([[0.2197]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005800000000000027, 0.007200000000000095, 0.023199999999999887]\n",
      "tensor([[0.5026]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.017400000000000027, -0.010800000000000087, -0.02400000000000002]\n",
      "tensor([[0.3058]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.00880000000000003, 0.011799999999999977, 0.009200000000000041]\n",
      "tensor([[0.2803]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015800000000000036, -0.003200000000000036, 0.012399999999999967]\n",
      "tensor([[0.2593]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.008400000000000019, 0.01200000000000001, 0.013800000000000034]\n",
      "tensor([[0.3107]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0020000000000000018, 0.0016000000000000458, -0.0043999999999999595]\n",
      "tensor([[0.3935]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02639999999999998, 0.014399999999999968, 0.013400000000000023]\n",
      "tensor([[0.1304]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012199999999999989, 0.0032000000000000917, 0.014399999999999968]\n",
      "tensor([[0.5743]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.011999999999999955, -0.01940000000000003, -0.03140000000000004]\n",
      "tensor([[0.5550]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01660000000000006, -0.006200000000000094, -0.011200000000000043]\n",
      "tensor([[0.1655]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0007999999999999119, 0.018399999999999972, 0.0041999999999999815]\n",
      "tensor([[0.3573]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007199999999999929, -0.011199999999999932, -0.008000000000000007]\n",
      "tensor([[0.2468]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0043999999999999595, -0.00039999999999995595, -0.02100000000000013]\n",
      "tensor([[0.5067]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025199999999999945, -0.0015999999999999903, 0.034999999999999976]\n",
      "tensor([[0.4539]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0033999999999999586, 0.031799999999999995, 0.03839999999999999]\n",
      "tensor([[0.5227]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.003399999999999903, -0.003200000000000036, 0.018199999999999994]\n",
      "tensor([[0.5630]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007000000000000062, -0.0041999999999999815, 0.008200000000000096]\n",
      "tensor([[0.1463]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005600000000000049, -0.006199999999999983, -0.016599999999999948]\n",
      "tensor([[0.6322]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.005199999999999927, 0.00500000000000006, -0.007799999999999974]\n",
      "tensor([[0.2147]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.011400000000000077, -0.0030000000000001137, -0.007200000000000095]\n",
      "tensor([[0.2973]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00019999999999997797, -0.014600000000000002, -0.004599999999999993]\n",
      "tensor([[0.3965]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, -0.0033999999999999586, 0.02839999999999998]\n",
      "tensor([[0.2063]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0033999999999998476, 0.010599999999999943, -0.009600000000000053]\n",
      "tensor([[0.5815]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007199999999999929, -0.004599999999999993, -0.0021999999999999797]\n",
      "tensor([[0.4857]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016000000000000014, 0.013799999999999979, 0.019399999999999917]\n",
      "tensor([[0.5346]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.015400000000000025, -0.009599999999999942, 0.0006000000000000449]\n",
      "tensor([[0.5296]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014800000000000035, -0.013399999999999967, 0.007400000000000018]\n",
      "tensor([[0.1813]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01980000000000004, 0.011800000000000033, 0.012199999999999989]\n",
      "tensor([[0.4476]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0043999999999999595, 0.010799999999999976, 0.0021999999999999797]\n",
      "tensor([[0.2820]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013599999999999945, 0.011199999999999988, -0.006399999999999961]\n",
      "tensor([[0.1643]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.015800000000000036, -0.0047999999999999154, 0.0]\n",
      "tensor([[0.6121]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.014000000000000012, 0.004400000000000015, 0.019400000000000084]\n",
      "tensor([[0.4113]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011400000000000021, -0.0036000000000000476, -0.011200000000000043]\n",
      "tensor([[0.4846]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01539999999999997, 0.0020000000000000018, 0.0018000000000000238]\n",
      "tensor([[0.3257]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0021999999999999797, 0.018399999999999972, -0.011400000000000021]\n",
      "tensor([[0.3626]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006599999999999995, 0.028000000000000025, 0.02200000000000002]\n",
      "tensor([[0.2341]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005400000000000071, 0.018399999999999972, -0.01519999999999988]\n",
      "tensor([[0.1554]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0052000000000000934, 0.019400000000000084, 0.0021999999999999797]\n",
      "tensor([[0.1809]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.022400000000000198, 0.021400000000000086, 0.010200000000000209]\n",
      "tensor([[0.7217]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.01200000000000001, -0.002799999999999969, 0.0021999999999999797]\n",
      "tensor([[0.1855]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007600000000000051, 0.02520000000000011, 0.015200000000000102]\n",
      "tensor([[0.1583]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009400000000000075, 0.0021999999999999797, 0.0045999999999999375]\n",
      "tensor([[0.3555]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0028000000000000247, 0.011800000000000033, -0.0014000000000000123]\n",
      "tensor([[0.4366]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007000000000000062, 0.016199999999999992, 0.021000000000000074]\n",
      "tensor([[0.3252]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0033999999999999586, -0.01419999999999999, -0.011000000000000065]\n",
      "tensor([[0.4671]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.014000000000000012, 0.01639999999999997, 0.0008000000000000784]\n",
      "tensor([[0.3932]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.002799999999999969, -0.0041999999999999815, -0.0009999999999999454]\n",
      "tensor([[0.0730]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007000000000000117, 0.01200000000000001, 0.0012000000000000899]\n",
      "tensor([[0.5548]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.007199999999999929, -0.004799999999999971, -0.0041999999999999815]\n",
      "tensor([[0.6454]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.013199999999999934, 0.005800000000000027, -0.008599999999999941]\n",
      "tensor([[0.5574]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.025199999999999945, 0.029799999999999993, 0.029600000000000015]\n",
      "tensor([[0.1772]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009199999999999875, 0.022399999999999975, -0.0030000000000001137]\n",
      "tensor([[0.5783]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.018600000000000005, -0.011000000000000065, -0.009599999999999997]\n",
      "tensor([[0.2873]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.016599999999999948, 0.005800000000000027, 0.01200000000000001]\n",
      "tensor([[0.2834]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0015999999999999903, 0.004400000000000015, -0.008599999999999941]\n",
      "tensor([[0.7174]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.01959999999999995, 0.02479999999999999, 0.02200000000000002]\n",
      "tensor([[0.5647]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013800000000000034, -0.00039999999999995595, 0.009800000000000031]\n",
      "tensor([[0.2988]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012400000000000078, -0.0035999999999999366, -0.00019999999999997797]\n",
      "tensor([[0.2679]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.004200000000000037, 0.008999999999999897, -0.0018000000000000238]\n",
      "tensor([[0.3304]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.00820000000000004, 0.003399999999999903, 0.013399999999999912]\n",
      "tensor([[0.6626]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.007799999999999974, 0.013200000000000045, -0.023599999999999954]\n",
      "tensor([[0.5907]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.012199999999999989, 0.010599999999999943, 0.020199999999999996]\n",
      "tensor([[0.6728]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.005800000000000027, 0.020600000000000063, 0.0038000000000000256]\n",
      "tensor([[0.1599]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006599999999999939, 0.014799999999999924, -0.0016000000000000458]\n",
      "tensor([[0.6506]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.032200000000000006, 0.02839999999999998, 0.007400000000000018]\n",
      "tensor([[0.6435]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.017400000000000027, 0.021200000000000052, -0.002799999999999969]\n",
      "tensor([[0.2042]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.006400000000000183, 0.006000000000000005, 0.004999999999999893]\n",
      "tensor([[0.1740]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.0048000000000001375, -0.007600000000000051, -0.012600000000000167]\n",
      "tensor([[0.3055]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.010399999999999965, 0.011600000000000055, 0.02479999999999999]\n",
      "tensor([[0.3892]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.02679999999999999, -0.008999999999999952, 0.007600000000000051]\n",
      "tensor([[0.2044]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0045999999999999375, 0.021199999999999886, 0.018399999999999972]\n",
      "tensor([[0.2919]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.006999999999999951, 0.025599999999999956, 0.018600000000000005]\n",
      "tensor([[0.4952]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.011000000000000065, 0.016000000000000014, -0.016199999999999992]\n",
      "tensor([[0.4695]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.013599999999999945, 0.014400000000000024, 0.023599999999999954]\n",
      "tensor([[0.0339]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.0007999999999999119, 0.006000000000000005, 0.005399999999999849]\n",
      "tensor([[0.7495]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[0.009999999999999842, 0.014200000000000046, 0.0022000000000000353]\n",
      "tensor([[0.2515]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "[-0.009999999999999842, -0.006799999999999973, -0.002999999999999947]\n",
      "Training [100%]\tLoss: -0.6426\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()        \n",
    "        # Forward pass\n",
    "        output = network(data)\n",
    "        # Calculating loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Neg Log Likelihood Loss')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Neg Log Likelihood Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of NN\n",
    "\n",
    "The outcome is not always the same because the prediction is probabilistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on test data is is: 0.88\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "number = 0\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    number +=1\n",
    "    output = network(data)\n",
    "    output = (output>0.5).float()\n",
    "    accuracy += (output[0][1].item() == target[0].item())*1\n",
    "    \n",
    "print(\"Performance on test data is is: {}\".format(accuracy/number))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = network(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title('Predicted {}'.format(pred.item()))\n",
    "        \n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
