{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "# Hybrid quantum-classical Neural Networks with PyTorch and Qiskit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning (ML) has established itself as a successful interdisciplinary field which seeks to mathematically extract generalizable information from data. Throwing in quantum computing gives rise to interesting areas of research which seek to leverage the principles of quantum mechanics to augment machine learning or vice-versa. Whether you're aiming to enhance classical ML algorithms by outsourcing difficult calculations to a quantum computer or optimise quantum algorithms using classical ML architectures - both fall under the diverse umbrella of quantum machine learning (QML).\n",
    "\n",
    "In this chapter, we explore how a classical neural network can be partially quantized to create a hybrid quantum-classical neural network. We will code up a simple example that integrates **Qiskit** with a state-of-the-art open-source software package - **[PyTorch](https://pytorch.org/)**. The purpose of this example is to demonstrate the ease of integrating Qiskit with existing ML tools and to encourage ML practitioners to explore what is possible with quantum computing.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [How Does it Work?](#how)    \n",
    "    1.1 [Preliminaries](#prelims)    \n",
    "2. [So How Does Quantum Enter the Picture?](#quantumlayer)\n",
    "3. [Let's code!](#code)  \n",
    "    3.1 [Imports](#imports)   \n",
    "    3.2 [Create a \"Quantum Class\" with Qiskit](#q-class)    \n",
    "    3.3 [Create a \"Quantum-Classical Class\" with PyTorch](#qc-class)    \n",
    "    3.4 [Data Loading and Preprocessing](#data-loading-preprocessing)    \n",
    "    3.5 [Creating the Hybrid Neural Network](#hybrid-nn)     \n",
    "    3.6 [Training the Network](#training)    \n",
    "    3.7 [Testing the Network](#testing)\n",
    "4. [What Now?](#what-now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How does it work? <a id='how'></a>\n",
    "<img src=\"hybridnetwork.png\" width=\"800\"/>\n",
    "\n",
    "**Fig.1** Illustrates the framework we will construct in this chapter. Ultimately, we will create a hybrid quantum-classical neural network that seeks to classify hand drawn digits. Note that the edges shown in this image are all directed downward; however, the directionality is not visually indicated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Preliminaries <a id='prelims'></a>\n",
    "The background presented here on classical neural networks is included to establish relevant ideas and shared terminology; however, it is still extremely high-level. __If you'd like to dive one step deeper into classical neural networks, see the well made video series by youtuber__ [3Blue1Brown](https://youtu.be/aircAruvnKk). Alternatively, if you are already familiar with classical networks, you can [skip to the next section](#quantumlayer).\n",
    "\n",
    "###### Neurons and Weights\n",
    "A neural network is ultimately just an elaborate function that is built by composing smaller building blocks called neurons. A ***neuron*** is typically a simple, easy-to-compute, and nonlinear function that maps one or more inputs to a single real number. The single output of a neuron is typically copied and fed as input into other neurons. Graphically, we represent neurons as nodes in a graph and we draw directed edges between nodes to indicate how the output of one neuron will be used as input to other neurons. It's also important to note that each edge in our graph is often associated with a scalar-value called a [***weight***](https://en.wikipedia.org/wiki/Artificial_neural_network#Connections_and_weights). The idea here is that each of the inputs to a neuron will be multiplied by a different scalar before being collected and processed into a single value. The objective when training a neural network consists primarily of choosing our weights such that the network behaves in a particular way. \n",
    "\n",
    "###### Feed Forward Neural Networks\n",
    "It is also worth noting that the particular type of neural network we will concern ourselves with is called a **[feed-forward neural network (FFNN)](https://en.wikipedia.org/wiki/Feedforward_neural_network)**. This means that as data flows through our neural network, it will never return to a neuron it has already visited. Equivalently, you could say that the graph which describes our neural network is a **[directed acyclic graph (DAG)](https://en.wikipedia.org/wiki/Directed_acyclic_graph)**. Furthermore, we will stipulate that neurons within the same layer of our neural network will not have edges between them. \n",
    "\n",
    "###### IO Structure of Layers\n",
    "The input to a neural network is a classical (real-valued) vector. Each component of the input vector is multiplied by a different weight and fed into a layer of neurons according to the graph structure of the network. After each neuron in the layer has been evaluated, the results are collected into a new vector where the i'th component records the output of the i'th neuron. This new vector can then treated as input for a new layer, and so on. We will use the standard term ***hidden layer*** to describe all but the first and last layers of our network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. So How Does Quantum Enter the Picture? <a id='quantumlayer'> </a>\n",
    "\n",
    "To create a quantum-classical neural network, one can implement a hidden layer for our neural network using a parameterized quantum circuit. By \"parameterized quantum circuit\", we mean a quantum circuit where the rotation angles for each gate are specified by the components of a classical input vector. The outputs from our neural network's previous layer will be collected and used as the inputs for our parameterized circuit. The measurement statistics of our quantum circuit can then be collected and used as inputs for the following layer. A simple example is depicted below:\n",
    "\n",
    "<img src=\"neuralnetworkQC.png\" width=\"800\"/>\n",
    "\n",
    "Here, $\\sigma$ is a [nonlinear function](https://en.wikipedia.org/wiki/Activation_function) and $h_i$ is the value of neuron $i$ at each hidden layer. $R(h_i)$ represents any rotation gate about an angle equal to $h_i$ and $y$ is the final prediction value generated from the hybrid network.  \n",
    "\n",
    "### What about backpropagation?\n",
    "If you're familiar with classical ML, you may immediately be wondering *how do we calculate gradients when quantum circuits are involved?* This would be necessary to enlist powerful optimisation techniques such as **[gradient descent](https://en.wikipedia.org/wiki/Gradient_descent)**. It gets a bit technical, but in short, we can view a quantum circuit as a black box and the gradient of this black box with respect to its parameters can be calculated as follows: \n",
    "\n",
    "<img src=\"quantumgradient.png\" width=\"800\"/>\n",
    "\n",
    "where $\\theta$ represents the parameters of the quantum circuit and $s$ is a macroscopic shift. The gradient is then simply the difference between our quantum circuit evaluated at $\\theta+s$ and $\\theta - s$. Thus, we can systematically differentiate our quantum circuit as part of a larger backpropogation routine. This closed form rule for calculating the gradient of quantum circuit parameters is known as **[the parameter shift rule](https://arxiv.org/pdf/1905.13311.pdf)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Let's code! <a id='code'></a>\n",
    "\n",
    "\n",
    "### 3.1 Imports <a id='imports'></a>\n",
    "First, we import some handy packages that we will need, including Qiskit and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import qiskit\n",
    "from qiskit.visualization import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create a \"Quantum Class\" with Qiskit <a id='q-class'></a>\n",
    "We can conveniently put our Qiskit quantum functions into a class. First, we specify how many trainable quantum parameters and how many shots we wish to use in our quantum circuit. In this example, we will keep it simple and use a 1-qubit circuit with one trainable quantum parameter $\\theta$. We hard code the circuit for simplicity and use a $RY-$rotation by the angle $\\theta$ to train the output of our circuit. The circuit looks like this:\n",
    "\n",
    "<img src=\"1qubitcirc.png\" width=\"400\"/>\n",
    "\n",
    "In order to measure the output in the $z-$basis, we calculate the $\\sigma_\\mathbf{z}$ expectation. \n",
    "$$\\sigma_\\mathbf{z} = \\sum_i z_i p(z_i)$$\n",
    "We will see later how this all ties into the hybrid neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCircuit:\n",
    "    \"\"\" \n",
    "    This class provides a simple interface for interaction \n",
    "    with the quantum circuit \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.theta = qiskit.circuit.Parameter('theta')\n",
    "        \n",
    "        self._circuit.h(all_qubits)\n",
    "        self._circuit.barrier()\n",
    "        self._circuit.ry(self.theta, all_qubits)\n",
    "        \n",
    "        self._circuit.measure_all()\n",
    "        # ---------------------------\n",
    "\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "    \n",
    "    def run(self, thetas):\n",
    "        job = qiskit.execute(self._circuit, \n",
    "                             self.backend, \n",
    "                             shots = self.shots,\n",
    "                             parameter_binds = [{self.theta: theta} for theta in thetas])\n",
    "        result = job.result().get_counts(self._circuit)\n",
    "        \n",
    "        counts = np.array(list(result.values()))\n",
    "        states = np.array(list(result.keys())).astype(float)\n",
    "        \n",
    "        # Compute probabilities for each state\n",
    "        probabilities = counts / self.shots\n",
    "        # Get state expectation\n",
    "        expectation = np.sum(states * probabilities)\n",
    "        \n",
    "        return np.array([expectation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value for rotation pi 51081167834783.19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">         ┌───┐ ░ ┌───────────┐ ░ ┌─┐                                          \n",
       "    q_0: ┤ H ├─░─┤ RY(theta) ├─░─┤M├──────────────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░ └╥┘┌─┐                                       \n",
       "    q_1: ┤ H ├─░─┤ RY(theta) ├─░──╫─┤M├───────────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║ └╥┘┌─┐                                    \n",
       "    q_2: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫─┤M├────────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║ └╥┘┌─┐                                 \n",
       "    q_3: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫─┤M├─────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║ └╥┘┌─┐                              \n",
       "    q_4: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫─┤M├──────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║ └╥┘┌─┐                           \n",
       "    q_5: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫─┤M├───────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║ └╥┘┌─┐                        \n",
       "    q_6: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫─┤M├────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║ └╥┘┌─┐                     \n",
       "    q_7: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫─┤M├─────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐                  \n",
       "    q_8: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫─┤M├──────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐               \n",
       "    q_9: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├───────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐            \n",
       "   q_10: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐         \n",
       "   q_11: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├─────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐      \n",
       "   q_12: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├──────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐   \n",
       "   q_13: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├───\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐\n",
       "   q_14: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├\n",
       "         └───┘ ░ └───────────┘ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘\n",
       " meas_0: ═════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                     ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_1: ════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                        ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_2: ═══════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                           ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_3: ══════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                              ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_4: ═════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                 ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_5: ════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                    ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_6: ═══════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                       ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_7: ══════════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                          ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_8: ═════════════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬═\n",
       "                                                             ║  ║  ║  ║  ║  ║ \n",
       " meas_9: ════════════════════════════════════════════════════╩══╬══╬══╬══╬══╬═\n",
       "                                                                ║  ║  ║  ║  ║ \n",
       "meas_10: ═══════════════════════════════════════════════════════╩══╬══╬══╬══╬═\n",
       "                                                                   ║  ║  ║  ║ \n",
       "meas_11: ══════════════════════════════════════════════════════════╩══╬══╬══╬═\n",
       "                                                                      ║  ║  ║ \n",
       "meas_12: ═════════════════════════════════════════════════════════════╩══╬══╬═\n",
       "                                                                         ║  ║ \n",
       "meas_13: ════════════════════════════════════════════════════════════════╩══╬═\n",
       "                                                                            ║ \n",
       "meas_14: ═══════════════════════════════════════════════════════════════════╩═\n",
       "                                                                              </pre>"
      ],
      "text/plain": [
       "         ┌───┐ ░ ┌───────────┐ ░ ┌─┐                                          \n",
       "    q_0: ┤ H ├─░─┤ RY(theta) ├─░─┤M├──────────────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░ └╥┘┌─┐                                       \n",
       "    q_1: ┤ H ├─░─┤ RY(theta) ├─░──╫─┤M├───────────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║ └╥┘┌─┐                                    \n",
       "    q_2: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫─┤M├────────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║ └╥┘┌─┐                                 \n",
       "    q_3: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫─┤M├─────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║ └╥┘┌─┐                              \n",
       "    q_4: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫─┤M├──────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║ └╥┘┌─┐                           \n",
       "    q_5: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫─┤M├───────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║ └╥┘┌─┐                        \n",
       "    q_6: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫─┤M├────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║ └╥┘┌─┐                     \n",
       "    q_7: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫─┤M├─────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐                  \n",
       "    q_8: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫─┤M├──────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐               \n",
       "    q_9: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├───────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐            \n",
       "   q_10: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐         \n",
       "   q_11: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├─────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐      \n",
       "   q_12: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├──────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐   \n",
       "   q_13: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├───\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐\n",
       "   q_14: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├\n",
       "         └───┘ ░ └───────────┘ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘\n",
       " meas_0: ═════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                     ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_1: ════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                        ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_2: ═══════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                           ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_3: ══════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                              ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_4: ═════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                 ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_5: ════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                    ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_6: ═══════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                       ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_7: ══════════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                          ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_8: ═════════════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬═\n",
       "                                                             ║  ║  ║  ║  ║  ║ \n",
       " meas_9: ════════════════════════════════════════════════════╩══╬══╬══╬══╬══╬═\n",
       "                                                                ║  ║  ║  ║  ║ \n",
       "meas_10: ═══════════════════════════════════════════════════════╩══╬══╬══╬══╬═\n",
       "                                                                   ║  ║  ║  ║ \n",
       "meas_11: ══════════════════════════════════════════════════════════╩══╬══╬══╬═\n",
       "                                                                      ║  ║  ║ \n",
       "meas_12: ═════════════════════════════════════════════════════════════╩══╬══╬═\n",
       "                                                                         ║  ║ \n",
       "meas_13: ════════════════════════════════════════════════════════════════╩══╬═\n",
       "                                                                            ║ \n",
       "meas_14: ═══════════════════════════════════════════════════════════════════╩═\n",
       "                                                                              "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator = qiskit.Aer.get_backend('qasm_simulator')\n",
    "\n",
    "circuit = QuantumCircuit(15, simulator, 100)\n",
    "print('Expected value for rotation pi {}'.format(circuit.run([np.pi])[0]))\n",
    "circuit._circuit.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create a \"Quantum-Classical Class\" with PyTorch <a id='qc-class'></a>\n",
    "Now that our quantum circuit is defined, we can create the functions needed for backpropagation using PyTorch. [The forward and backward passes](http://www.ai.mit.edu/courses/6.034b/backprops.pdf) contain elements from our Qiskit class. The backward pass directly computes the analytical gradients using the finite difference formula we introduced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridFunction(Function):\n",
    "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input, quantum_circuit, shift):\n",
    "        \"\"\" Forward pass computation \"\"\"\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "\n",
    "        expectation_z = ctx.quantum_circuit.run(input[0].tolist())\n",
    "        result = torch.tensor([expectation_z])\n",
    "        ctx.save_for_backward(input, result)\n",
    "\n",
    "        return result\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\" Backward pass computation \"\"\"\n",
    "        input, expectation_z = ctx.saved_tensors\n",
    "        input_list = np.array(input.tolist())\n",
    "        \n",
    "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
    "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
    "        \n",
    "        gradients = []\n",
    "        for i in range(len(input_list)):\n",
    "            expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
    "            expectation_left  = ctx.quantum_circuit.run(shift_left[i])\n",
    "            \n",
    "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "            gradients.append(gradient)\n",
    "        gradients = np.array([gradients]).T\n",
    "        return torch.tensor([gradients]).float() * grad_output.float(), None, None\n",
    "\n",
    "class Hybrid(nn.Module):\n",
    "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots, shift):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(n_qubits, backend, shots)\n",
    "        self.shift = shift\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return HybridFunction.apply(input, self.quantum_circuit, self.shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">         ┌───┐ ░ ┌───────────┐ ░ ┌─┐                                          \n",
       "    q_0: ┤ H ├─░─┤ RY(theta) ├─░─┤M├──────────────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░ └╥┘┌─┐                                       \n",
       "    q_1: ┤ H ├─░─┤ RY(theta) ├─░──╫─┤M├───────────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║ └╥┘┌─┐                                    \n",
       "    q_2: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫─┤M├────────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║ └╥┘┌─┐                                 \n",
       "    q_3: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫─┤M├─────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║ └╥┘┌─┐                              \n",
       "    q_4: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫─┤M├──────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║ └╥┘┌─┐                           \n",
       "    q_5: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫─┤M├───────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║ └╥┘┌─┐                        \n",
       "    q_6: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫─┤M├────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║ └╥┘┌─┐                     \n",
       "    q_7: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫─┤M├─────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐                  \n",
       "    q_8: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫─┤M├──────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐               \n",
       "    q_9: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├───────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐            \n",
       "   q_10: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐         \n",
       "   q_11: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├─────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐      \n",
       "   q_12: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├──────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐   \n",
       "   q_13: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├───\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐\n",
       "   q_14: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├\n",
       "         └───┘ ░ └───────────┘ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘\n",
       " meas_0: ═════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                     ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_1: ════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                        ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_2: ═══════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                           ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_3: ══════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                              ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_4: ═════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                 ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_5: ════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                    ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_6: ═══════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                       ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_7: ══════════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                          ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_8: ═════════════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬═\n",
       "                                                             ║  ║  ║  ║  ║  ║ \n",
       " meas_9: ════════════════════════════════════════════════════╩══╬══╬══╬══╬══╬═\n",
       "                                                                ║  ║  ║  ║  ║ \n",
       "meas_10: ═══════════════════════════════════════════════════════╩══╬══╬══╬══╬═\n",
       "                                                                   ║  ║  ║  ║ \n",
       "meas_11: ══════════════════════════════════════════════════════════╩══╬══╬══╬═\n",
       "                                                                      ║  ║  ║ \n",
       "meas_12: ═════════════════════════════════════════════════════════════╩══╬══╬═\n",
       "                                                                         ║  ║ \n",
       "meas_13: ════════════════════════════════════════════════════════════════╩══╬═\n",
       "                                                                            ║ \n",
       "meas_14: ═══════════════════════════════════════════════════════════════════╩═\n",
       "                                                                              </pre>"
      ],
      "text/plain": [
       "         ┌───┐ ░ ┌───────────┐ ░ ┌─┐                                          \n",
       "    q_0: ┤ H ├─░─┤ RY(theta) ├─░─┤M├──────────────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░ └╥┘┌─┐                                       \n",
       "    q_1: ┤ H ├─░─┤ RY(theta) ├─░──╫─┤M├───────────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║ └╥┘┌─┐                                    \n",
       "    q_2: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫─┤M├────────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║ └╥┘┌─┐                                 \n",
       "    q_3: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫─┤M├─────────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║ └╥┘┌─┐                              \n",
       "    q_4: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫─┤M├──────────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║ └╥┘┌─┐                           \n",
       "    q_5: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫─┤M├───────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║ └╥┘┌─┐                        \n",
       "    q_6: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫─┤M├────────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║ └╥┘┌─┐                     \n",
       "    q_7: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫─┤M├─────────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐                  \n",
       "    q_8: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫─┤M├──────────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐               \n",
       "    q_9: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├───────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐            \n",
       "   q_10: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├────────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐         \n",
       "   q_11: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├─────────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐      \n",
       "   q_12: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├──────\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐   \n",
       "   q_13: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├───\n",
       "         ├───┤ ░ ├───────────┤ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘┌─┐\n",
       "   q_14: ┤ H ├─░─┤ RY(theta) ├─░──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫──╫─┤M├\n",
       "         └───┘ ░ └───────────┘ ░  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ └╥┘\n",
       " meas_0: ═════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                     ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_1: ════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                        ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_2: ═══════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                           ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_3: ══════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                              ║  ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_4: ═════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                 ║  ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_5: ════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                    ║  ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_6: ═══════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                       ║  ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_7: ══════════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬══╬═\n",
       "                                                          ║  ║  ║  ║  ║  ║  ║ \n",
       " meas_8: ═════════════════════════════════════════════════╩══╬══╬══╬══╬══╬══╬═\n",
       "                                                             ║  ║  ║  ║  ║  ║ \n",
       " meas_9: ════════════════════════════════════════════════════╩══╬══╬══╬══╬══╬═\n",
       "                                                                ║  ║  ║  ║  ║ \n",
       "meas_10: ═══════════════════════════════════════════════════════╩══╬══╬══╬══╬═\n",
       "                                                                   ║  ║  ║  ║ \n",
       "meas_11: ══════════════════════════════════════════════════════════╩══╬══╬══╬═\n",
       "                                                                      ║  ║  ║ \n",
       "meas_12: ═════════════════════════════════════════════════════════════╩══╬══╬═\n",
       "                                                                         ║  ║ \n",
       "meas_13: ════════════════════════════════════════════════════════════════╩══╬═\n",
       "                                                                            ║ \n",
       "meas_14: ═══════════════════════════════════════════════════════════════════╩═\n",
       "                                                                              "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantum_circ = Hybrid(15, qiskit.Aer.get_backend('qasm_simulator'), 100, np.pi / 2)\n",
    "quantum_circ.quantum_circuit._circuit.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Data Loading and Preprocessing <a id='data-loading-preprocessing'></a>\n",
    "##### Putting this all together:\n",
    "We will create a simple hybrid neural network to classify images of two types of digits (0 or 1) from the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). We first load MNIST and filter for pictures containing 0's and 1's. These will serve as inputs for our neural network to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concentrating on the first 100 samples\n",
    "n_samples = 100\n",
    "\n",
    "X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Leaving only labels 0 and 1 \n",
    "idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \n",
    "                np.where(X_train.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAABxCAYAAAA6YcICAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAVEklEQVR4nO3de7RNVd8H8O90d9JDqHhzeUZvurgkUSmNHnqF3IWRUjEiKqNQwlvq1St6ukiupfS4vY3SBRElDI5LIY1S9LqkQeIVSSKXpPX+sc/6nd9hLXvvc9bea689v58xGuN71ll77Xnm2daZzbnmnMZxHBARERHZoljYBSAiIiJKJzZ+iIiIyCps/BAREZFV2PghIiIiq7DxQ0RERFZh44eIiIiskjGNH2PMcmNM7yi9Npuw/sPDug8X6z9crP/w2Fz3gTd+jDE7jDHNg75upjDGDDTG7DXGHDLG/MsYUzrsMmms//Bkc90bY+oaYxYZY342xmTk4mDZXP9AZn/2AdZ/mLK57lN178mYnp8oMMa0BDAUwH8A+DuAiwE8HWaZbML6D9VJAO8A6BV2QWzEz364WP+hSsm9J22NH2PMecaYD40x+40xB/NytdNO+3djzLq8lvUHxpiK6vWNjTGfGmN+NcZsMMY0Pct73WuM+d+891lkjKmpvneLMWZz3ntMAGCS+DF6AHjDcZxNjuMcBDACQM8kXh8a1n94sqHuHcfZ4jjOGwA2Jf6TZ4ZsqH9E9LMPsP7DlA11n6p7Tzp7fooBmAqgJoAaAI4BmHDaOfcAuBfAvwH4E8A4ADDGXARgAYBnAFQEMAjA+8aY809/E2NMRwCPA7gNwPkAVgJ4K+97lQG8D2AYgMoAtgNool5bI++XXMPnZ6gDYIP6egOAC40xlRKqgXCx/sOTDXUfZdlQ/1H97AOs/zBlQ92nhuM4gf4HYAeA5gmcdxWAg+rr5QD+qb6uDeAPAMUBDAEw87TXLwLQQ722d17+CEAvdV4xAEcR++XfA2CN+p4B8KP72gTKvB1AK/V1SQAOgL8HXY+s/+jVfzbXvXrdJbHbRvj1bVP9Z/pnn/XPuo/avSedw145xpjJxpidxpjfAKwAUMEYU1ydtkvlnYh9wCojVoFd81qHvxpjfgVwI4CqHm9VE8BYdd4viFX2RYi1bOU9nFiN7vK4hp8jAP6mvnbz4SSuEQrWf3iypO4jK0vqP5KffYD1H6YsqfuUSOew16MALgNwneM4fwNwU95xPfZXXeUaiD3o9DNiFTXTcZwK6r9zHMf5p8f77ALQ97RzyzqO8ymA/9PvYYwxp71nPJsA1Fdf1wfwk+M4B5K4RlhY/+HJhrqPsmyo/6h+9gHWf5iyoe5TIlWNn5LGmDLqvxIAzkVsvPFXE3ug6r88XneXMaa2MSYHwH8DeM9xnFMA/gdAO2NMS2NM8bxrNjVnPrgFAK8C+E9jTB0AMMaUN8Z0zfveAgB1jDG35ZXpYQBVkvi5ZgDolVfG8xAbw5yWxOvThfUfnqysexNTBkCpvK/LmAya6qtkZf0jGp99gPUfpqys+5Tde4IaP1PjcjsQGwvV/z2DWNfXcsS6D7cC6Jv3vRJO/vjhswDWAfgNwHwAldV1rwOQi1h32n7EKrSGem1vde7dAL7Ju84uAP9S32uV9/6HEHvwKxf545Y18spX4yw/3yMAfsq79lQApYOuQ9Z/NOs/m+sesem9p/9sO8Kuc1vqP9M/+6x/1n2q6h4puveYvIsTERERWYGLHBIREZFV2PghIiIiq7DxQ0RERFZh44eIiIiswsYPERERWaVEMiebALeTt5HjOMlspFcA677IfnYc54w9aRLF+i8y1n+IeO8JFT/74fKsf/b8kC12hl0Ay7H+yVb87IfLs/7Z+CEiIiKrsPFDREREVmHjh4iIiKzCxg8RERFZhY0fIiIisgobP0RERGQVNn6IiIjIKmz8EBERkVWSWuE5qkaPHp3wuStWrJC8ePFiyUePHg20TGS3rl27Sn777bcljxo16ox87Nix9BWMxGWXXQYA6NGjhxy74YYbJLdr107y4cOH01cwSlrTpk0BAEuXLpVjxYoVO+P7AJCbm5uuYmUdx8lfjPqvv/6S3KRJEwDAmjVr0l4mP+z5ISIiIquw8UNERERWMbqbKu7JGb7BWt26dSUPHDhQcs+ePSXH+3mNyd//7/bbb5f83nvvFbl82bC5YLly5SQPGzZM8uDBgyXrOly1apXkuXPnAgBefvllOXbq1KmUlNPDF47jNCrsi4Oo/06dOkmeNm2a5JycHM/zR44cCQAYPnx4Ud86E4Re/4moWLGi5BEjRgAAHnjgAc9z9XDYzJkzU1uwIsqGe0+y9H3/oYceAgBceeWVckwPe3311VeSZ8yYIXnixImS//zzz8IWJRKf/SDo+7ke9tqzZw+Agn9T0zgE5ln/7PkhIiIiq7DxQ0RERFaJ/GwvPZQwdepUyXp4hoqmVKlSknX3fvv27SWvXr1a8vbt2yXfddddkt2ZMlOmTJFjhw4dCrawGeyee+6R7DfUpT322GMAgBMnTsixZ599NviCkXjzzTclt2zZ8qznDh06VHLp0qUlL1u2TLL+t0Cpp4e67r77bsl6uMuL/v6LL74o2R2qB4CdO3cGUMLsM2vWLMn6kQc9rFi9enUAQLVq1dJXsDjY80NERERWYeOHiIiIrBLJYa+2bdtK1k/mly1bNu5rFyxYcMaxNm3aeJ7boEEDyUHM9ooqPatLD3UdOHBAcrNmzSTrWRFPPPGE5Hnz5gEAtmzZIsf04mKbN28OpsAZSg976aGR+vXre57vDjfq+v/tt98k65koVHiNGzeWfNVVVyX8uiuuuELya6+9JlnPeJkzZ45k997j/jsAgIMHDyZXWItVqFBBsv496ccdKleuLLlMmTJnXEPfY/SwzKWXXhpYOW2jZ1D7LXLo1nUys8tTjT0/REREZBU2foiIiMgqkVnk8Nxzz5WsZwj5lf/IkSOSBw0aJPn1118/41w9g6l79+6e127VqpVkvedXMqK20Ni1114LAFi+fLkc07Na9GyYJUuWxL1elSpVAADbtm2TY3pxxFdeeaXQZU1ARi005u4bBQAbN25M+HV6+LV///6S9+3bF0zBUiej6v+iiy6SvH79eskXXnhhka+tZ7x43Z/0gnpjx46VrGcWBT0LMmr3HlfHjh0l33fffZJbtGghWQ9f6aEWL7169fJ8ndffBQC45JJLJBdhtldGffaD4Lc3od9n371v6UUO04iLHBIRERGx8UNERERWyfjZXu5MjEmTJskxv6fL9eyjZ555RrJfl6bL3cMHAO68807Pa+vu0sIOe0VB8eLFJbtdzr///rscc/fIAQoOhyVi7969AAru7fXSSy9J/vHHHyXPnz8/qWtHjVsXQMF9vvQibV66dOkiWS+U2KFDh8DKZgM9M7SwQ116GOTbb7+VXLJkScnNmzc/43V+M5XcRUABoG/fvoUqU7ZwF0edPn163HP18FU8elimsNeggrxmdZ1+fMyYMWktUyL4GyciIiKrsPFDREREVsnIYS+96Ji7l5Hf3ix6qEs/gb5ixYqE32/r1q2S9ZPr+sn0m2++WXKTJk0k6z2tssE111wjeciQIQAKLmCYTL36mTBhguQ+ffpIbtQo/4H8bB/20rN59GxE3W3szjzUQ5Fa69atJes9qfSMRcqnh7r0sHg848aNk6wXztO/Q/ffClDw9/Xoo49KbtiwIQDg+uuvl2N6r6Nu3bp5XlvPiMxmeh9Ad2hcD50cP35c8k8//SRZzwSuWLGi57Xd1+pFQsuXLy853iwxKkj/jdb3LL+9vdasWZOegiWBPT9ERERklYxZ50e33nNzcyV79fjoB3D1//0G0Quj/6/Z72E7/fCWu/N2IqKw1obucSlRItYx2K5dOzmmt64IwsKFCyXrJeb1+hoBidxaG+5DtLVq1Yp7rl62X28psm7dOsn6IesQhF7/VatWlbx79+6457sP4N94441y7IcffpB83nnnSU5mmwp3vSug4EQKPZlAP8xer149yYVdayZT7z16HZ/3339fsldPjP67oB8k15ME/Ca3PPLIIwCA8ePHJ/U6rvPjTW/hksgDz3oSQAi4zg8RERERGz9ERERklYx54DmRXa5d+uHjL774ItBy6Ad6/daEcB9czBbnn3++ZP3Ac+fOnQEEP9SlzZo1S/Jzzz3nWab9+/en7P0zmbvdh14LyU/t2rUl6+EDvau4281/9OjRgEoYLfqB+kR88803AAoOdWmF3ZFdDz+OHDlScqVKlSQPGDBAcshDBoHTw016zS/NfUB57dq1cuzhhx+Oe+0NGzZI1o8teG2do7eK0VtnuNv6kD+/B5v9jmeizC4dERERUcDY+CEiIiKrpH3YS3ft6nUtGjRoINlrywq9/k7QQ11+/GbC6Vkj2aBfv36Sv/zyS8npWMNId03rtVeaNm0q+d133015OTLRq6++CgD4/PPP5diDDz4o+Y477oh7jU6dOkm+//77Adg77HXLLbckdf6nn36aopJ409vm6GEvvQ6U+zuMsieffFLyOeec43nOqFGjAOSv83Y2q1atkvzRRx9J1msBeTly5IjkEydOxH0fyqf/NiYy2ysTseeHiIiIrMLGDxEREVkl7cNeutv26aefjnv+5MmTAQBPPfVUysqkJbK4XjILQ0aB3q5DLyQWJj37wtZhr5MnTwIouDS8Hh7Wi09WqFAh7vVWrlwJAKhTp05QRYwUPYSiFxTU3DoCCs7ESgc9ZPP1119L1ju86zLt2rUrPQULgN7JXi9oq4dJ/LZxiee7774rfMHyRGmWUiZIZLZXJm5pofG3TERERFZh44eIiIiskpZhr7Zt20rWe9n40fusJLP7chDmzp0b95wRI0akoSR2mz17dthFyEhei7UBwIQJEyT7zbJw96Jq1aqVHPv4448DLF10ZPrQtS6fznrmV//+/dNapmTVrVtXsl54U++JFuaMoHLlykkuVaqU5EyfpRSWgQMHSk5ktpffApaZgj0/REREZBU2foiIiMgqKRv2KlEi/9J6tkLNmjU9z9+9e7fkMWPGSP7jjz9SUDogJydH8uDBgyXrmQi6a2/q1KmS33rrrZSUyXZ6UbmOHTtKdhf7o4L0EJge9vLj7pc2ceJEOdanTx/JS5cuDbB0mUfvUXf48GHJ+t98mTJlJJctWxYAcOzYsTSUrqBffvkl7e8ZtHHjxkmuUaNGiCXx1qVLF8nczyu+xo0bS/ab7aX/juucidjzQ0RERFZh44eIiIiskrJhr2HDhkm+9dZbJfvNsmjevLnkrVu3pqpYonfv3pJ1WXX5dNe4Hoqj1Lj44osl6/2sKL42bdpInj9//lnP1UMQ1atXT1mZMs3+/fslT5o0SfKQIUMkN2rUSHLr1q0BFJyplC561mmzZs3S/v7poh85SIfLL79c8vPPP+95zo4dOyQfP3481UWKDL8ZiHq2l350gYscEhEREWWQlPX86J17/Xp7dA9POnp7gPw1evyWt9f0z7Bp06aUlclm+sFzvf7H2LFjwyhOZOkl/tevXy9Z92R40VubzJkzR/KhQ4cCLF3meeONNyTrnh/NXVNH/9vfvHlzysqkf1fpXt8sLAcOHEjL+7g9Ph988IEcq1SpkuR9+/ZJ1g9Cx9sZPtt17drVM/s98NytW7f0FCwA7PkhIiIiq7DxQ0RERFZJ+67u2m233Zayazds2FCy7s53h1bcNTxO16lTJ8mLFy9OUekyl986TKmid2/XXeBbtmxJazmiTg976TqdNm2a5Pr165/xup49e0rW3deJbEMTZUePHpW8d+9eyVWqVJF83XXXAQBWrFghx2bNmiV54cKFcd9HPzC7bt06AMBNN90kx/QwwdVXXy1Zrz0UVYnslK7XT5sxY0aR31NvWaGv16FDhzPO/f777yXrLZh47/Hmt41FVLcDYc8PERERWYWNHyIiIrJKyoa9EukW012Uer0Rv6XnXXqNnilTpkjWs7N0t73ufj1x4gQAYNmyZXJMD7/p97aFXpvh3nvvlVy6dGkA+XUWFP17b9GihWR3Jh4VzcaNGyXrmUr16tUD4D8E0b17d8l6WCiRmZFRs2fPHsl6qFsPkbtDYJUrV5Zj/fr188yavt+cPHlSsjs0qdeayWZ6xpoeLixfvrzn+fqe7M4Q1rOz9HCUXh9I17fenV1vWeF+nkeNGiXHZs+e7Xltyqd/b3rWdiJDmpkumqUmIiIiKiQ2foiIiMgqxm8BQs+TjUn45F27dkmuWrVqIteWrBc8rFWr1lnPTaT8a9eulezOAJg8eXLc1wXNcRwT/yxvydR9UejFvpYsWQKg4BBiUXa4docRFi1aJMf0ju16l/IU+MJxnLOv+HcW6ar/VHIXbKtYsWLcc+fNmye5c+fOQbx9JOrfneEF5A+5XHDBBUldI9n7Uzzbtm2T3LJlS8l6G4Z4wr73/OMf/5CstwvRQ2CFnUHk97rc3FzJ7n0/iBllhRCJz76XU6dOSU5ktlfJkiXTU7DkeNY/e36IiIjIKmz8EBERkVVSNttL7+T+4YcfSq5WrVrc13oNdfn57LPPJOvZAnoBskzfXTaTTJ8+XXL//v0BFOzG1zPt9BCY36KRelaGO5NMH9PDK0Rh00PktWvXBgD07dtXjunPrt+spSDoRSsLO9SVSfQQlF5ss0+fPpKHDRtWqGvrRSpXrlwpWf/esn2vulTxm9XF2V5EREREEcPGDxEREVklZbO9tEqVKkn2Gx4ZMGCAZF0mt/tXzxjTCxvq/aCKMhMpHcKecZGsHj16ACg4I0svIrZgwQLJbdq08byGXizPnTX2zjvvBFrOBEV2xkVQGjWK/fh6n6OhQ4d6nmvrbK94cnJyJLvDwkDBhTsff/xxyZ988onk9evXn3E9PSt25syZkvUsG70/WGFF4d7j3m8AYNCgQQAKLgi5efNmyS+88ILk7du3S169enUqi1hYkf3s63rWf6P1UNfo0aMl62HhDMLZXkRERERs/BAREZFV0jLsRTFR6Hr2omdnDB8+XHL79u0l79+/X7JexGz8+PGSdbd1CCLb9ZwlWP8hiuq9J0vwsx8uDnsRERERpWydH8oeGzZskKx3wCYiIooi9vwQERGRVdj4ISIiIquw8UNERERWYeOHiIiIrMLGDxEREVmFjR8iIiKyChs/REREZBU2foiIiMgqyS5y+DOAnakoiAVqFvH1rPuiYf2Hi/UfHtZ9uFj/4fKs/6T29iIiIiKKOg57ERERkVXY+CEiIiKrsPFDREREVmHjh4iIiKzCxg8RERFZhY0fIiIisgobP0RERGQVNn6IiIjIKmz8EBERkVX+H6qrMOgs7MuyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x216 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples_show = 6\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "while n_samples_show > 0:\n",
    "    images, targets = data_iter.__next__()\n",
    "\n",
    "    axes[n_samples_show - 1].imshow(images[0].numpy().squeeze(), cmap='gray')\n",
    "    axes[n_samples_show - 1].set_xticks([])\n",
    "    axes[n_samples_show - 1].set_yticks([])\n",
    "    axes[n_samples_show - 1].set_title(\"Labeled: {}\".format(targets.item()))\n",
    "    \n",
    "    n_samples_show -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "\n",
    "X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                        transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "idx = np.append(np.where(X_test.targets == 0)[0][:n_samples], \n",
    "                np.where(X_test.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have loaded the data and coded a class that creates our quantum circuit which contains 1 trainable parameter. This quantum parameter will be inserted into a classical neural network along with the other classical parameters to form the hybrid neural network. We also created backward and forward pass functions that allow us to do backpropagation and optimise our neural network. Lastly, we need to specify our neural network architecture such that we can begin to train our parameters using optimisation techniques provided by PyTorch. \n",
    "\n",
    "\n",
    "### 3.5 Creating the Hybrid Neural Network <a id='hybrid-nn'></a>\n",
    "We can use a neat PyTorch pipeline to create a neural network architecture. The network will need to be compatible in terms of its dimensionality when we insert the quantum layer (i.e. our quantum circuit). Since our quantum  in this example contains 1 parameter, we must ensure the network condenses neurons down to size 1. We create a typical Convolutional Neural Network with two fully-connected layers at the end. The value of the last neuron of the fully-connected layer is fed as the parameter $\\theta$ into our quantum circuit. The circuit measurement then serves as the final prediction for 0 or 1 as provided by a $\\sigma_z$ measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 5)\n",
    "        self.hybrid1 = Hybrid(5, qiskit.Aer.get_backend('qasm_simulator'), 100, np.pi / 2)\n",
    "        self.fc3 = nn.Linear(5,1)\n",
    "        self.hybrid2 = Hybrid(1, qiskit.Aer.get_backend('qasm_simulator'), 100, np.pi / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.hybrid1(x)\n",
    "        x = self.fc3(x.float())\n",
    "        x = self.hybrid2(x)\n",
    "        return torch.cat((x, 1 - x), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Training the Network <a id='training'></a>\n",
    "We now have all the ingredients to train our hybrid network! We can specify any [PyTorch optimiser](https://pytorch.org/docs/stable/optim.html), [learning rate](https://en.wikipedia.org/wiki/Learning_rate) and [cost/loss function](https://en.wikipedia.org/wiki/Loss_function) in order to train over multiple epochs. In this instance, we use the [Adam optimiser](https://arxiv.org/abs/1412.6980), a learning rate of 0.001 and the [negative log-likelihood loss function](https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 1], m2: [5 x 1] at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-m3brw02t\\aten\\src\\TH/generic/THTensorMath.cpp:136",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-719b6d3e9a3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Calculating loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-80-3e723797caff>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhybrid1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhybrid2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 1], m2: [5 x 1] at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-m3brw02t\\aten\\src\\TH/generic/THTensorMath.cpp:136"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "epochs = 20\n",
    "loss_list = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        # Calculating loss\n",
    "        loss = loss_func(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Neg Log Likelihood Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Testing the Network <a id='testing'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(\n",
    "        sum(total_loss) / len(total_loss),\n",
    "        correct / len(test_loader) * 100)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title('Predicted {}'.format(pred.item()))\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What Now? <a id='what-now'></a>\n",
    "\n",
    "#### While it is totally possible to create hybrid neural networks, does this actually have any benefit? \n",
    "\n",
    "In fact, the classical layers of this network train perfectly fine (in fact, better) without the quantum layer. Furthermore, you may have noticed that the quantum layer we trained here **generates no entanglement**, and will, therefore, continue to be classically simulatable as we scale up this particular architecture. This means that if you hope to achieve a quantum advantage using hybrid neural networks, you'll need to start by extending this code to include a more sophisticated quantum layer. \n",
    "\n",
    "\n",
    "The point of this exercise was to get you thinking about integrating techniques from ML and quantum computing in order to investigate if there is indeed some element of interest - and thanks to PyTorch and Qiskit, this becomes a little bit easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "qiskit.__qiskit_version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03685b39e42d42f5847d4661e55037b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b8d5e3ae0b724fbda8f85bc652c2546f",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d39f9a7893d44acfa69d3ae2cc7e78bc",
       "value": 1
      }
     },
     "0ca977dfbb784facb124f2af7ba5c65c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1228832637e84285bb3561d2d4bb3289": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2fe4322d4fc846179d1a31452b9538f0",
        "IPY_MODEL_419a034357bd4ab180ccd9ea4b5b4a5b"
       ],
       "layout": "IPY_MODEL_b5ed9f20e72a4e8e914e852d19ac81d3"
      }
     },
     "1aabbc3ce54d436db993fa91c6cfbe50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "242d6437e1e8430589c3a5417601b137": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_28a22f1ff61a4badbf886da28d49ca84",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ba88f8b7b9324bc0b835e2f6e0c4c3ea",
       "value": 1
      }
     },
     "28a22f1ff61a4badbf886da28d49ca84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ba09042bf3d4c94a3b6659386137e74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_32f3a21895da4431bf9f5a8c1cc0a4c5",
       "placeholder": "​",
       "style": "IPY_MODEL_c83d593544ff45348b36d7639341a88e",
       "value": " 8192/? [00:00&lt;00:00, 24497.25it/s]"
      }
     },
     "2fe4322d4fc846179d1a31452b9538f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8d385e665a554aae879157e3f7d37bf5",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_634610351f774d8c8b33b12e5cd18333",
       "value": 1
      }
     },
     "32f3a21895da4431bf9f5a8c1cc0a4c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "34f51e734a864fe9a72fb7462e79fa08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "419a034357bd4ab180ccd9ea4b5b4a5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0ca977dfbb784facb124f2af7ba5c65c",
       "placeholder": "​",
       "style": "IPY_MODEL_a460764bec3a406db99921fbde2cc4c9",
       "value": " 9920512/? [00:03&lt;00:00, 3037004.71it/s]"
      }
     },
     "463ae78c6c0944d1a38d0731cbd4c8da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fea957dacd6c4c41aec04c5b2bf46a94",
       "placeholder": "​",
       "style": "IPY_MODEL_5d85f1c9f8c64fcfbd541cc24b28453b",
       "value": " 1654784/? [00:01&lt;00:00, 1342577.10it/s]"
      }
     },
     "473d0404bd2b480fb59f08fe4901e7d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4bba676834944c57ac231e5d14e8cfef",
        "IPY_MODEL_463ae78c6c0944d1a38d0731cbd4c8da"
       ],
       "layout": "IPY_MODEL_6629277b337f4058a4c88e357205ced2"
      }
     },
     "47bc5f0c1d314e239bf496e093ee07b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4bba676834944c57ac231e5d14e8cfef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b800834365734370852035d9588e0252",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1aabbc3ce54d436db993fa91c6cfbe50",
       "value": 1
      }
     },
     "5d85f1c9f8c64fcfbd541cc24b28453b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "62cab7f3edd441e6bc526aa14797c8a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_975b89a4787346e2b12ff6943d581134",
       "placeholder": "​",
       "style": "IPY_MODEL_cfd1498b96d34effa8fd08545a80939f",
       "value": " 32768/? [00:01&lt;00:00, 21033.52it/s]"
      }
     },
     "634610351f774d8c8b33b12e5cd18333": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "6629277b337f4058a4c88e357205ced2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d385e665a554aae879157e3f7d37bf5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "975b89a4787346e2b12ff6943d581134": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a460764bec3a406db99921fbde2cc4c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b5ed9f20e72a4e8e914e852d19ac81d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b800834365734370852035d9588e0252": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8d5e3ae0b724fbda8f85bc652c2546f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba88f8b7b9324bc0b835e2f6e0c4c3ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "bc479f7e6d574605b51b1edf5e856e57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_242d6437e1e8430589c3a5417601b137",
        "IPY_MODEL_2ba09042bf3d4c94a3b6659386137e74"
       ],
       "layout": "IPY_MODEL_34f51e734a864fe9a72fb7462e79fa08"
      }
     },
     "c83d593544ff45348b36d7639341a88e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cfd1498b96d34effa8fd08545a80939f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d39f9a7893d44acfa69d3ae2cc7e78bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f2e7e0077d824337af244cb353bfd0f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_03685b39e42d42f5847d4661e55037b1",
        "IPY_MODEL_62cab7f3edd441e6bc526aa14797c8a2"
       ],
       "layout": "IPY_MODEL_47bc5f0c1d314e239bf496e093ee07b9"
      }
     },
     "fea957dacd6c4c41aec04c5b2bf46a94": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
