{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals.\n",
    "#\n",
    "# Code adapted from QizGloria team, Qiskit Camp Europe 2019, updated by \n",
    "# Team Ube Pancake, Qiskit Summer Jam 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumRegister,QuantumCircuit,ClassicalRegister,execute\n",
    "from qiskit.circuit import Parameter,ControlledGate\n",
    "from qiskit import Aer\n",
    "import qiskit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "\n",
    "NUM_QUBITS = 1\n",
    "NUM_SHOTS = 10000\n",
    "SHIFT = 0.01\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.5\n",
    "\n",
    "SIMULATOR = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to translate Q-Circuit parameters from pytorch back to QISKIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Contruct QuantumCircuit QFT Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:09:30.598730Z",
     "start_time": "2019-10-01T16:09:30.567861Z"
    }
   },
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self.circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        self.n_qubits = n_qubits\n",
    "        self.thetas ={k : Parameter('Theta'+str(k))for k in range(self.n_qubits)}\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.circuit.h(all_qubits)\n",
    "        self.circuit.barrier()\n",
    "        for k in range(n_qubits):\n",
    "            self.circuit.ry(self.thetas[k], k)\n",
    "        \n",
    "#         # Apply controlled-unitary\n",
    "# #         uc=ry(self.theta4, 4).to_gate().control(4)\n",
    "# #         self.circuit.append(uc, [0,1,2,3,4])\n",
    "#         self.circuit.ry(self.theta4, 4).to_gate().control(4)\n",
    "    \n",
    "        self.circuit.barrier()\n",
    "        self.circuit.measure_all()\n",
    "        # ---------------------------\n",
    "        \n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects  \n",
    "    \n",
    "    def run(self, i):\n",
    "        params = i\n",
    "#         print('params = {}'.format(len(params)))\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        try:\n",
    "            job_sim = execute(self.circuit,\n",
    "                              self.backend,\n",
    "                              shots=self.shots,\n",
    "                              parameter_binds = [{self.thetas[k] : params[k] for k in range(NUM_QUBITS)}])\n",
    "        except:\n",
    "            job_sim = execute(self.circuit,\n",
    "                              self.backend,\n",
    "                              shots=self.shots,\n",
    "                              parameter_binds = [{self.thetas[k] : params[k].item() for k in range(NUM_QUBITS)}])\n",
    "        \n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,NUM_QUBITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value for rotation [pi/4]: [0.7158]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐ ░ ┌────────────┐ ░  ░ ┌─┐\n",
       "   q_0: ┤ H ├─░─┤ RY(Theta0) ├─░──░─┤M├\n",
       "        └───┘ ░ └────────────┘ ░  ░ └╥┘\n",
       "meas_0: ═════════════════════════════╩═\n",
       "                                       </pre>"
      ],
      "text/plain": [
       "        ┌───┐ ░ ┌────────────┐ ░  ░ ┌─┐\n",
       "   q_0: ┤ H ├─░─┤ RY(Theta0) ├─░──░─┤M├\n",
       "        └───┘ ░ └────────────┘ ░  ░ └╥┘\n",
       "meas_0: ═════════════════════════════╩═\n",
       "                                       "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit = QiskitCircuit(NUM_QUBITS, SIMULATOR, NUM_SHOTS)\n",
    "print('Expected value for rotation [pi/4]: {}'.format(circuit.run([np.pi/4]*NUM_QUBITS)))\n",
    "circuit.circuit.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchCircuit()\n",
    "\n",
    "A pytorch layer always has two functions. One for the forward pass and one for the backward pass. The forward pass simply takes the Quantum Circuits variational parameters from the previous pytorch layer and runs the circuit on the defined hardware (defined in `QiskitCircuit.run()`) and returns the measurements from the quantum hardware.\n",
    "These measurements will be the inputs of the next pytorch layer.\n",
    "\n",
    "The backward pass returns the gradients of the quantum circuit. In this case here it is finite difference.\n",
    "\n",
    "the `forward_tensor` is saved from the forward pass. So we just have to do one evaluation of the Q-Circuit in the backpass for the finite difference.\n",
    "\n",
    "The `gradient` variable here is as well hard coded to 3 parameters. This should be updated in the future and made more general.\n",
    "\n",
    "The loop `for k in range(len(input_numbers)):` goes through all the parameters (in this case 3), and shifts them by a small $\\epsilon$. Then it runs the circuit and takes the diefferences of the ouput for the parameters $\\Theta$ and $\\Theta + \\epsilon$. This is the finite difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(NUM_QUBITS, SIMULATOR, shots=NUM_SHOTS)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i)\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "#         eps = 0.01\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors\n",
    "#         print('forward_tensor = {}'.format(forward_tensor))\n",
    "        input_numbers = i\n",
    "#         print('input_numbers = {}'.format(input_numbers))\n",
    "        gradients = torch.Tensor()\n",
    "        \n",
    "        for k in range(len(input_numbers)):\n",
    "            shift_right = input_numbers\n",
    "            shift_right[k] = input_numbers[k] + SHIFT\n",
    "            shift_left = input_numbers\n",
    "            shift_left[k] = input_numbers[k] - SHIFT\n",
    "            \n",
    "            expectation_right = ctx.QiskitCirc.run(shift_right)\n",
    "            expectation_left  = ctx.QiskitCirc.run(shift_left)\n",
    "#             print('expectation_right = {}, \\nexpectation_left = {}'.format(expectation_right,\n",
    "#                                                                           expectation_left))\n",
    "            \n",
    "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "            gradients = torch.cat((gradients, gradient.float()))\n",
    "# #             print(k)\n",
    "#             input_eps = input_numbers\n",
    "#             input_eps[k] = input_numbers[k] + eps\n",
    "# #             print('input_eps = {}'.format(input_eps))\n",
    "#             exp_value = ctx.QiskitCirc.run(input_eps)\n",
    "#             print('exp_value = {}'.format(exp_value))\n",
    "#             print('forward_tensor[0][k] = {}'.format(forward_tensor[0][k]))\n",
    "#             gradient = (exp_value - forward_tensor[0][k].item())\n",
    "#             gradients.append(gradient)\n",
    "            \n",
    "#         print('gradients = {}'.format(gradients))\n",
    "        result = torch.Tensor(gradients)\n",
    "\n",
    "        return result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 after quantum layer: tensor([[0.7102]], dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "x.grad = tensor([-1.0682e-05])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([np.pi/4]*NUM_QUBITS, requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "print('y1 after quantum layer: {}'.format(y1))\n",
    "y1 = nn.Linear(NUM_QUBITS,1)(y1.float())\n",
    "y1.backward()\n",
    "print('x.grad = {}'.format(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Quantum Circuit's Gradient Descent\n",
    "\n",
    "First, we want the \"neural net\" consisting of just the quantum circuit (with its 4 inputs and 4 outputs) and a linear layer (from 4 inputs to 1 output) to converge to a target value (-1). So, we define a cost function where the cost is defined as the square distance from the target value.\n",
    "\n",
    "`x` is the initialization of the parameters. Here, every angle in the quantum circuit starts at $\\pi/4$. We should see that the loss eventually goes down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████▏                              | 62/100 [00:03<00:02, 17.35it/s]"
     ]
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)[0]\n",
    "    # simple linear layer: average all outputs of quantum layer\n",
    "    val = torch.sum(expval) / NUM_QUBITS\n",
    "    return torch.abs(val - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([np.pi/4]*NUM_QUBITS, requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval)\n",
    "#     print(loss.item())\n",
    "\n",
    "plt.plot(loss_list)\n",
    "# print('final parameters: {}'.format(expval_list))\n",
    "    \n",
    "# print(circuit(phi, theta))\n",
    "# print(cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST (0-1) Dataset\n",
    "\n",
    "**Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Concentrating on the first 100 samples\n",
    "n_samples = 100\n",
    "\n",
    "X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Leaving only labels 0 and 1 \n",
    "idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \n",
    "                np.where(X_train.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "print(X_train)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 200\n",
    "\n",
    "X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                        transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "idx = np.append(np.where(X_test.targets == 0)[0][:n_samples], \n",
    "                np.where(X_test.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network with Q-node\n",
    "\n",
    "This NN is  2 layers of ConvNN and a fully connected layer, with a Q-Node as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, NUM_QUBITS)\n",
    "        self.qc = TorchCircuit.apply\n",
    "        self.fc3 = nn.Linear(NUM_QUBITS, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = qc(x[0]) # QUANTUM LAYER\n",
    "        x = self.fc3(x.float())\n",
    "        x = F.softmax(x, 1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        # apply softmax\n",
    "        pred = self.forward(x)\n",
    "#         print(pred)\n",
    "        ans = torch.argmax(pred[0]).item()\n",
    "        return torch.tensor(ans)\n",
    "    \n",
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=MOMENTUM)\n",
    "\n",
    "# optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "standard pytorch training loop.\n",
    "- Load data from train_loader. Which is this case a single example each step.\n",
    "- Forward pass through NN\n",
    "- Caluculate loss\n",
    "- Backprop and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "loss_list = []\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()        \n",
    "        # Forward pass\n",
    "        output = network(data)\n",
    "        # Calculating loss\n",
    "        loss = loss_func(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Cross Entropy Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of NN\n",
    "\n",
    "The outcome is not always the same because the prediction is probabilistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "number = 0\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    number +=1\n",
    "    output = network.predict(data).item()\n",
    "    accuracy += (output == target[0].item())*1\n",
    "    \n",
    "print(\"Performance on test data is is: {}\".format(accuracy/number))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_shape = (8, 6)\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=n_samples_shape[0], ncols=n_samples_shape[1], figsize=(10, 2*n_samples_shape[0]))\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if count == n_samples_shape[0]*n_samples_shape[1]:\n",
    "            break\n",
    "        pred = network.predict(data).item()\n",
    "\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].set_xticks([])\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].set_yticks([])\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].set_title('Predicted {}'.format(pred))\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
