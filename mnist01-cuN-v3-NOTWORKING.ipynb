{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals.\n",
    "#\n",
    "# Code adapted from QizGloria team, Qiskit Camp Europe 2019, updated by \n",
    "# Team Ube Pancake, Qiskit Summer Jam 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumRegister,QuantumCircuit,ClassicalRegister,execute\n",
    "from qiskit.circuit import Parameter,ControlledGate\n",
    "from qiskit import Aer\n",
    "import qiskit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "\n",
    "NUM_QUBITS = 1\n",
    "NUM_SHOTS = 10000\n",
    "SHIFT = 0.01\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.5\n",
    "\n",
    "SIMULATOR = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to translate Q-Circuit parameters from pytorch back to QISKIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Contruct QuantumCircuit QFT Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:09:30.598730Z",
     "start_time": "2019-10-01T16:09:30.567861Z"
    }
   },
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self.circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        self.n_qubits = n_qubits\n",
    "        self.thetas ={k : Parameter('Theta'+str(k))for k in range(self.n_qubits)}\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.circuit.h(all_qubits)\n",
    "        self.circuit.barrier()\n",
    "        for k in range(n_qubits):\n",
    "            self.circuit.ry(self.thetas[k], k)\n",
    "        \n",
    "#         # Apply controlled-unitary\n",
    "# #         uc=ry(self.theta4, 4).to_gate().control(4)\n",
    "# #         self.circuit.append(uc, [0,1,2,3,4])\n",
    "#         self.circuit.ry(self.theta4, 4).to_gate().control(4)\n",
    "    \n",
    "        self.circuit.barrier()\n",
    "        self.circuit.measure_all()\n",
    "        # ---------------------------\n",
    "        \n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects  \n",
    "    \n",
    "    def run(self, i):\n",
    "        params = i\n",
    "#         print('params = {}'.format(len(params)))\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        try:\n",
    "            job_sim = execute(self.circuit,\n",
    "                              self.backend,\n",
    "                              shots=self.shots,\n",
    "                              parameter_binds = [{self.thetas[k] : params[k] for k in range(NUM_QUBITS)}])\n",
    "        except:\n",
    "            job_sim = execute(self.circuit,\n",
    "                              self.backend,\n",
    "                              shots=self.shots,\n",
    "                              parameter_binds = [{self.thetas[k] : params[k].item() for k in range(NUM_QUBITS)}])\n",
    "        \n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,NUM_QUBITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value for rotation [pi: 0.5049\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐ ░ ┌────────────┐ ░  ░ ┌─┐\n",
       "   q_0: ┤ H ├─░─┤ RY(Theta0) ├─░──░─┤M├\n",
       "        └───┘ ░ └────────────┘ ░  ░ └╥┘\n",
       "meas_0: ═════════════════════════════╩═\n",
       "                                       </pre>"
      ],
      "text/plain": [
       "        ┌───┐ ░ ┌────────────┐ ░  ░ ┌─┐\n",
       "   q_0: ┤ H ├─░─┤ RY(Theta0) ├─░──░─┤M├\n",
       "        └───┘ ░ └────────────┘ ░  ░ └╥┘\n",
       "meas_0: ═════════════════════════════╩═\n",
       "                                       "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit = QiskitCircuit(NUM_QUBITS, SIMULATOR, NUM_SHOTS)\n",
    "print('Expected value for rotation [pi: {}'.format(circuit.run([np.pi]*NUM_QUBITS)[0]))\n",
    "circuit.circuit.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchCircuit()\n",
    "\n",
    "A pytorch layer always has two functions. One for the forward pass and one for the backward pass. The forward pass simply takes the Quantum Circuits variational parameters from the previous pytorch layer and runs the circuit on the defined hardware (defined in `QiskitCircuit.run()`) and returns the measurements from the quantum hardware.\n",
    "These measurements will be the inputs of the next pytorch layer.\n",
    "\n",
    "The backward pass returns the gradients of the quantum circuit. In this case here it is finite difference.\n",
    "\n",
    "the `forward_tensor` is saved from the forward pass. So we just have to do one evaluation of the Q-Circuit in the backpass for the finite difference.\n",
    "\n",
    "The `gradient` variable here is as well hard coded to 3 parameters. This should be updated in the future and made more general.\n",
    "\n",
    "The loop `for k in range(len(input_numbers)):` goes through all the parameters (in this case 3), and shifts them by a small $\\epsilon$. Then it runs the circuit and takes the diefferences of the ouput for the parameters $\\Theta$ and $\\Theta + \\epsilon$. This is the finite difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(NUM_QUBITS, SIMULATOR, shots=NUM_SHOTS)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i)\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "#         eps = 0.01\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors\n",
    "#         print('forward_tensor = {}'.format(forward_tensor))\n",
    "        input_numbers = i\n",
    "#         print('input_numbers = {}'.format(input_numbers))\n",
    "        gradients = torch.Tensor()\n",
    "        \n",
    "        for k in range(len(input_numbers)):\n",
    "            shift_right = input_numbers\n",
    "            shift_right[k] = input_numbers[k] + SHIFT\n",
    "            shift_left = input_numbers\n",
    "            shift_left[k] = input_numbers[k] - SHIFT\n",
    "            \n",
    "            expectation_right = ctx.QiskitCirc.run(shift_right)\n",
    "            expectation_left  = ctx.QiskitCirc.run(shift_left)\n",
    "#             print('expectation_right = {}, \\nexpectation_left = {}'.format(expectation_right,\n",
    "#                                                                           expectation_left))\n",
    "            \n",
    "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "            gradients = torch.cat((gradients, gradient.float()))\n",
    "# #             print(k)\n",
    "#             input_eps = input_numbers\n",
    "#             input_eps[k] = input_numbers[k] + eps\n",
    "# #             print('input_eps = {}'.format(input_eps))\n",
    "#             exp_value = ctx.QiskitCirc.run(input_eps)\n",
    "#             print('exp_value = {}'.format(exp_value))\n",
    "#             print('forward_tensor[0][k] = {}'.format(forward_tensor[0][k]))\n",
    "#             gradient = (exp_value - forward_tensor[0][k].item())\n",
    "#             gradients.append(gradient)\n",
    "            \n",
    "#         print('gradients = {}'.format(gradients))\n",
    "        result = torch.Tensor(gradients)\n",
    "\n",
    "        return result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 after quantum layer: tensor([[0.8585]], dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "x.grad = tensor([-0.0021])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([np.pi/4]*NUM_QUBITS, requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "print('y1 after quantum layer: {}'.format(y1))\n",
    "y1 = nn.Linear(NUM_QUBITS,1)(y1.float())\n",
    "y1.backward()\n",
    "print('x.grad = {}'.format(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Quantum Circuit's Gradient Descent\n",
    "\n",
    "First, we want the \"neural net\" consisting of just the quantum circuit (with its 4 inputs and 4 outputs) and a linear layer (from 4 inputs to 1 output) to converge to a target value (-1). So, we define a cost function where the cost is defined as the square distance from the target value.\n",
    "\n",
    "`x` is the initialization of the parameters. Here, every angle in the quantum circuit starts at $\\pi/4$. We should see that the loss eventually goes down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 16.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2911a4b32b0>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXzU1b3/8dcnk30jCUlISAIBCftO2BQQRCtK3fddq7VY22pvF3u7e71tb9vb/tpbtZa6K7jjvrRWQQQkECAQ9iWEbJB9IyHbzPn9kcFiDGSbme8sn+fjkYeZmTPz/XwF3jk53/M9R4wxKKWU8n1BVheglFLKNTTQlVLKT2igK6WUn9BAV0opP6GBrpRSfiLYqgMnJiaazMxMqw6vlFI+acuWLVXGmKTuXrMs0DMzM8nNzbXq8Eop5ZNE5MjpXtMhF6WU8hMa6Eop5Sc00JVSyk9ooCullJ/QQFdKKT+hga6UUn5CA10ppfxEj4EuIuEisklEtovILhF5sJs2g0Tk7VPa3OGecv3fW9vLKK5ptroMpZQP6k0PvRU4zxgzBZgKLBGROV3a3AvsdrZZCPxBREJdWmkAOFLdxHde2MZ/vJyHrlOvlOqrHgPddDrufBji/OqaNgaIEREBooEaoMOVhQaCd3YcBWBzYS0f7DxmcTVKKV/TqzF0EbGJSB5QAXxojMnp0uRhYBxQBuQD9xljHN18zt0ikisiuZWVlQMs3f+8lVfG1Iw4xqbE8Jv399LaYbe6JKWUD+lVoBtj7MaYqUA6MEtEJnZpciGQBwylc1jmYRGJ7eZzlhtjso0x2UlJ3a4tE7D2HWtkX3kjV0xL4ydLx1FU08yzG067ZINSSn1Jn2a5GGPqgDXAki4v3QGscg7PHAQOA2NdUmGAeGt7KUECF09KZX5WEovGJPF/Hx+g+nir1aUppXxEb2a5JIlInPP7COB8YG+XZkXAYmebIcAYoMC1pfovYwxvbz/KOaMSSYoJA+AnS8fR3Gbnuy9v53irXo5QSvWsNz30VGC1iOwANtM5hv6OiCwTkWXONg8BZ4tIPvAR8IAxpso9Jfuf7SX1FNU0c8mUoZ8/Nyo5hl9dPpH1B6u45rHPKKs7YWGFSilf0ON66MaYHcC0bp5/7JTvy4CvuLa0wPFWXhmhtiAunJDyheevnzWM1LgI7l2xlcsfWc/yW7OZmhFnUZVKKW+nd4parKXdzjs7ylg4JolBESFfev3c0Um8ds/ZhNiCuOqvG/jdB3tpadfZL0qpL9NAt5DdYfiPl/OoaGzllrnDT9tuTEoM7903nyunpfHomkN89S/ryC+p92ClSilfoIFuEWMMD72zm/fyj/HTpeOYn3XmaZyDIkL4/TVTePqOmTS1dnDj4xvZX97ooWqVUr5AA90iy9cW8PSGQu6aN4K75o/s9fsWjknm1XvOJiLExu1PbqK8ocWNVSqlfIkGugWWrz3Eb97fy1cnp/Lji8f1+f1pcRE8eftM6k60c8dTm3Vao1IK0ED3KIfD8Kt3d/Pr9/aydHIqf7h2CkFB0q/Pmpg2iEdums6+8kbueX6LLhOglNJA9xS7w/D9V7bz908Pc9vc4fzl+mmEBdsG9JmLxiTzmysn8emBKr61chvt9i8tn6OUCiAa6B7yzo4yVm0r5f7zs/jlpRP63TPv6trsDB68dAIf7i7nuy/lYXfosrtKBaoebyxSrvHU+kJGJEbxnfOy6Fxl2HVuOzuTlnY7v3l/L6HBQfzuqskE2/RntVKBRgPdA7YV1ZJXXMcvLxnvsp55V9849yzaOhz84cP9NJzo4C83TCMidGBDOkop36LdOA94ZkMh0WHBXJ2d4dbjfHtxFg9dNoGP9pZzyxM51DW3dduuraP7sXYdrlHKt2mgu1lFQwvv5h/lmux0osPc/wvRLXMzeeTG6ewoqee6v22kpumLof7HD/cz4Rcf8JPX8zlW3zmH/WBFI/eu2Mqon7zHDcs38vb2stOGvlLKe+mQi5utyCmiw2G4bW6mx4558aRU4iJCuOPpzdz6ZA4rvz6H2PAQnvuskP/76AAT02J5aXMxr24pYdaIBNYfrCIixMa1MzJYf6iKb7+wjYSoUKZlxDEmJYbRQ2LISIgkLS6CpJgwbG4aNlJKDYwGuhu1dthZkVPEojHJZCZGefTYZ49K5LFbZnD3s7l87anN3Dh7GD9/axeLxybzt1tmcLS+hT/96wBr9lVw57wRLDv3LAZHh2F3GD49UMmbeWXsLmvgk/2VdJwyFBNqC+KXl07gxtnDPHo+SqmeiVW7y2dnZ5vc3FxLju0p7+44yr0rt/LM12Zx7mhrttx7L/8o31q5FYeBacPiWHnXnD5dLG3rcFBY3URp7QlK607w1vYy8orqeOPecxg/9Eu7DCql3ExEthhjsrt7TcfQ3ejd/DISo8OYNyrRshounpTK/7tuKovHJvPkbTP7PPMlNDiI0UNiWDQ2mZvnDOevN01nUGQI9724rV/L+FrVgVAqEGigu0lzWwcf761gycQhlo85XzY1jSdun0l8VOiAP2twdBh/vHYKByqO86t399Dc1sGrW0q47clNPPj2Lhpa2rt9n8NhuP/FbVz+6IbTtlFKDYyOobvJmn2VtLQ7uHhSqtWluNz8rCS+Pn8Ef//0MKu2ltDUZictLoK1Byp5L/8oD146gQsnpHzhBqrf/WMfb+SVIQL3rtjKk7fPJERvflLKpTTQ3eTd/KMkRocye8Rgq0txi+9fOIaS2hNEhgZz3cwMZmbGs6Oknh+tymfZ81uZn5XI/eePZsbweF7OLeaxTw5x0+xhTEmP44ev7eDnb+7i11dMdPlds0oFMg10NzjRZufjPRVcOT3N8uEWdwkLtvHXm2d84bkpGXG8/a1zeHpDIY+sPshVf93A7BEJbDlSy/ysRH556QRCbEEcqWnikdWH6LA7iAoLpvJ4K3ERIfz44nFEeWCuvlL+Sv/1uMGafRWcaLez1A+HW3oSbAvirvkjuWHWMJ7beIS/ry1gZFIUD984/fMhlu9dMIaj9S28sqWE6LBgkmLCKKppZs/RBp66Y1a3e6sqpXqm0xbd4Fsrt7LhUDWbfrw44BfJautwYDDdLhXc0m4nPKTz+Q92HuXbL2xj9JAYnrtzNgkuuICrlDfKLaxh/NBYIkP7158e0LRFEQkXkU0isl1EdonIg6dpt1BE8pxtPulXpX6gpd3Ox3sruHBCSsCHOXROezzduu8nwxxgycRUlt+azcGK41z3t8++tGSBUv6gsaWdW57YxK/f2+OWz+9N4rQC5xljpgBTgSUiMufUBiISBzwKXGqMmQBc4/JKfcQT6w7T3BaYwy0DtWhMMk/dMZOimmbueHozTbq1nvIz7+w4yol2O1dOT3fL5/cY6KbTcefDEOdX13GaG4FVxpgi53sqXFqlDzDG8McP9/P7f+zjookpzD3LP2e3uNvZZyXy8I3TyS+p454VW3UXJuVXXtxczOgh0UzLiHPL5/dqTEBEbCKSB1QAHxpjcro0GQ3Ei8gaEdkiIree5nPuFpFcEcmtrKwcWOVexOEwPPj2bv7vowNcm53OX26Y5rezWzzhgvFD+M2Vk1i7v5IfvLJd7y5VfmHfsUa2F9dxbXaG26br9irQjTF2Y8xUIB2YJSITuzQJBmYAS4ELgZ+JyOhuPme5MSbbGJOdlGTN2ibusHJTEU9vKOTr80fwW90tyCWumzmM+8/P4o28Mj4rqLa6HKUG7KXNxYTYxG3DLdDHW/+NMXXAGmBJl5dKgA+MMU3GmCpgLTDFJRX6gHd2lDF6SDQ/vnic3ijjQsvOPYuY8GBezS2xuhSlBqS1w86qbSV8ZXyKW2dw9WaWS5LzoiciEgGcD+zt0uxNYL6IBItIJDAbcM9lXC9T29TGpsM1fGV8ioa5i4WH2LhkylDe23mURl3/RfmwD3eXU9fczrUz3btrWW966KnAahHZAWymcwz9HRFZJiLLAIwxe4APgB3AJuBxY8xOdxXtTT7eW4HDdI77Kte7ekY6Le0O3t1x1OpSlOq3lzYXM3RQuNtXXu1xZrsxZgcwrZvnH+vy+PfA711Xmm/4cHc5Q2LDmJQ2yOpS/NK0jDjOSorilS0lXD9LN9VQvqfqeCvrDlbx7UWj3D5ZQq/eDUBLu521Byq5YPwQgnRWi1uICNdkZ7DlSC0Flcd7foNSXmbdgSqMgfM98Fu8BvoArD9YRXObnQvGp1hdil+7clrnImevbtGLo8r3rD1QSXxkCBOGuv+3eA30AfhwdznRYcHMGZlgdSl+LTk2nHNHJ7Fqayl2h85JV77DGMOnB6qYl5XkkXtTNND7ye4w/GtPOQvHJJ12rRLlOlfPSOdYQwvrDlZZXYpSvbavvJHKxlbmZ3lmG0oN9H7KK66l6nibzm7xkMXjkokND+b1rTrsonzHp/s7OyAa6F7u/fxjhNiEhWOSrS4lIIQF21g6eSj/2FWui3Ypn7H2QCVZydGkDorwyPE00Puh3e7g9W2lLB47RDdj8KArp6dxot3OP3Yds7oUpXrU0m4n53ANC0Z7bpkTDfR++HhvBdVNbVyT7b41GdSXZQ+PJz0+gte3lVpdilI92nS4hrYOh8eGW0ADvV9eyS0hKSaMcz34k1d1zkm/Yloa6w9WUd7QAkBxTTP3PL+FXWX1Flen1Bd9eqCSUFuQRzeK10Dvo4rGFlbvq+Cq6em6qqIFrpiWhsPAm3mlFFY1cd3fPuP9ncf48es7ceiURmWhdruD5WsPsTKniI0F1azZV8nMEfFEhHpuFpxuEt1HrzvnQutwizVGJkUzJSOOFTlFPLHuMG0dDr5x7kj+9kkBb24v5Ypp+ueirPHx3gp+/d4X1y28aoZn/z5qoPeBMYZXtpQwY3g8ZyVFW11OwLpyWhq/eGsXidFhvHj3XLKSo9lwsJrfvr+PCyek9Lj57qbDNUSF2Txy554KHB/uLic2PJi3vz2PI9XNHKtv4eLJnt2KUscM+mBbcR0HK45zrfbOLXXl9DTuOCeTF++ew5iUGIKChJ9fMp5jDS0sX1twxvfuKqvn5sdzuPyR9azMKfJQxcrf2R2Gj/dWcN7YZIYPjmLB6CSunZlBdJhn+8wa6H3w8uZiIkI650Mr68SEh/CLSyYwKvnfvyXNzExg6eRUHvvkEIVVTd2+70Sbne+8sI24yBDmjBzMj1/P5z9X5dPaYfdU6cpPbTlSS01Tm+XrOmmg91JDSztv5pVx2dShHv+pq3rnR0vGEiTChX9ay6/e3U1NU9sXXv/vd3dzqLKJP147lafvmMU9C8/ihU1FPPDqDosqVv7iw93HCLUFce4Ya2e+aTL10qotJZxot3PznOFWl6JOIyMhkn/cv4A//esAT6w7zMqcIhaOTWZK+iBsQUGsyCni7gUjmeecF/zAkrGcaLOzIucIv7hkAvFu3BpM+S9jDB/uLmfuWYMt7+xpD70XjDE8n1PElIw4JupGFl4tIyGSP1w7hX9+dwEXTkwhr6iOX7+3l4fe2c2EobF8/ytjvtD+6hnptNsN7+brjkiqfw5WHKewutkr1nXyuR561fFWthfXcc6oRMJDPDO/c2NBDQcrjvP7qyd75Hhq4EYlx/DHa6cCnX9ndpc1MC41ltDgL/ZhJgyNZVRyNG/mlepvX6pf/rm7HPCObSh9rof+2aFq7nwml8OnufDlDs/nHGFQRAiXTNGLob4oMTqMBaOTSIoJ+9JrJ+8+3VxYS3FNswXVKV/34e5ypqQPYkhsuNWl+F6gZyREAnjsH19FYwv/2HmMq2eke+w3AuVZlzp/UL+1vcziSpSvqWhoIa+4zit65+CDQy4Z8Z3LUBbXnnDbMd7LP8on+yppdzgoqm6mw2G4abZuUOyvMhIimZkZz+vbSvnmwrMQ0f1hVe88ub4QEbhokmdvIDqdHnvoIhIuIptEZLuI7BKRB8/QdqaI2EXkateW+W8JUaFEhtrc1kN/fuMRvrliK//cfYycghoqj7dy85xhjNQ7Q/3aZVPTOFhxnF1lDVaXonxERUMLT284zGVThnrNneO96aG3AucZY46LSAiwTkTeN8ZsPLWRiNiA3wL/cEOdpx6HjPhISmpdH+jPbzzCT9/YyeKxyTx683TdWi6ALJ2Uyi/f2sWbeaU6k0n1yl8+PkiH3fDdC0ZbXcrneuyhm07HnQ9DnF/dLWv3beA1oMJ15XUvIyGC4hrXDrm8uKlIwzyAxUeFcv64IazMKeJItecuuCvfVFTdzAubirhuZgbDB0dZXc7nenVRVERsIpJHZ1h/aIzJ6fJ6GnAF8JjrS/yy9PhIimubMcY1y6XWNrXxX+/sZt6oRA3zAPbTr47DFiR858U82u0Oq8tRXuxP/9qPLUj49nlZVpfyBb0KdGOM3RgzFUgHZonIxC5N/gQ8YIw546IYInK3iOSKSG5lZWX/KgaGJUTS3Gb/0q3d/fXMZ4U0t9n5+SXjNcwDWHp8JP9z1WS2F9fxxw/3W12O8lIHKxp5Pa+U28/OJGWQ9VMVT9WnaYvGmDpgDbCky0vZwIsiUghcDTwqIpd38/7lxphsY0x2UlL/1zz4fOqiC2a6NLV28PSGQs4fN4TRQ2IG/HnKt108KZXrZ2bw2CeHWH+wyupylBf6x65yjIG75o+0upQv6c0slyQRiXN+HwGcD3xhFXdjzAhjTKYxJhN4FfimMeYNN9QLdI6hg2vmor+wqYi65na+ueisAX+W8g8/v2Q8IxOj+MEr22lp15UY1RdtLKhmbEpMtzeqWa03PfRUYLWI7AA20zmG/o6ILBORZe4tr3sZ8Sd76AML9NYOO49/epjZIxKYPizeFaUpPxAZGsxDl02krL6FFzbpmunq39rtDnILa5kz0nP7hPZFj9MWjTE7gGndPN/tBVBjzO0DL+vMosKCSYgKHfBMlze2lXKsoYXf6hotqouzRyUyd+RgHll9iOtnDvPovpDKe+0oqedEu53ZIxKsLqVbPnfr/0kZ8REDnov+5LpCJgyNZYFzOVWlTvW9r4ym6ngrz35WaHUpyktsLKgGYJYGumulJ0QOaAy9+ngr+8obuWTKUL3VW3UrOzOBc0cn8dgnhzje2mF1OcoL5ByuYfSQaAZHe9/4OfhwoGfER1JadwK7o39z0fOK6wCYlhHnyrKUn/mPC0ZT29zOU+sOW12Ksljn+HmN146fgy8HekIE7XZDeUNLv96/taiW4CBhcroGujq9KRlxXDB+CH//tIATbTrjJZDtLK2nuc3O7BEa6C53cqZLUT+HXbYeqWNcaqxe7FI9umveCBpaOnhnhy6vG8g2FtQAMHukd46fgy8H+gDWRbc7DNtL6pg2THvnqmezRiRwVlIUK3UKY0DbWFBNVnI0iV46fg4+HOhD48IR6d/dovuONdLcZte556pXRIQbZg1jW1Ede47q8rqBqMM5fu7NvXPw4UAPC7aREhtOST966FuLagE00FWvXT0jndDgIL3RKEDtLGugqc3u1RdEwYcDHTrH0ftzt+i2ojoGR4V+voSAUj2Jiwxl6aRUXt9aqhdHA9CGQ53r+njr/POTfDrQ0/u5Lvq2olqmDYvX+eeqT26YNYzG1g7edl4cNcbQ1qHL7AaCNfsqGZ8aS3KMd62u2JXP7Sl6qoz4SMobS2ntsPd62dvapjYKqpq4OjvdzdUpfzMzM55RydH85eMDvL29jPzSeto6HKz5wUKv/4eu+q+hpZ0tR2r5xgLvW12xK5/uoWckRGIMlPbhwui/byjS8XPVNyLC1+ePoLyhlZqmNuaNSqS5zc6avf1f2195v3UHqrA7DIvGJltdSo98uoeeObhz6mJBZVOvN3HeWlSLLUiYkqH7Rqq+u27mMK7NzkBEMMaQW1jL6n0VXDszw+rSlJus2VdBbHiwT9xV7tM99DEpnRtS9GUq2daiWsamxBAZ6tM/y5SFTl57EREWjU3i0wNVumWdnzLG8Mn+SuZnJRFs8/649P4KzyAmPIThgyPZ3ctA77A72F5crzcUKZdZOCaZ460d5BbWWl2KcoM9Rxspb2jl3DH932HNk3w60AHGp8b2OtB3H23geGsHs7x4LQblW84ZlUiITVizr8LqUpQbrHb+uS4crYHuEeNTYzlS3UxjS3uPbU+uZTzHy+eSKt8RHRbMrBEJn//DV/7lk32VTBgaS3Ksb8xi8v1AHxoLwN5jjT223VhQw8ikKJ/5w1G+YdGYZPaXHx/whivKu9SfaGdLUS0LfWS4Bfwo0HeXnXnYxe4wbD5c49VLXyrfdHI62+p9On3Rn6w/2DldceEY75+ueJLPB3pKbDgJUaE9BvrusgYaWzuY4+WL6yjfMzIximEJkazZq8Mu/mT1Xt+ZrniSzwe6iPTqwujn4+devriO8j0iwqIxSaw/VEVDL67lKO/ncBjW7K9kwWjfmK54ku9Uegbjh8ayr7zxjHOBNxZUMzIxiiE6fq7c4JIpQ2ntcHDRnz7VGS9+YFdZA5WNrSzyoeEW6EWgi0i4iGwSke0isktEHuymzU0issP5tUFEprin3O6NT42lrcNBQWVTt6/bHYZNh2uYrb1z5SbZmQm8umwu4SFB3P7UZv7j5Txa2nVVRl+1el8FIvjM/POTetNDbwXOM8ZMAaYCS0RkTpc2h4FzjTGTgYeA5a4t88w+vzB6tL7b1/cc1fFz5X4zhifw3n3z+daiUazaWqprp/uw1fsqmJwe59W7E3Wnx0A3nY47H4Y4v0yXNhuMMSdvldsIeHQpw5GJUYQGB532wujJ8XOd4aLcLSzYxvcvHMOM4fE8tb4Qu8P0/CblVaqPt5JXXMd5PjbcAr0cQxcRm4jkARXAh8aYnDM0vxN4/zSfc7eI5IpIbmWl66Z4BduCGJsSw64zBPqIxChSBun4ufKMr50zgqKaZj7aU251KaqP1h6oxBhYNNa3hlugl4FujLEbY6bS2fOeJSITu2snIovoDPQHTvM5y40x2caY7KQk1/7POjnTxZgv9ogaW9rJOVyjwy3Koy6cMIS0uAieWHfY6lJUH63eW0lidBgTh/reiqx9muVijKkD1gBLur4mIpOBx4HLjDHVLqmuD8YPjaWuuZ2j9S2fP2d3GL7zwjaa2+xcPUM3tFCeE2wL4vazM8k5XMPO0u6v7Sjv02F38Mn+ShaOSSIoyPd2NOvNLJckEYlzfh8BnA/s7dJmGLAKuMUYs98dhfZkgvOn6a/e3UNNUxsAv35vD6v3VfJfl01gxnDtoSvPum5WBlGhNp7UXrrPyCuuo/5Eu89NVzypN4uCpwLPiIiNzh8ALxtj3hGRZQDGmMeAnwODgUeda0V3GGOy3VRzt6YPi+O+xVk8svognxVUc9HEFFbkFHH72ZncNHu4J0tRCoDY8BCuyc5gRc4RHrhorN4D4QPe3l6GLUiYl5VodSn9Il3HnD0lOzvb5Obmuvxz9x5r4IHX8tleXMeC0Uk8eVu2T93ppfzLkeomFv/hE66ans5vr55sdTnqDHaXNXDJw+u4ZkY6/3OV9/5ZiciW03WY/W7bnrEpsay652zW7q9k1ogEDXNlqeGDo/javBEsX1vAtTMzmDFc97L1RnaH4cev5xMXEcKPLhprdTn95pdpZwsSFo1NJirM735eKR903+IsUmLD+dkbO+nQreq80sqcI+QV1/Gzr44nLjLU6nL6zS8DXSlvEhUWzM++Op7dRxt4fuMRq8tRXZQ3tPC7D/Yxb1Qil00danU5A6KBrpQHXDwphflZifzhn/upaGzp+Q3KI1ra7Xz3pTxa7Q7++/KJn28A7qs00JXyABHhwUsn0Gp3cP+LeTr04gXaOhzcu2IrGw5V85srJpGZGGV1SQOmga6Uh4xMiuZXl09kw6FqfvvB3p7foNymw+7guy/l8dHeCh66fCJX+cmNh3rVUCkPuiY7g/zSev7+6WEmpg3isqlpVpcUkH793l7ezT/KTy4exy1z/Oc+Fe2hK+VhP106npmZ8Tzw2g7WHaiyupyAU1zTzLOfFXLDrGF8fcFIq8txKQ10pTwsNDiIR26aTnJMODc/kcOdT29mf3mj1WUFjL9+coggEb6zeJTVpbicBrpSFkiOCeef313AD5eMYdPhGpb8aS2v5BZbXZbfK6s7wSu5xVw7M53UQRFWl+NyGuhKWSQ8xMY3F47ikx8uYmLaIP7y8UEcuiGGW/11zSEA7lnof71z0EBXynIJUaHcOa9zQ4wNhzy+8nTAOFbfwkubi7l6RgZpcf7XOwcNdKW8woUTUoiPDGHlJr2T1F0e++QQDmP45sKzrC7FbTTQlfIC4SE2rpqezj93leudpG5Q19zGS5uLuXxaGhkJkVaX4zYa6Ep5iRtmD6PDYXh1S4nVpfidFzYVc6Ldzl3zR1hdiltpoCvlJc5Kimb2iARe3FSsF0ddqN3u4JkNhZwzajBjU2KtLsetNNCV8iI3zh5GUU0z6w/pDUd9kVNQ/fnWk129v/MYxxpa+No5/t07Bw10pbzKkokpDI4K5adv7OSA3mzUK4cqj3Pd8o3c9uQmWtrtX3jNGMMT6w4zMjHKZ/cJ7QsNdKW8SFiwjb/flk1Tq50rHt3AR3vKrS7J663YWIQtSMgvrefBt3d94bWtRbVsL67jjnMyCQry7aVxe0MDXSkvM31YPG996xxGJEZx17O5rMwpsrokr3Wizc6rW4q5aGIK31x4Fi9sKuZl5x23B8ob+d0H+4gND+bK6f6xmmJPdLVFpbzQ0LgIXv7GXO58ZjO/eX8Pl0xJJSY8xOqyvM7bO8poaOng5jnDmZmZwPaSOn72xk5W5hSRV1xHcJDw06XjAmY7Su2hK+WlIkJtPLBkLI0tHbywSXvp3Vmx8QhZyZ2zg2xBwp+vn0ZybBjNbR38dOk4Nv54MbcHwMXQk3r8sSUi4cBaIMzZ/lVjzC+6tBHgz8DFQDNwuzFmq+vLVSqwTMmIY+7IwTyx7jC3nZ1JWLDN6pK8Rn5JPdtL6vnlJeM/3zouMTqMtT9Y5PNbyfVXb3rorcB5xpgpwFRgiYjM6dLmIiDL+XU38FeXVqlUAFu28CzKG1p5c1uZ1aV4lRU5R4gIsXFll92GAjXMoReBbjoddz4McX51vevhMuBZZydsRmQAABD2SURBVNuNQJyIpLq2VKUC04KsRManxvLY2kN6w5FTQeVx3swr47KpQ4nVawuf69UYuojYRCQPqAA+NMbkdGmSBpy6mHOJ87mun3O3iOSKSG5lZWV/a1YqoIgI3zh3JAWVTfxLpzFS0dDCrU9uIjLUxr2L/HMZ3P7qVaAbY+zGmKlAOjBLRCZ2adLd7zhf6koYY5YbY7KNMdlJSUl9r1apALV0Uirp8RH897t7KKg83vMb/FRDSzu3PbWZmqY2nrpjpl8vtNUffZrlYoypA9YAS7q8VAJknPI4HdABP6VcJNgWxJ+vn0pjSzuXP7I+IPcibetw8I1nt3CgvJHHbp7B5PQ4q0vyOj0GuogkiUic8/sI4Hxgb5dmbwG3Sqc5QL0x5qjLq1UqgM0YnsBb35pHyqBwbntqEytyAmvt9N+8v4fPCqr5/TWTWTBaf8PvTm966KnAahHZAWymcwz9HRFZJiLLnG3eAwqAg8DfgW+6pVqlAlxGQiSv3XM2C7IS+cnrO3l9W2AstfvBzqM8tb6Q28/O5IppgXHXZ3+IMdZcNc/Ozja5ubmWHFspX9faYee2JzeRW1jLU3fMZH6W//ZYi6qbWfqXTxmZGMXLy+YG/Fx8EdlijMnu7jW9U1QpHxQWbGP5rdmMSo5m2XNb2Flab3VJbtHW4eBbL2xFgIdvnB7wYd4TDXSlfFRseAhP3zGLuMhQvvHcFr+co77+YBU7Sup56PKJOqOlFzTQlfJhKYPC+f6FoymtO0G+H/bSd5TUIwKLxw2xuhSfoIGulI9bODqZIMEv107PL63jrKRoogNktcSB0kBXysfFR4UyY3g8H+2tsLoUl9tRUs/ktEFWl+EzNNCV8gPnjR3CrrIGjtW3WF2Ky5Q3tFDR2MqkdA303tJAV8oPnD+uc7/Mj/2ol76jpPOawGQN9F7TQFfKD4xKjiYjIcKvxtHzS+oIEhifqoHeWxroSvkBEWHx2CGsO1jFiTa71eW4xI7SekYPiSEiVOee95YGulJ+YvG4ZFo7HHxW4PsLdxljyC+pZ5JeEO0TDXSl/MSsEQlEhdr41x7fH0cvq2+huqlNx8/7SANdKT8RFmxjflYSH++p8Pm7RvNL6gCYpEvk9okGulJ+5KtTUjnW0MLqfb7dS88vrSc4SBibEmN1KT5FA10pP3LhhBRSB4Xz5PrDVpcyIDtK6hmTEkN4iF4Q7QsNdKX8SIgtiFvnZrL+YDV7jzVYXU6/GGPIL63X8fN+0EBXys/cMCuD8JAgnlpXaHUp/VJSe4K65nYm6gyXPtNAV8rPxEWGctX0dF7PK6X6eKvV5fRZXnHnBdHJaXpBtK800JXyQ3eck0lbh4OVOUVWl9JnuYU1RIbaGJeqF0T7SgNdKT80KjmGc0cn8ezGIzS2tFtdTp9sLqxl+rB4gm0aT32l/8eU8lPfWZxFTVMb330pz2fmpTe0tLP3WAPZmfFWl+KTNNCV8lMzhsfz86+O5197Kvh//9pvdTm9sq2oDoeBmZkJVpfik3QbEKX82K1zh7O7rIG/fHyQsSmxLJ2canVJZ5RbWIMtSJiaoRdE+6PHHrqIZIjIahHZIyK7ROS+btoMEpG3RWS7s80d7ilXKdUXIsJ/XT6BGcPj+f4r2zlc1WR1SWe0ubCGCUNjidIt5/qlN0MuHcD3jDHjgDnAvSIyvkube4HdxpgpwELgDyIS6tJKlVL9EhZs49GbphNsE37yej7GeOd4eluHg7ziOrKH63BLf/UY6MaYo8aYrc7vG4E9QFrXZkCMiAgQDdTQ+YNAKeUFhsSG88CSsWw4VM2qraVWl9OtXWX1tLQ7mKkXRPutTxdFRSQTmAbkdHnpYWAcUAbkA/cZYxzdvP9uEckVkdzKysp+FayU6p8bZw1jxvB4/vvd3dQ0tVldzpfkFtYCMEMDvd96HegiEg28BtxvjOm6SMSFQB4wFJgKPCwisV0/wxiz3BiTbYzJTkpKGkDZSqm+CgoSfn3FJBpbOvjVu3usLudLNhfWkDk4kuSYcKtL8Vm9CnQRCaEzzFcYY1Z10+QOYJXpdBA4DIx1XZlKKVcYkxLD3QtG8trWEnaV1VtdzueMMeQeqSVbpysOSG9muQjwBLDHGPPH0zQrAhY72w8BxgAFripSKeU6X5s3AoCPvWhno4KqJmqa2nT8fIB600M/B7gFOE9E8pxfF4vIMhFZ5mzzEHC2iOQDHwEPGGN8f2NDpfxQYnQYE9NiWXvAe65jbTjYGRfaQx+YHid7GmPWAdJDmzLgK64qSinlXguykvjb2gIaW9qJCQ+xuhzezCtj9JBoRiZGWV2KT9Nb/5UKQAtGJ2F3GDYcqra6FIqqm8k9Usvl09LoHOFV/aWBrlQAmj4snqhQG2v3Wz/s8mZe57z4y6Z2vb1F9ZUGulIBKDQ4iLlnDWbtgUpL7xw1xvB6XimzRySQFhdhWR3+QgNdqQC1YHQSxTUnOFLdbFkN+aX1FFQ2cfk07Z27gga6UgFqQVbnzX1WznZ5fVspobYgLp7o3atA+goNdKUCVGZiFMMSIi0bR++wO3h7exnnjU1mUKT1M238gQa6UgFswehEPjtUTVvHl5Zecrt1B6uoOt6mwy0upIGuVABbkJVEU5udzYU1Hj/28xuLSIgKZdFYXdfJVTTQlQpg87OSiAkL5rWtJR49bmFVEx/tLeem2cMIC7Z59Nj+TANdqQAWEWrj0qlDeS//KA0t7R477tMbCgkOEm6ZM9xjxwwEGuhKBbjrZmbQ0u7grbwyjxyvoaWdV3KLuWTyUJJjdalcV9JAVyrATUobxNiUGF7aXOyR4728uZimNjt3nDPCI8cLJBroSgU4EeH6mRnkl9a7fY10u8Pw9IZCZmUmMCl9kFuPFYg00JVSXD4tjdDgIF52cy/9nR1llNSe4GvzMt16nEClga6UIi4ylCUTUnh9Wykt7Xa3HOODncf4was7GJcaywXjU9xyjECnga6UAjovjja0dPD+zqMu/+wXNxXxzRVbmDA0lpV3zcYWpMvkuoMGulIKgLkjBzMiMYrnPjvi0s99aXMRP1qVz/ysJFbcNZv4qFCXfr76Nw10pRQAQc554VuL6sgvcc3FUbvD8Od/HWDG8Hgevy2byNAeN0lTA6CBrpT63FUz0okMtfHsZ4Uu+bxP9ldQVt/CnfNGEGLTuHE3/T+slPrcoIgQrpiWxpvby6htahvw563YWERSTBgXjB/igupUTzTQlVJfcOvcTNo6HLyUO7ApjCW1zXy8r4LrsjO0d+4hPf5fFpEMEVktIntEZJeI3HeadgtFJM/Z5hPXl6qU8oQxKTHMGZnAc58dwe7o//Z0J+88vX5WhqtKUz3ozY/NDuB7xphxwBzgXhEZf2oDEYkDHgUuNcZMAK5xeaVKKY+5bW4mpXUn+GhPeb/e32538NLmYhaNSSY9PtLF1anT6fGSszHmKHDU+X2jiOwB0oDdpzS7EVhljClytqtwQ61KKQ+5YPwQUmLDeW7jEb4yoXc3ATW3dXCkuhm7w5BbWENFYys3zR7m5krVqfo0h0hEMoFpQE6Xl0YDISKyBogB/myMedYF9SmlLBBsC+LmOcP433/u52DFcUYlR/f4nruf3cK6g1WfP06Li2DhmGR3lqm66HWgi0g08BpwvzGmoZvPmQEsBiKAz0RkozFmf5fPuBu4G2DYMP3JrZQ3u37WMP7vo4M8v/EIv7x0whnbNra0s7GgmkumDOWSyakE24Ss5Bi9I9TDenXpWURC6AzzFcaYVd00KQE+MMY0GWOqgLXAlK6NjDHLjTHZxpjspCTddkopb5YYHcbSyam8uqWE460dZ2y7saCGDofhhlkZfGVCCueNHUJGgo6de1pvZrkI8ASwxxjzx9M0exOYLyLBIhIJzAb2uK5MpZQVbp07nOOtHazqYYu6dQcqiQixMWN4vIcqU93pTQ/9HOAW4DzntMQ8EblYRJaJyDIAY8we4ANgB7AJeNwYs9NtVSulPGJqRhyT0wfxzIZCjDn9FMZPD1Qxe2SC7g9qsd7MclkH9DgQZoz5PfB7VxSllPIOIsJtczP53ivbWXuginNHf3motKS2mYKqJm7S/UEtp7dvKaXOaOnkVIYOCufbK7eSU1D9pdfXHeic2TI/K9HTpakuNNCVUmcUHmLjpW/MJTEmjFue2MTb27+4mfSnB6sYEhtGVi+mNir30kBXSvUoIyGSVfeczZSMQXz7hW08se4w0Lk87vqDVcwblUTn/AllJV2cWCnVK3GRoTx352zufzGPh97ZzYm2DhaMTqKuuZ0Fo3W4xRtooCulei08xMbDN07jh6/u4H//uZ838jqHX84ZpYHuDTTQlVJ9EmwL4n+vmUJ4qI2VOUWMT40lMTrM6rIUGuhKqX4IChJ+dflERidHMyJJL4Z6Cw10pVS/iAi3nzPC6jLUKXSWi1JK+QkNdKWU8hMa6Eop5Sc00JVSyk9ooCullJ/QQFdKKT+hga6UUn5CA10ppfyEnGkXErceWKQSONLPtycCVT228j+BeN6BeM4QmOcdiOcMfT/v4caYbjdltizQB0JEco0x2VbX4WmBeN6BeM4QmOcdiOcMrj1vHXJRSik/oYGulFJ+wlcDfbnVBVgkEM87EM8ZAvO8A/GcwYXn7ZNj6Eoppb7MV3voSimlutBAV0opP+FzgS4iS0Rkn4gcFJEfWV2PO4hIhoisFpE9IrJLRO5zPp8gIh+KyAHnf+OtrtXVRMQmIttE5B3n40A45zgReVVE9jr/zOcGyHl/1/n3e6eIvCAi4f523iLypIhUiMjOU5477TmKyH86s22fiFzY1+P5VKCLiA14BLgIGA/cICLjra3KLTqA7xljxgFzgHud5/kj4CNjTBbwkfOxv7kP2HPK40A45z8DHxhjxgJT6Dx/vz5vEUkDvgNkG2MmAjbgevzvvJ8GlnR5rttzdP4bvx6Y4HzPo87M6zWfCnRgFnDQGFNgjGkDXgQus7gmlzPGHDXGbHV+30jnP/A0Os/1GWezZ4DLranQPUQkHVgKPH7K0/5+zrHAAuAJAGNMmzGmDj8/b6dgIEJEgoFIoAw/O29jzFqgpsvTpzvHy4AXjTGtxpjDwEE6M6/XfC3Q04DiUx6XOJ/zWyKSCUwDcoAhxpij0Bn6QLJ1lbnFn4AfAo5TnvP3cx4JVAJPOYeaHheRKPz8vI0xpcD/AkXAUaDeGPNP/Py8nU53jgPON18LdOnmOb+ddyki0cBrwP3GmAar63EnEfkqUGGM2WJ1LR4WDEwH/mqMmQY04fvDDD1yjhtfBowAhgJRInKztVVZbsD55muBXgJknPI4nc5f0/yOiITQGeYrjDGrnE+Xi0iq8/VUoMKq+tzgHOBSESmkcyjtPBF5Hv8+Z+j8O11ijMlxPn6VzoD39/M+HzhsjKk0xrQDq4Cz8f/zhtOf44DzzdcCfTOQJSIjRCSUzgsIb1lck8uJiNA5prrHGPPHU156C7jN+f1twJuers1djDH/aYxJN8Zk0vnn+rEx5mb8+JwBjDHHgGIRGeN8ajGwGz8/bzqHWuaISKTz7/tiOq8V+ft5w+nP8S3gehEJE5ERQBawqU+fbIzxqS/gYmA/cAj4idX1uOkc59H5q9YOIM/5dTEwmM6r4gec/02wulY3nf9C4B3n935/zsBUINf55/0GEB8g5/0gsBfYCTwHhPnbeQMv0HmNoJ3OHvidZzpH4CfObNsHXNTX4+mt/0op5Sd8bchFKaXUaWigK6WUn9BAV0opP6GBrpRSfkIDXSml/IQGulJK+QkNdKWU8hP/HwKmcs2oPy9tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)[0]\n",
    "    # simple linear layer: average all outputs of quantum layer\n",
    "    val = torch.sum(expval) / NUM_QUBITS\n",
    "    return torch.abs(val - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([np.pi/4]*NUM_QUBITS, requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval)\n",
    "#     print(loss.item())\n",
    "\n",
    "plt.plot(loss_list)\n",
    "# print('final parameters: {}'.format(expval_list))\n",
    "    \n",
    "# print(circuit(phi, theta))\n",
    "# print(cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST (0-1) Dataset\n",
    "\n",
    "**Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 200\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Concentrating on the first 100 samples\n",
    "n_samples = 100\n",
    "\n",
    "X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Leaving only labels 0 and 1 \n",
    "idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \n",
    "                np.where(X_train.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "print(X_train)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 200\n",
    "\n",
    "X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                        transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "idx = np.append(np.where(X_test.targets == 0)[0][:n_samples], \n",
    "                np.where(X_test.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network with Q-node\n",
    "\n",
    "This NN is  2 layers of ConvNN and a fully connected layer, with a Q-Node as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, NUM_QUBITS)\n",
    "        self.qc = TorchCircuit.apply\n",
    "        self.fc3 = nn.Linear(NUM_QUBITS, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = qc(x[0]) # QUANTUM LAYER\n",
    "        x = self.fc3(x.float())\n",
    "        x = F.softmax(x, 1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        # apply softmax\n",
    "        pred = self.forward(x)\n",
    "#         print(pred)\n",
    "        ans = torch.argmax(pred[0]).item()\n",
    "        return torch.tensor(ans)\n",
    "    \n",
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=LEARNING_RATE,\n",
    "                      momentum=MOMENTUM)\n",
    "\n",
    "# optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "standard pytorch training loop.\n",
    "- Load data from train_loader. Which is this case a single example each step.\n",
    "- Forward pass through NN\n",
    "- Caluculate loss\n",
    "- Backprop and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training [5%]\tLoss: 0.6947\n",
      "Training [10%]\tLoss: 0.6943\n",
      "Training [15%]\tLoss: 0.6947\n",
      "Training [20%]\tLoss: 0.6949\n",
      "Training [25%]\tLoss: 0.6950\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-3cc7a334b82d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Optimize the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "loss_list = []\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()        \n",
    "        # Forward pass\n",
    "        output = network(data)\n",
    "        # Calculating loss\n",
    "        loss = loss_func(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Cross Entropy Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of NN\n",
    "\n",
    "The outcome is not always the same because the prediction is probabilistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "number = 0\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    number +=1\n",
    "    output = network.predict(data).item()\n",
    "    accuracy += (output == target[0].item())*1\n",
    "    \n",
    "print(\"Performance on test data is is: {}\".format(accuracy/number))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_shape = (8, 6)\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=n_samples_shape[0], ncols=n_samples_shape[1], figsize=(10, 2*n_samples_shape[0]))\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if count == n_samples_shape[0]*n_samples_shape[1]:\n",
    "            break\n",
    "        pred = network.predict(data).item()\n",
    "\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].set_xticks([])\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].set_yticks([])\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].set_title('Predicted {}'.format(pred))\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
