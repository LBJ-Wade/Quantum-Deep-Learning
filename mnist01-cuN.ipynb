{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals.\n",
    "#\n",
    "# Code adapted from QizGloria team, Qiskit Camp Europe 2019, updated by \n",
    "# Team Ube Pancake, Qiskit Summer Jam 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumRegister,QuantumCircuit,ClassicalRegister,execute\n",
    "from qiskit.circuit import Parameter,ControlledGate\n",
    "from qiskit import Aer\n",
    "import qiskit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "\n",
    "NUM_QUBITS = 4\n",
    "NUM_SHOTS = 10000\n",
    "SHIFT = np.pi/8\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.5\n",
    "\n",
    "SIMULATOR = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to translate Q-Circuit parameters from pytorch back to QISKIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Contruct QuantumCircuit QFT Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:09:30.598730Z",
     "start_time": "2019-10-01T16:09:30.567861Z"
    }
   },
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self.circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        self.n_qubits = n_qubits\n",
    "        self.theta0 = Parameter('Theta0')\n",
    "        self.theta1 = Parameter('Theta1')\n",
    "        self.theta2 = Parameter('Theta2')\n",
    "        self.theta3 = Parameter('Theta3')\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.circuit.h(all_qubits)\n",
    "        self.circuit.barrier()\n",
    "        self.circuit.ry(self.theta0, 0)\n",
    "        self.circuit.ry(self.theta1, 1)\n",
    "        self.circuit.ry(self.theta2, 2)\n",
    "        self.circuit.ry(self.theta3, 3)\n",
    "        self.circuit.barrier()\n",
    "        \n",
    "#         # Apply controlled-unitary\n",
    "# #         uc=ry(self.theta4, 4).to_gate().control(4)\n",
    "# #         self.circuit.append(uc, [0,1,2,3,4])\n",
    "#         self.circuit.ry(self.theta4, 4).to_gate().control(4)\n",
    "    \n",
    "        self.circuit.barrier()\n",
    "        self.circuit.measure_all()\n",
    "        # ---------------------------\n",
    "        \n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects  \n",
    "    \n",
    "    def run(self, i):\n",
    "        params = i\n",
    "#         print('params = {}'.format(len(params)))\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        job_sim = execute(self.circuit,\n",
    "                          self.backend,\n",
    "                          shots=self.shots,\n",
    "                          parameter_binds = [{self.theta0 : float(params[0]),\n",
    "                                              self.theta1 : float(params[1]),\n",
    "                                              self.theta2 : float(params[2]),\n",
    "                                              self.theta3 : float(params[3])}])\n",
    "        \n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,NUM_QUBITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value for rotation [pi/4]: [ 0.7    -0.7014  0.7124 -0.6992]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐ ░ ┌────────────┐ ░  ░  ░ ┌─┐         \n",
       "   q_0: ┤ H ├─░─┤ RY(Theta0) ├─░──░──░─┤M├─────────\n",
       "        ├───┤ ░ ├────────────┤ ░  ░  ░ └╥┘┌─┐      \n",
       "   q_1: ┤ H ├─░─┤ RY(Theta1) ├─░──░──░──╫─┤M├──────\n",
       "        ├───┤ ░ ├────────────┤ ░  ░  ░  ║ └╥┘┌─┐   \n",
       "   q_2: ┤ H ├─░─┤ RY(Theta2) ├─░──░──░──╫──╫─┤M├───\n",
       "        ├───┤ ░ ├────────────┤ ░  ░  ░  ║  ║ └╥┘┌─┐\n",
       "   q_3: ┤ H ├─░─┤ RY(Theta3) ├─░──░──░──╫──╫──╫─┤M├\n",
       "        └───┘ ░ └────────────┘ ░  ░  ░  ║  ║  ║ └╥┘\n",
       "meas_0: ════════════════════════════════╩══╬══╬══╬═\n",
       "                                           ║  ║  ║ \n",
       "meas_1: ═══════════════════════════════════╩══╬══╬═\n",
       "                                              ║  ║ \n",
       "meas_2: ══════════════════════════════════════╩══╬═\n",
       "                                                 ║ \n",
       "meas_3: ═════════════════════════════════════════╩═\n",
       "                                                   </pre>"
      ],
      "text/plain": [
       "        ┌───┐ ░ ┌────────────┐ ░  ░  ░ ┌─┐         \n",
       "   q_0: ┤ H ├─░─┤ RY(Theta0) ├─░──░──░─┤M├─────────\n",
       "        ├───┤ ░ ├────────────┤ ░  ░  ░ └╥┘┌─┐      \n",
       "   q_1: ┤ H ├─░─┤ RY(Theta1) ├─░──░──░──╫─┤M├──────\n",
       "        ├───┤ ░ ├────────────┤ ░  ░  ░  ║ └╥┘┌─┐   \n",
       "   q_2: ┤ H ├─░─┤ RY(Theta2) ├─░──░──░──╫──╫─┤M├───\n",
       "        ├───┤ ░ ├────────────┤ ░  ░  ░  ║  ║ └╥┘┌─┐\n",
       "   q_3: ┤ H ├─░─┤ RY(Theta3) ├─░──░──░──╫──╫──╫─┤M├\n",
       "        └───┘ ░ └────────────┘ ░  ░  ░  ║  ║  ║ └╥┘\n",
       "meas_0: ════════════════════════════════╩══╬══╬══╬═\n",
       "                                           ║  ║  ║ \n",
       "meas_1: ═══════════════════════════════════╩══╬══╬═\n",
       "                                              ║  ║ \n",
       "meas_2: ══════════════════════════════════════╩══╬═\n",
       "                                                 ║ \n",
       "meas_3: ═════════════════════════════════════════╩═\n",
       "                                                   "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit = QiskitCircuit(NUM_QUBITS, SIMULATOR, NUM_SHOTS)\n",
    "print('Expected value for rotation [pi/4]: {}'.format(circuit.run([-np.pi/4, np.pi/4, -np.pi/4, np.pi/4])))\n",
    "circuit.circuit.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchCircuit()\n",
    "\n",
    "A pytorch layer always has two functions. One for the forward pass and one for the backward pass. The forward pass simply takes the Quantum Circuits variational parameters from the previous pytorch layer and runs the circuit on the defined hardware (defined in `QiskitCircuit.run()`) and returns the measurements from the quantum hardware.\n",
    "These measurements will be the inputs of the next pytorch layer.\n",
    "\n",
    "The backward pass returns the gradients of the quantum circuit. In this case here it is finite difference.\n",
    "\n",
    "the `forward_tensor` is saved from the forward pass. So we just have to do one evaluation of the Q-Circuit in the backpass for the finite difference.\n",
    "\n",
    "The `gradient` variable here is as well hard coded to 3 parameters. This should be updated in the future and made more general.\n",
    "\n",
    "The loop `for k in range(len(input_numbers)):` goes through all the parameters (in this case 3), and shifts them by a small $\\epsilon$. Then it runs the circuit and takes the diefferences of the ouput for the parameters $\\Theta$ and $\\Theta + \\epsilon$. This is the finite difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(NUM_QUBITS, SIMULATOR, shots=NUM_SHOTS)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i)\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = 0.01\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors\n",
    "#         print('forward_tensor = {}'.format(forward_tensor))\n",
    "        input_numbers = i\n",
    "#         print('input_numbers = {}'.format(input_numbers))\n",
    "        gradients = []\n",
    "        \n",
    "        for k in range(len(input_numbers)):\n",
    "#             print(k)\n",
    "            input_eps = input_numbers\n",
    "            input_eps[k] = input_numbers[k] + eps\n",
    "#             print('input_eps = {}'.format(input_eps))\n",
    "            exp_value = ctx.QiskitCirc.run(input_eps)\n",
    "            gradient = (exp_value - forward_tensor[0][k].item())#/eps\n",
    "            gradients.append(gradient)\n",
    "            \n",
    "#         print('gradients = {}'.format(gradients))\n",
    "        result = torch.tensor(gradients)\n",
    "\n",
    "        return result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 after quantum layer: tensor([[0.7100, 0.7150, 0.7040, 0.6966]], dtype=torch.float64,\n",
      "       grad_fn=<TorchCircuitBackward>)\n",
      "x.grad = tensor([ 0.0022,  0.0002, -0.0043,  0.0073])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([np.pi/4, np.pi/4, np.pi/4, np.pi/4], requires_grad=True)\n",
    "# x = torch.tensor([[0.0, 0.0, 0.0]], requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "print('y1 after quantum layer: {}'.format(y1))\n",
    "y1 = nn.Linear(4,1)(y1.float())\n",
    "y1.backward()\n",
    "print('x.grad = {}'.format(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Quantum Circuit separately\n",
    "\n",
    "This example is simply to test the QC with a pytorch optimizer\n",
    "\n",
    "We define a cost function and a target expectation value (here -1). The cost is the square distance from the target value.\n",
    "\n",
    "`x` is the initialization of the parameters. Here again, this was hard coded such that every angle starts at $\\pi / 4$.\n",
    "\n",
    "The rest is standard pytorch optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22f684feac8>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)[0]\n",
    "    # simple linear layer: add up 4 outputs of quantum layer\n",
    "    val = expval[0] + expval[1] + expval[2] + expval[3]\n",
    "    return torch.abs(val - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([np.pi/4, 0, np.pi/4, 0], requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval)\n",
    "#     print(loss.item())\n",
    "\n",
    "plt.plot(loss_list)\n",
    "# print('final parameters: {}'.format(expval_list))\n",
    "    \n",
    "# print(circuit(phi, theta))\n",
    "# print(cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST\n",
    "\n",
    "In this code we can not handle batches yet.\n",
    "This should be implemented as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 100\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size_train = 1\n",
    "batch_size_test = 1\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "n_datapoints = 100\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "labels = mnist_trainset.targets #get labels\n",
    "labels = labels.numpy()\n",
    "idx1 = np.where(labels == 0) #search all zeros\n",
    "idx2 = np.where(labels == 1) # search all ones\n",
    "idx = np.concatenate((idx1[0][0:n_datapoints//2],idx2[0][0:n_datapoints//2])) # concatenate their indices\n",
    "mnist_trainset.targets = labels[idx] \n",
    "mnist_trainset.data = mnist_trainset.data[idx]\n",
    "\n",
    "print(mnist_trainset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network with Q-node\n",
    "\n",
    "This NN is  2 layers of ConvNN and a fully connected layer, with a Q-Node as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, NUM_QUBITS)\n",
    "        self.qft = TorchCircuit.apply\n",
    "        self.fc3 = nn.Linear(NUM_QUBITS, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "#         print(x)\n",
    "        x = self.qft(x[0]) # This is the q node\n",
    "#         print(x)\n",
    "        x = self.fc3(x.float())\n",
    "#         print(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        print(x)\n",
    "#         x = nn.LogSoftmax()(x)\n",
    "#         x = torch.argmax(x)\n",
    "#         x = torch.Tensor([x])\n",
    "#         print(x)\n",
    "        x = torch.cat((x, 1-x), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "# optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "standard pytorch training loop.\n",
    "- Load data from train_loader. Which is this case a single example each step.\n",
    "- Forward pass through NN\n",
    "- Caluculate loss\n",
    "- Backprop and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5098]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5398]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5217]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5073]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5132]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5365]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5141]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5232]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4925]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5145]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5168]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4899]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5049]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5012]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5159]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5243]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5270]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5067]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5293]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5368]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5363]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5356]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5080]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5207]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5151]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5254]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5130]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5519]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5132]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5187]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5392]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5300]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5249]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5359]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5190]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5128]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5172]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5254]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5090]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5251]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5454]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5286]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5353]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5299]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5327]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5320]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5267]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5157]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5318]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5231]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5125]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5236]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5122]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5348]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5152]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4988]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5241]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5122]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5135]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5227]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5243]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5332]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5202]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5346]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5338]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5140]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4931]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5326]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5153]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5281]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5070]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5311]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4948]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4989]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5135]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5246]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5295]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5117]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5075]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5214]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4938]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5146]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5237]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5254]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5175]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4991]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5372]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5069]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5039]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5229]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5182]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5113]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5159]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5175]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5245]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5210]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5083]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4910]], grad_fn=<SigmoidBackward>)\n",
      "Training [5%]\tLoss: -0.4996\n",
      "tensor([[0.5100]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5366]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5253]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5112]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5228]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5080]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5010]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5084]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5136]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5150]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5024]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5134]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5227]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5321]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5098]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4892]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5059]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5239]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5073]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5151]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5005]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5237]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5212]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5215]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5358]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4962]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5205]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5012]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5046]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5188]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5265]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5289]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5103]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5022]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5349]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5117]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4971]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5084]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5291]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5228]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5483]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5380]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4910]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5532]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5502]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5058]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5414]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5527]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5260]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5163]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5258]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5150]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5182]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5320]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5057]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5217]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5120]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5151]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5258]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5307]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5287]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5228]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4909]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5236]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5399]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5247]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4988]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5197]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5284]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5160]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5281]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5241]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5314]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5219]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5262]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5082]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5261]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5387]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5351]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5349]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5225]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5133]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5042]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5118]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5263]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5324]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4870]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5083]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5274]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5199]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4935]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5189]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5291]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5416]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5079]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5233]], grad_fn=<SigmoidBackward>)\n",
      "Training [10%]\tLoss: -0.4990\n",
      "tensor([[0.5218]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5146]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5175]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5033]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5024]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5228]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5262]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5280]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5149]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5373]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5145]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5489]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5295]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5283]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5301]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5438]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5041]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5351]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5456]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5316]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5267]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5182]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5266]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5210]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5213]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5178]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5420]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5227]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5385]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5229]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5350]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5143]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5322]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5233]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5355]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5395]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5408]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5189]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5271]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5177]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5368]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5445]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5245]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5343]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5179]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5379]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5254]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5402]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5330]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5019]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5353]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5068]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4965]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5177]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5349]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5238]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5319]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5562]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5187]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5455]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5344]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5185]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5302]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5316]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5222]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5238]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5191]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5342]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5044]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5304]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5213]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4899]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5353]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5127]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5208]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5155]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5254]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5223]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5163]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5223]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5057]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5356]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5120]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5277]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5342]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5243]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5033]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4583]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5380]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5479]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5219]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5228]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5269]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4783]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5151]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5030]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4653]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5180]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5100]], grad_fn=<SigmoidBackward>)\n",
      "Training [15%]\tLoss: -0.4972\n",
      "tensor([[0.4918]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5128]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5112]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5296]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5189]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4838]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4910]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5012]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5305]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4956]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5194]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5115]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5007]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4982]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5204]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4990]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5251]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4905]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5253]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5277]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4894]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5014]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5169]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4962]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5044]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5093]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5036]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5317]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5195]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5243]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5137]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5078]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5037]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5305]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4964]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5093]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5272]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5001]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5123]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5303]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5191]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5107]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5072]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5057]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5080]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4877]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5098]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5335]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5133]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5405]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5163]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5116]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5287]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4967]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5022]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5178]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5147]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4841]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5072]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5076]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5271]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5059]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5427]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5095]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5161]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5291]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5299]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5227]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5268]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5491]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4943]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5267]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5207]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5181]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5232]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5149]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5257]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5134]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5203]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4988]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5194]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5154]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5325]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5221]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5156]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5108]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5228]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5144]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5060]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5326]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5368]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5323]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4960]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4961]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5198]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5164]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5134]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5133]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4998]], grad_fn=<SigmoidBackward>)\n",
      "Training [20%]\tLoss: -0.4971\n",
      "tensor([[0.4932]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5257]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5206]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5164]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5147]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5213]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5190]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4980]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5173]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5308]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4660]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4853]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5111]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4928]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5162]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4891]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5167]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4834]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5187]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5196]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5236]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4915]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5187]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5173]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5168]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5211]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5273]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4912]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5213]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4777]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5046]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4762]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5158]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5236]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5324]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4987]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5181]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5304]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5266]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5110]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5052]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5214]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4917]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5328]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5254]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5211]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5156]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5138]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5332]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5012]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5150]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5189]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5152]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5302]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4803]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5045]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5123]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4619]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4902]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5320]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5188]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5297]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5240]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5125]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5048]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5323]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5236]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5106]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4992]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4742]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5217]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5050]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5100]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4871]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5028]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4799]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4925]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4997]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5159]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5103]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5170]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5021]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5064]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5125]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4647]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5097]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5344]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5273]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5386]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5088]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5383]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4991]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5028]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4900]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5425]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5057]], grad_fn=<SigmoidBackward>)\n",
      "Training [25%]\tLoss: -0.4958\n",
      "tensor([[0.5279]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5123]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5227]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5138]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5204]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5190]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4850]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5112]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5113]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5022]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5077]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5054]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5041]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5022]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4989]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5173]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5249]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5032]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5045]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4891]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5003]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5171]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5060]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4680]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5188]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5217]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5035]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5172]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4745]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5082]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5177]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5186]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5205]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5093]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5276]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5353]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4963]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4954]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5117]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5123]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5098]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4783]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5036]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5027]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4767]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5289]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5186]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5145]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5102]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4990]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5315]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5081]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5212]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5107]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4884]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4840]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5079]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5078]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5227]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4924]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5397]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5277]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5113]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5131]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5137]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5132]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5116]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5377]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4875]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5214]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5006]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5264]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4701]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4746]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5275]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4869]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5126]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5107]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4955]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5061]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5208]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4811]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5527]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5263]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5248]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4996]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5347]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4919]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4940]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5537]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5217]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5166]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5695]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5203]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5247]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5197]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5466]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5129]], grad_fn=<SigmoidBackward>)\n",
      "Training [30%]\tLoss: -0.4982\n",
      "tensor([[0.5354]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5174]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5263]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5321]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5103]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5132]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4902]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5132]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5232]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5177]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5400]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5435]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5249]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5186]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5182]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5093]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5251]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5153]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5109]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5171]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5076]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5019]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5233]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5160]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5044]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4809]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5118]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5196]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5273]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5489]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5168]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5220]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5413]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5151]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5030]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4799]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4896]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5048]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5150]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5023]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5079]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5192]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5220]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5185]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5349]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5023]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5419]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5120]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5108]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4791]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5022]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5042]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4362]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4784]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4649]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4918]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5166]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5019]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4919]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5113]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5165]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5263]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5094]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4786]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5033]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4814]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5135]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4736]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4991]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4948]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5046]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5018]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5102]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5200]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4990]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5622]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5283]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4824]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4992]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5164]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4991]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5232]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4863]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4777]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5470]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4757]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5251]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5181]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5399]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5308]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4984]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5107]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5278]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4961]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5203]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4977]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5076]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5202]], grad_fn=<SigmoidBackward>)\n",
      "Training [35%]\tLoss: -0.4951\n",
      "tensor([[0.5241]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5218]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4840]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5445]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4778]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5223]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5340]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4852]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5166]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5410]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4905]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5748]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5548]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5368]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5279]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5201]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5565]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5160]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5440]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5766]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5373]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5834]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5046]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5504]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5313]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5337]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5307]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4952]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5473]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4891]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5015]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5064]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5248]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5339]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5487]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5241]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5182]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4992]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5621]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5329]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5373]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5280]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5360]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5103]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5264]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5087]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4715]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4729]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5154]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4631]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5221]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5385]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5491]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5444]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4756]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4766]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5209]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5296]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5130]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5035]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5328]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4976]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5141]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5093]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4947]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4934]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4834]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4533]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5069]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5410]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5363]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5277]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5217]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6448]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4754]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4290]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4374]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4522]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5191]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4809]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5189]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4855]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4826]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5207]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4227]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4808]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5110]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4758]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5077]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4962]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3483]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4345]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5170]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5270]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4749]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4370]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4070]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5278]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4285]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4956]], grad_fn=<SigmoidBackward>)\n",
      "Training [40%]\tLoss: -0.5064\n",
      "tensor([[0.5148]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4075]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4891]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4487]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3924]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3783]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4476]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3995]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4442]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4674]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3778]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4208]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.7102]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4504]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4101]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3485]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3627]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5155]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4252]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4182]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5216]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4218]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4901]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5027]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4355]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3898]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4083]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3717]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4788]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4104]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4439]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5879]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4260]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4800]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3761]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4730]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3556]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.7030]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3789]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4487]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4600]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5592]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3994]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4665]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5359]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4094]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5820]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5515]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5662]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4319]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5671]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6695]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5920]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6403]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4750]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5273]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4903]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4664]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4391]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4978]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5504]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5220]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5547]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5575]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5454]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4550]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5114]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5466]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4035]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4274]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5361]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4717]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5031]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5190]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6179]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4595]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6783]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3993]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.2923]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6465]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6945]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5634]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4673]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3219]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3934]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4408]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6127]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4711]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4432]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5131]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6767]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4782]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4328]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4008]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5887]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5110]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5898]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5368]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6881]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4473]], grad_fn=<SigmoidBackward>)\n",
      "Training [45%]\tLoss: -0.5188\n",
      "tensor([[0.5507]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5589]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5461]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4847]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5037]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3324]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3243]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4198]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4298]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6137]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3910]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6785]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4621]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3992]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4265]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5947]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5440]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6559]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4965]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4673]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5782]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3707]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5404]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3251]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4282]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4557]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3929]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5714]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3548]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6501]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6353]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6863]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3508]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5559]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4271]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4470]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3912]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5371]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4573]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.7009]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5885]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3110]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4039]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5124]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4082]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4751]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3532]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5832]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.7423]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5361]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.7473]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5046]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5596]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6023]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5141]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3064]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4348]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3328]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5229]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4914]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5630]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3635]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3036]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5778]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4580]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4202]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4841]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4931]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5366]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5357]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3970]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4773]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3885]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6474]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4236]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5436]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4797]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6096]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4696]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5778]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4682]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6347]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5798]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5509]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6484]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4047]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4863]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5127]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5297]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6667]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5556]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4017]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3953]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4194]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6483]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5680]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6369]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5515]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3575]], grad_fn=<SigmoidBackward>)\n",
      "Training [50%]\tLoss: -0.5137\n",
      "tensor([[0.4426]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6524]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4482]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4741]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4750]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4551]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.3977]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5147]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6745]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6659]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5065]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5424]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5186]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6631]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5137]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6423]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6481]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5186]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6225]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5551]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5195]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5876]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5182]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5242]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5208]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5063]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5349]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5208]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5198]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6225]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5356]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5312]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6181]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5274]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5295]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5186]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5256]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5241]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5352]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5269]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5495]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5748]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5225]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5296]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5107]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5313]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6090]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5262]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6759]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6536]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5198]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5146]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5267]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6739]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6755]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5333]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5223]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5923]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5262]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5251]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5175]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5888]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6173]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5275]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6368]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6182]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5334]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5259]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5179]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6352]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6187]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5338]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5216]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5911]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5207]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5112]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6477]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5313]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5748]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5467]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5294]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5211]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6317]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5178]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5266]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6122]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5223]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5286]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5786]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5227]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5291]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5162]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5321]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5202]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5123]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5203]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5151]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5192]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5129]], grad_fn=<SigmoidBackward>)\n",
      "Training [55%]\tLoss: -0.5056\n",
      "tensor([[0.5219]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5141]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6325]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5300]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5284]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5216]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5051]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6421]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6579]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5238]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6624]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5221]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5240]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6677]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5211]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5372]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5268]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6376]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6143]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6573]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6287]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5220]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5418]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5197]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5319]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5263]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5219]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5382]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5280]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6629]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5205]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6656]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5393]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5237]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5255]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6768]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5175]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5280]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5211]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6512]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5319]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5145]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5195]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6704]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5306]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5173]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5344]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5383]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5265]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5223]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5232]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5318]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6097]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6650]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5202]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5297]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5273]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5364]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5260]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5278]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5221]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5370]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5219]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6375]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5219]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5251]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5299]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5283]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5351]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5238]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5314]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5306]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6796]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6094]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5171]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5315]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5304]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5262]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5437]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5398]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5257]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5346]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5210]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5214]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6540]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5283]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5354]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5268]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5339]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5371]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5241]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5247]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5362]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6715]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5320]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5210]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5324]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5243]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5365]], grad_fn=<SigmoidBackward>)\n",
      "Training [60%]\tLoss: -0.4956\n",
      "tensor([[0.5258]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6360]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5228]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5313]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6591]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5177]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5325]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5197]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5217]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5313]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5366]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5249]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5142]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5296]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6784]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5186]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5314]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5210]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5117]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6454]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5167]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5259]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5247]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5266]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5261]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5270]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5415]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5858]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5350]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5195]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6745]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5315]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6771]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5265]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5270]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5207]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5233]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5228]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5390]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5247]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5294]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5191]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6565]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5307]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5359]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5329]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5264]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5345]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6806]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6819]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5228]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5341]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5199]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5321]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5343]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5304]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5426]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5298]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5274]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5112]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5899]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6760]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5356]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5370]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5378]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6805]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5259]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5395]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5187]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5247]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5287]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5292]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5319]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5233]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5289]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5329]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5336]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5232]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5198]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5316]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6259]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5313]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5231]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5355]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5343]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6343]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6883]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6847]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5345]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5266]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5240]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5194]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6129]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5367]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5121]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6704]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5309]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6465]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5179]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5228]], grad_fn=<SigmoidBackward>)\n",
      "Training [65%]\tLoss: -0.4985\n",
      "tensor([[0.5270]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5234]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6673]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5184]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6749]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5192]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5242]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5260]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5311]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5213]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5273]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5165]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6607]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6769]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5278]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5222]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6706]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5250]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6180]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5309]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5270]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5782]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5851]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6263]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5819]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6565]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5158]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5199]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5173]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5120]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5239]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5205]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5285]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5185]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5194]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5251]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5231]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5134]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5144]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5268]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5197]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5097]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5140]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5204]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5125]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5120]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5190]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5120]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6692]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5187]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5218]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5216]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5300]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5143]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5194]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5139]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5158]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5731]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5346]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5214]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5165]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5248]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5343]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5212]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5259]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6541]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5188]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5251]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5243]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5223]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5183]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6697]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5328]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6729]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5217]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5933]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5212]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5280]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5355]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5224]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6684]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5346]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5198]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5219]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5247]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5275]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5215]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5321]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5330]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6729]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5236]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5260]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5210]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5314]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5241]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5209]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5406]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6276]], grad_fn=<SigmoidBackward>)\n",
      "Training [70%]\tLoss: -0.4966\n",
      "tensor([[0.5283]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5258]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5292]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5955]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5417]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5312]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5309]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5351]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5316]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5315]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5218]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5297]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5213]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6642]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6749]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5442]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5253]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5274]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5389]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5280]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6628]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5352]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6472]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5294]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5436]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5296]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5352]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5312]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5361]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5289]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5323]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5350]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6641]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6699]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5220]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5339]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5409]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6800]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5276]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5197]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5862]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5367]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5189]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5283]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5313]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5433]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5243]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5322]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6457]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5218]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5255]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5242]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5209]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6638]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5242]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5242]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6750]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5196]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5185]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5312]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5283]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5144]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5301]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5197]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5207]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5217]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5267]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5340]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5098]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6031]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6687]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5218]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6558]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5161]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5165]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5262]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6605]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5179]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6702]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5244]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5136]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5138]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5182]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5311]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6383]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6583]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6709]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5216]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5258]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6807]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5287]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5242]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5270]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5358]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5286]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5091]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5281]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5245]], grad_fn=<SigmoidBackward>)\n",
      "Training [75%]\tLoss: -0.5044\n",
      "tensor([[0.5260]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5252]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5208]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6764]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5272]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5257]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5326]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5463]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5310]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5318]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5236]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5215]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5440]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5270]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5319]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5372]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5446]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6097]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5355]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5225]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5309]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5261]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5188]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6734]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5337]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5253]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5224]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6069]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5253]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5312]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5160]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5168]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6571]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5159]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5255]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5194]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5244]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5217]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5285]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5185]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6691]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5336]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5186]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5252]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6745]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5267]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6591]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5330]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6603]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5207]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5249]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6535]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5165]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5260]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5372]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5314]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5323]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6653]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6672]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5332]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5413]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6650]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5136]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5341]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5294]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5323]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5403]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5166]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6592]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5325]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6636]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6542]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5251]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6604]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5387]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5323]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5225]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6657]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6635]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6687]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6586]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5226]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5409]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5169]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5196]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5249]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5335]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6667]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5234]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6229]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5212]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5312]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6722]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5351]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5243]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5229]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5274]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5345]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5283]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5246]], grad_fn=<SigmoidBackward>)\n",
      "Training [80%]\tLoss: -0.4913\n",
      "tensor([[0.5265]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5503]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5325]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5256]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6728]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5425]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6655]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5199]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5356]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5173]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5374]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5397]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5465]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5230]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5266]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6815]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6563]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5392]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5292]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5450]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5324]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5372]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5524]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5303]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5310]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5186]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6374]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5280]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6526]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5237]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6724]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5277]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5297]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5426]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5105]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5298]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6678]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6717]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5518]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6707]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6738]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5373]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5271]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5346]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5321]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6829]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6713]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5347]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5271]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5231]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6700]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5232]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6630]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6770]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5365]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5182]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5253]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5442]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5176]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6611]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5181]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5241]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5166]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6595]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6526]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.7204]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5365]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5209]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5355]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5166]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5200]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5231]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5341]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5178]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6693]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5237]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5220]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5263]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5222]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5202]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6551]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6619]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5195]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5325]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5253]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5309]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5227]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5329]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5306]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5203]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5202]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6678]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6537]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5265]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5265]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5192]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5340]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6416]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5284]], grad_fn=<SigmoidBackward>)\n",
      "Training [85%]\tLoss: -0.4953\n",
      "tensor([[0.5199]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5266]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5273]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5416]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5373]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5358]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5295]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6597]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5330]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5303]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5333]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5317]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5233]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5117]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6272]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5299]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5429]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6740]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5268]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6669]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5444]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5390]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5250]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5276]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5195]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6723]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5218]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5151]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5097]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6607]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5191]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5209]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6676]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5224]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5106]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5181]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6643]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6598]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6002]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5092]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5186]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5417]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5348]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5275]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5155]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5229]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5159]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5063]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6577]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5138]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6667]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5307]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6666]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5170]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6332]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5337]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5335]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6714]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5209]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5343]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()        \n",
    "        # Forward pass\n",
    "        output = network(data)\n",
    "        # Calculating loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Neg Log Likelihood Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of NN\n",
    "\n",
    "The outcome is not always the same because the prediction is probabilistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0514]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0719]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0691]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0549]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0523]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0549]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0678]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0698]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0609]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0619]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0529]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0541]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0560]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0644]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0650]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0817]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0594]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0738]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0794]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0769]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0516]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0636]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0550]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0577]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0720]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0435]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0765]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0755]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0626]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0722]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0573]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0673]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0379]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0581]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0392]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0512]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0762]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0798]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0681]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0472]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0532]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0810]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0517]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0771]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0486]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0600]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0484]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0601]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0551]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0642]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0754]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0807]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0557]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0613]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0549]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0659]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0751]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0667]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0401]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0553]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0441]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0563]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0672]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0564]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0724]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0624]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0431]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0727]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0701]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0496]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0558]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0762]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0716]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0618]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0636]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0809]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0622]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0746]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0470]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0463]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0836]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0642]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0826]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0668]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0922]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0731]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0699]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0539]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0564]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0755]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0671]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0751]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0718]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0503]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0644]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0732]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0597]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0626]], grad_fn=<AddmmBackward>)\n",
      "Performance on test data is is: 0.5\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "number = 0\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    number +=1\n",
    "    output = network(data)\n",
    "    output = (output>0.5).float()\n",
    "    accuracy += (output[0][1].item() == target[0].item())*1\n",
    "    \n",
    "print(\"Performance on test data is is: {}\".format(accuracy/number))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0382]])\n",
      "tensor([[0.0757]])\n",
      "tensor([[0.0685]])\n",
      "tensor([[0.0698]])\n",
      "tensor([[0.0790]])\n",
      "tensor([[0.0580]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = network(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title('Predicted {}'.format(pred.item()))\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
