{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals.\n",
    "#\n",
    "# Code adapted from QizGloria team, Qiskit Camp Europe 2019, updated by \n",
    "# Team Ube Pancake, Qiskit Summer Jam 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumRegister,QuantumCircuit,ClassicalRegister,execute\n",
    "from qiskit.circuit import Parameter,ControlledGate\n",
    "from qiskit import Aer\n",
    "import qiskit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "\n",
    "NUM_QUBITS = 4\n",
    "NUM_SHOTS = 10000\n",
    "SHIFT = np.pi/8\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.5\n",
    "\n",
    "SIMULATOR = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to translate Q-Circuit parameters from pytorch back to QISKIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Contruct QuantumCircuit QFT Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:09:30.598730Z",
     "start_time": "2019-10-01T16:09:30.567861Z"
    }
   },
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self.circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        self.n_qubits = n_qubits\n",
    "        self.theta0 = Parameter('Theta0')\n",
    "        self.theta1 = Parameter('Theta1')\n",
    "        self.theta2 = Parameter('Theta2')\n",
    "        self.theta3 = Parameter('Theta3')\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.circuit.h(all_qubits)\n",
    "        self.circuit.barrier()\n",
    "        self.circuit.ry(self.theta0, 0)\n",
    "        self.circuit.ry(self.theta1, 1)\n",
    "        self.circuit.ry(self.theta2, 2)\n",
    "        self.circuit.ry(self.theta3, 3)\n",
    "        self.circuit.barrier()\n",
    "        \n",
    "#         # Apply controlled-unitary\n",
    "# #         uc=ry(self.theta4, 4).to_gate().control(4)\n",
    "# #         self.circuit.append(uc, [0,1,2,3,4])\n",
    "#         self.circuit.ry(self.theta4, 4).to_gate().control(4)\n",
    "    \n",
    "        self.circuit.barrier()\n",
    "        self.circuit.measure_all()\n",
    "        # ---------------------------\n",
    "        \n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects  \n",
    "    \n",
    "    def run(self, i):\n",
    "        params = i[0]\n",
    "#         print('params = {}'.format(len(params)))\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        job_sim = execute(self.circuit,\n",
    "                          self.backend,\n",
    "                          shots=self.shots,\n",
    "                          parameter_binds = [{self.theta0 : float(params[0].item()),\n",
    "                                              self.theta1 : float(params[1].item()),\n",
    "                                              self.theta2 : float(params[2].item()),\n",
    "                                              self.theta3 : float(params[3].item())}])\n",
    "        \n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value for rotation [pi/4]: [ 0.701  -0.703   0.6966 -0.7038]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐ ░ ┌────────────┐ ░  ░  ░ ┌─┐         \n",
       "   q_0: ┤ H ├─░─┤ RY(Theta0) ├─░──░──░─┤M├─────────\n",
       "        ├───┤ ░ ├────────────┤ ░  ░  ░ └╥┘┌─┐      \n",
       "   q_1: ┤ H ├─░─┤ RY(Theta1) ├─░──░──░──╫─┤M├──────\n",
       "        ├───┤ ░ ├────────────┤ ░  ░  ░  ║ └╥┘┌─┐   \n",
       "   q_2: ┤ H ├─░─┤ RY(Theta2) ├─░──░──░──╫──╫─┤M├───\n",
       "        ├───┤ ░ ├────────────┤ ░  ░  ░  ║  ║ └╥┘┌─┐\n",
       "   q_3: ┤ H ├─░─┤ RY(Theta3) ├─░──░──░──╫──╫──╫─┤M├\n",
       "        └───┘ ░ └────────────┘ ░  ░  ░  ║  ║  ║ └╥┘\n",
       "meas_0: ════════════════════════════════╩══╬══╬══╬═\n",
       "                                           ║  ║  ║ \n",
       "meas_1: ═══════════════════════════════════╩══╬══╬═\n",
       "                                              ║  ║ \n",
       "meas_2: ══════════════════════════════════════╩══╬═\n",
       "                                                 ║ \n",
       "meas_3: ═════════════════════════════════════════╩═\n",
       "                                                   </pre>"
      ],
      "text/plain": [
       "        ┌───┐ ░ ┌────────────┐ ░  ░  ░ ┌─┐         \n",
       "   q_0: ┤ H ├─░─┤ RY(Theta0) ├─░──░──░─┤M├─────────\n",
       "        ├───┤ ░ ├────────────┤ ░  ░  ░ └╥┘┌─┐      \n",
       "   q_1: ┤ H ├─░─┤ RY(Theta1) ├─░──░──░──╫─┤M├──────\n",
       "        ├───┤ ░ ├────────────┤ ░  ░  ░  ║ └╥┘┌─┐   \n",
       "   q_2: ┤ H ├─░─┤ RY(Theta2) ├─░──░──░──╫──╫─┤M├───\n",
       "        ├───┤ ░ ├────────────┤ ░  ░  ░  ║  ║ └╥┘┌─┐\n",
       "   q_3: ┤ H ├─░─┤ RY(Theta3) ├─░──░──░──╫──╫──╫─┤M├\n",
       "        └───┘ ░ └────────────┘ ░  ░  ░  ║  ║  ║ └╥┘\n",
       "meas_0: ════════════════════════════════╩══╬══╬══╬═\n",
       "                                           ║  ║  ║ \n",
       "meas_1: ═══════════════════════════════════╩══╬══╬═\n",
       "                                              ║  ║ \n",
       "meas_2: ══════════════════════════════════════╩══╬═\n",
       "                                                 ║ \n",
       "meas_3: ═════════════════════════════════════════╩═\n",
       "                                                   "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit = QiskitCircuit(NUM_QUBITS, SIMULATOR, NUM_SHOTS)\n",
    "print('Expected value for rotation [pi/4]: {}'.format(circuit.run(torch.Tensor([[-np.pi/4, np.pi/4, -np.pi/4, np.pi/4]]))))\n",
    "circuit.circuit.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchCircuit()\n",
    "\n",
    "A pytorch layer always has two functions. One for the forward pass and one for the backward pass. The forward pass simply takes the Quantum Circuits variational parameters from the previous pytorch layer and runs the circuit on the defined hardware (defined in `QiskitCircuit.run()`) and returns the measurements from the quantum hardware.\n",
    "These measurements will be the inputs of the next pytorch layer.\n",
    "\n",
    "The backward pass returns the gradients of the quantum circuit. In this case here it is finite difference.\n",
    "\n",
    "the `forward_tensor` is saved from the forward pass. So we just have to do one evaluation of the Q-Circuit in the backpass for the finite difference.\n",
    "\n",
    "The `gradient` variable here is as well hard coded to 3 parameters. This should be updated in the future and made more general.\n",
    "\n",
    "The loop `for k in range(len(input_numbers)):` goes through all the parameters (in this case 3), and shifts them by a small $\\epsilon$. Then it runs the circuit and takes the diefferences of the ouput for the parameters $\\Theta$ and $\\Theta + \\epsilon$. This is the finite difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(NUM_QUBITS, SIMULATOR, shots=NUM_SHOTS)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i)\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = 0.01\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors\n",
    "#         print('forward_tensor = {}'.format(forward_tensor))\n",
    "        input_numbers = i\n",
    "        gradients = []\n",
    "        \n",
    "        for k in range(len(input_numbers)):\n",
    "            input_eps = input_numbers\n",
    "            input_eps[k] = input_numbers[k] + eps\n",
    "            exp_value = ctx.QiskitCirc.run(torch.Tensor(input_eps))\n",
    "            gradient = (exp_value - forward_tensor[0][k].item())#/eps\n",
    "            gradients.append(gradient)\n",
    "            \n",
    "#         print('gradient = {}'.format(gradients))\n",
    "        result = torch.tensor(gradients)\n",
    "\n",
    "        return result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 after quantum layer: tensor([[0.7140, 0.7056, 0.7072, 0.7122]], dtype=torch.float64,\n",
      "       grad_fn=<TorchCircuitBackward>)\n",
      "x.grad = tensor([[-0.0002,  0.0011, -0.0028, -0.0003]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[np.pi/4, np.pi/4, np.pi/4, np.pi/4]], requires_grad=True)\n",
    "# x = torch.tensor([[0.0, 0.0, 0.0]], requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "print('y1 after quantum layer: {}'.format(y1))\n",
    "y1 = nn.Linear(4,1)(y1.float())\n",
    "y1.backward()\n",
    "print('x.grad = {}'.format(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Quantum Circuit separately\n",
    "\n",
    "This example is simply to test the QC with a pytorch optimizer\n",
    "\n",
    "We define a cost function and a target expectation value (here -1). The cost is the square distance from the target value.\n",
    "\n",
    "`x` is the initialization of the parameters. Here again, this was hard coded such that every angle starts at $\\pi / 4$.\n",
    "\n",
    "The rest is standard pytorch optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:05<00:00, 18.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a12bfdec88>]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)[0]\n",
    "    # simple linear layer: add up 4 outputs of quantum layer\n",
    "    val = expval[0] + expval[1] + expval[2] + expval[3]\n",
    "    return torch.abs(val - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([[np.pi/4, 0, np.pi/4, 0]], requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval)\n",
    "#     print(loss.item())\n",
    "\n",
    "plt.plot(loss_list)\n",
    "# print('final parameters: {}'.format(expval_list))\n",
    "    \n",
    "# print(circuit(phi, theta))\n",
    "# print(cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST\n",
    "\n",
    "In this code we can not handle batches yet.\n",
    "This should be implemented as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0683461ca0b44761958b35fc21525b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Using downloaded and verified file: ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Using downloaded and verified file: ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Using downloaded and verified file: ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Processing...\n",
      "\n",
      "Done!\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 100\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size_train = 1\n",
    "batch_size_test = 1\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "n_datapoints = 100\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "labels = mnist_trainset.targets #get labels\n",
    "labels = labels.numpy()\n",
    "idx1 = np.where(labels == 0) #search all zeros\n",
    "idx2 = np.where(labels == 1) # search all ones\n",
    "idx = np.concatenate((idx1[0][0:n_datapoints//2],idx2[0][0:n_datapoints//2])) # concatenate their indices\n",
    "mnist_trainset.targets = labels[idx] \n",
    "mnist_trainset.data = mnist_trainset.data[idx]\n",
    "\n",
    "print(mnist_trainset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network with Q-node\n",
    "\n",
    "This NN is  2 layers of ConvNN and a fully connected layer, with a Q-Node as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, NUM_QUBITS)\n",
    "        self.qft = TorchCircuit.apply\n",
    "        self.fc3 = nn.Linear(NUM_QUBITS, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = np.pi*torch.tanh(x)\n",
    "        x = self.qft(x) # This is the q node\n",
    "        x = self.fc3(x.float())\n",
    "#         print(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "#         x = torch.argmax(x)\n",
    "#         x = torch.Tensor([x])\n",
    "#         print(x)\n",
    "#         x = torch.cat((x, 1-x), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "# optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "standard pytorch training loop.\n",
    "- Load data from train_loader. Which is this case a single example each step.\n",
    "- Forward pass through NN\n",
    "- Caluculate loss\n",
    "- Backprop and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training [5%]\tLoss: -0.5020\n",
      "Training [10%]\tLoss: -0.5133\n",
      "Training [15%]\tLoss: -0.5236\n",
      "Training [20%]\tLoss: -0.5856\n",
      "Training [25%]\tLoss: -0.5969\n",
      "Training [30%]\tLoss: -0.5962\n",
      "Training [35%]\tLoss: -0.5256\n",
      "Training [40%]\tLoss: -0.5173\n",
      "Training [45%]\tLoss: -0.5506\n",
      "Training [50%]\tLoss: -0.5215\n",
      "Training [55%]\tLoss: -0.4830\n",
      "Training [60%]\tLoss: -0.5038\n",
      "Training [65%]\tLoss: -0.5005\n",
      "Training [70%]\tLoss: -0.4840\n",
      "Training [75%]\tLoss: -0.4973\n",
      "Training [80%]\tLoss: -0.4737\n",
      "Training [85%]\tLoss: -0.4968\n",
      "Training [90%]\tLoss: -0.4973\n",
      "Training [95%]\tLoss: -0.4970\n",
      "Training [100%]\tLoss: -0.5026\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()        \n",
    "        # Forward pass\n",
    "        output = network(data)\n",
    "        # Calculating loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Neg Log Likelihood Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of NN\n",
    "\n",
    "The outcome is not always the same because the prediction is probabilistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "number = 0\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    number +=1\n",
    "    output = network(data)\n",
    "    output = (output>0.5).float()\n",
    "    accuracy += (output[0][1].item() == target[0].item())*1\n",
    "    \n",
    "print(\"Performance on test data is is: {}\".format(accuracy/number))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = network(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title('Predicted {}'.format(pred.item()))\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
