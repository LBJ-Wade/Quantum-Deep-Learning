{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals.\n",
    "#\n",
    "# Code adapted from QizGloria team, Qiskit Camp Europe 2019, updated by \n",
    "# Team Ube Pancake, Qiskit Summer Jam 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumRegister,QuantumCircuit,ClassicalRegister,execute\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import Aer\n",
    "import qiskit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "\n",
    "NUM_SHOTS = 10000\n",
    "\n",
    "SIMULATOR = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to translate Q-Circuit parameters from pytorch back to QISKIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QiskitCircuit()\n",
    "\n",
    "Parameters have to be defined according to the circuit. In this case we have a unitary U3 with 3 parameters, which we call Theta, Phi and Lambda.\n",
    "The paramter `shots` always has to be defined. It gives the number of measurements done on the simulator or on the hardware to do the averages for the expectation values.\n",
    "\n",
    "### create_circuit()\n",
    "Define a quantum cirquit in QISKIT language\n",
    "\n",
    "### N_qubit_expectation_Z()\n",
    "This is a function that allows to take the measurements and translate them to Z-expectation values for every single qubit.\n",
    "\n",
    "### bind( parameters )\n",
    "Takes the Neural Network parameters and puts them into a format that can be fed into the QIKSIT unitaries.\n",
    "\n",
    "To generalze this code we would have to write a function that replaces the line `self.circuit.data[2][0]._params`.\n",
    "Because the `self.circuit.data` is a list of all the gates  of the circuit. And the indices direct to the correct gate, where the parameters have to go.\n",
    "\n",
    "At some point we would need a better scheme here.\n",
    "\n",
    "### run( parameters )\n",
    "This function puts the circuit with the given parameters on a quantum simulater or hardware and returns the measurements of every qubit in Z-basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:09:30.598730Z",
     "start_time": "2019-10-01T16:09:30.567861Z"
    }
   },
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self.circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        \n",
    "        self.theta = Parameter('Theta')\n",
    "        self.phi = Parameter('Phi')\n",
    "        self.lam = Parameter('Lambda')\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.circuit.h(all_qubits)\n",
    "        self.circuit.barrier()\n",
    "        self.circuit.u3(self.theta, self.phi, self.lam, all_qubits)\n",
    "        self.circuit.barrier()\n",
    "        self.circuit.measure_all()\n",
    "        # ---------------------------\n",
    "        \n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects\n",
    "    \n",
    "    def run(self, i):\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        job_sim = execute(self.circuit,\n",
    "                          self.backend,\n",
    "                          shots=self.shots,\n",
    "                          parameter_binds=[{self.theta : i[0].item(),\n",
    "                                            self.phi : i[1].item(),\n",
    "                                            self.lam : i[2].item()}])\n",
    "        \n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value for rotation [pi/4, pi/4, pi/4]: 0.5152000000000001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐ ░ ┌──────────────────────┐ ░  ░ ┌─┐\n",
       "   q_0: ┤ H ├─░─┤ U3(Theta,Phi,Lambda) ├─░──░─┤M├\n",
       "        └───┘ ░ └──────────────────────┘ ░  ░ └╥┘\n",
       "meas_0: ═══════════════════════════════════════╩═\n",
       "                                                 </pre>"
      ],
      "text/plain": [
       "        ┌───┐ ░ ┌──────────────────────┐ ░  ░ ┌─┐\n",
       "   q_0: ┤ H ├─░─┤ U3(Theta,Phi,Lambda) ├─░──░─┤M├\n",
       "        └───┘ ░ └──────────────────────┘ ░  ░ └╥┘\n",
       "meas_0: ═══════════════════════════════════════╩═\n",
       "                                                 "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit = QiskitCircuit(1, SIMULATOR, NUM_SHOTS)\n",
    "print('Expected value for rotation [pi/4, pi/4, pi/4]: {}'.format(circuit.run(torch.Tensor([np.pi/4, np.pi/4, np.pi/4]))[0]))\n",
    "circuit.circuit.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchCircuit()\n",
    "\n",
    "A pytorch layer always has two functions. One for the forward pass and one for the backward pass. The forward pass simply takes the Quantum Circuits variational parameters from the previous pytorch layer and runs the circuit on the defined hardware (defined in `QiskitCircuit.run()`) and returns the measurements from the quantum hardware.\n",
    "These measurements will be the inputs of the next pytorch layer.\n",
    "\n",
    "The backward pass returns the gradients of the quantum circuit. In this case here it is finite difference.\n",
    "\n",
    "the `forward_tensor` is saved from the forward pass. So we just have to do one evaluation of the Q-Circuit in the backpass for the finite difference.\n",
    "\n",
    "The `gradient` variable here is as well hard coded to 3 parameters. This should be updated in the future and made more general.\n",
    "\n",
    "The loop `for k in range(len(input_numbers)):` goes through all the parameters (in this case 3), and shifts them by a small $\\epsilon$. Then it runs the circuit and takes the diefferences of the ouput for the parameters $\\Theta$ and $\\Theta + \\epsilon$. This is the finite difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(1, SIMULATOR, shots=NUM_SHOTS)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i[0])\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = 0.01\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors\n",
    "#         print(i)\n",
    "        input_numbers = to_numbers(i[0])\n",
    "#         print(input_numbers)\n",
    "        gradient = [0,0,0]\n",
    "        \n",
    "        for k in range(len(input_numbers)):\n",
    "            input_eps = input_numbers\n",
    "            input_eps[k] = input_numbers[k] + eps\n",
    "            exp_value = ctx.QiskitCirc.run(torch.tensor(input_eps))[0]\n",
    "            gradient_result = (exp_value - forward_tensor[0][0].item())#/eps\n",
    "            gradient[k] = gradient_result\n",
    "            \n",
    "#         print(gradient)\n",
    "        result = torch.tensor([gradient])\n",
    "#         print(result)\n",
    "\n",
    "        return result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0094, 0.0246, 0.0178]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[np.pi/4, np.pi/4, np.pi/4]], requires_grad=True)\n",
    "# x = torch.tensor([[0.0, 0.0, 0.0]], requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "y1.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Quantum Circuit separately\n",
    "\n",
    "This example is simply to test the QC with a pytorch optimizer\n",
    "\n",
    "We define a cost function and a target expectation value (here -1). The cost is the square distance from the target value.\n",
    "\n",
    "`x` is the initialization of the parameters. Here again, this was hard coded such that every angle starts at $\\pi / 4$.\n",
    "\n",
    "The rest is standard pytorch optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 12.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x188659aaf60>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)\n",
    "    return torch.abs(qc(x) - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([[-np.pi/2, -np.pi/2, -np.pi/2]], requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 50\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval.item())\n",
    "#     print(loss.item())\n",
    "\n",
    "plt.plot(loss_list)\n",
    "    \n",
    "# print(circuit(phi, theta))\n",
    "# print(cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST\n",
    "\n",
    "In this code we can not handle batches yet.\n",
    "This should be implemented as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 100\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size_train = 1\n",
    "batch_size_test = 1\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "n_datapoints = 100\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "labels = mnist_trainset.targets #get labels\n",
    "labels = labels.numpy()\n",
    "idx1 = np.where(labels == 0) #search all zeros\n",
    "idx2 = np.where(labels == 1) # search all ones\n",
    "idx = np.concatenate((idx1[0][0:n_datapoints//2],idx2[0][0:n_datapoints//2])) # concatenate their indices\n",
    "mnist_trainset.targets = labels[idx] \n",
    "mnist_trainset.data = mnist_trainset.data[idx]\n",
    "\n",
    "print(mnist_trainset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network with Q-node\n",
    "\n",
    "This NN is  2 layers of ConvNN and a fully connected layer, with a Q-Node as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "#         return F.softmax(x)\n",
    "        x = np.pi*torch.tanh(x)\n",
    "        x = qc(x) # This is the q node\n",
    "        x = (x+1)/2 # Translate expectation values [-1,1] to labels [0,1]\n",
    "        x = torch.cat((x, 1-x), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "# optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "standard pytorch training loop.\n",
    "- Load data from train_loader. Which is this case a single example each step.\n",
    "- Forward pass through NN\n",
    "- Caluculate loss\n",
    "- Backprop and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training [5%]\tLoss: -0.5323\n",
      "Training [10%]\tLoss: -0.5169\n",
      "Training [15%]\tLoss: -0.5233\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()        \n",
    "        # Forward pass\n",
    "        output = network(data)\n",
    "        # Calculating loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Neg Log Likelihood Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of NN\n",
    "\n",
    "The outcome is not always the same because the prediction is probabilistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "number = 0\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    number +=1\n",
    "    output = network(data)\n",
    "    output = (output>0.5).float()\n",
    "    accuracy += (output[0][1].item() == target[0].item())*1\n",
    "    \n",
    "print(\"Performance on test data is is: {}\".format(accuracy/number))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = network(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title('Predicted {}'.format(pred.item()))\n",
    "        \n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
