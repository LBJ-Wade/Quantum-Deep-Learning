{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumRegister,QuantumCircuit,ClassicalRegister,execute\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import Aer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to translate Q-Circuit parameters from pytorch back to QISKIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QiskitCircuit()\n",
    "\n",
    "Parameters have to be defined according to the circuit. In this case we have a unitary U3 with 3 parameters, which we call Theta, Phi and Lambda.\n",
    "The paramter `shots` always has to be defined. It gives the number of measurements done on the simulator or on the hardware to do the averages for the expectation values.\n",
    "\n",
    "### create_circuit()\n",
    "Define a quantum cirquit in QISKIT language\n",
    "\n",
    "### N_qubit_expectation_Z()\n",
    "This is a function that allows to take the measurements and translate them to Z-expectation values for every single qubit.\n",
    "\n",
    "### bind( parameters )\n",
    "Takes the Neural Network parameters and puts them into a format that can be fed into the QIKSIT unitaries.\n",
    "\n",
    "To generalze this code we would have to write a function that replaces the line `self.circuit.data[2][0]._params`.\n",
    "Because the `self.circuit.data` is a list of all the gates  of the circuit. And the indices direct to the correct gate, where the parameters have to go.\n",
    "\n",
    "At some point we would need a better scheme here.\n",
    "\n",
    "### run( parameters )\n",
    "This function puts the circuit with the given parameters on a quantum simulater or hardware and returns the measurements of every qubit in Z-basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:09:30.598730Z",
     "start_time": "2019-10-01T16:09:30.567861Z"
    }
   },
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self,shots):\n",
    "        self.theta = Parameter('Theta')\n",
    "        self.phi = Parameter('Phi')\n",
    "        self.lam = Parameter('Lambda')\n",
    "        self.shots = shots\n",
    "        \n",
    "        def create_circuit():\n",
    "            qr = QuantumRegister(1,'q')\n",
    "            cr = ClassicalRegister(1,'c')\n",
    "            ckt = QuantumCircuit(qr,cr)\n",
    "            ckt.h(qr[0])\n",
    "            ckt.barrier()\n",
    "            ckt.u3(self.theta,self.phi,self.lam,qr[0])\n",
    "            ckt.barrier()\n",
    "            ckt.measure(qr,cr)\n",
    "            return ckt\n",
    "        \n",
    "        self.circuit = create_circuit()\n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects    \n",
    "    \n",
    "    def bind(self, parameters):\n",
    "        [self.theta,self.phi,self.lam] = to_numbers(parameters)\n",
    "        self.circuit.data[2][0]._params = to_numbers(parameters)\n",
    "    \n",
    "    def run(self, i):\n",
    "        self.bind(i)\n",
    "        \n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        job_sim = execute(self.circuit,backend,shots=self.shots)\n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchCircuit()\n",
    "\n",
    "A pytorch layer always has two functions. One for the forward pass and one for the backward pass. The forward pass simply takes the Quantum Circuits variational parameters from the previous pytorch layer and runs the circuit on the defined hardware (defined in `QiskitCircuit.run()`) and returns the measurements from the quantum hardware.\n",
    "These measurements will be the inputs of the next pytorch layer.\n",
    "\n",
    "The backward pass returns the gradients of the quantum circuit. In this case here it is finite difference.\n",
    "\n",
    "the `forward_tensor` is saved from the forward pass. So we just have to do one evaluation of the Q-Circuit in the backpass for the finite difference.\n",
    "\n",
    "The `gradient` variable here is as well hard coded to 3 parameters. This should be updated in the future and made more general.\n",
    "\n",
    "The loop `for k in range(len(input_numbers)):` goes through all the parameters (in this case 3), and shifts them by a small $\\epsilon$. Then it runs the circuit and takes the diefferences of the ouput for the parameters $\\Theta$ and $\\Theta + \\epsilon$. This is the finite difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(shots=10000)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i[0])\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = 0.01\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors\n",
    "        print(i)\n",
    "        input_numbers = to_numbers(i[0])\n",
    "        print(input_numbers)\n",
    "        gradient = [0,0,0]\n",
    "        \n",
    "        for k in range(len(input_numbers)):\n",
    "            input_eps = input_numbers\n",
    "            input_eps[k] = input_numbers[k] + eps\n",
    "            exp_value = ctx.QiskitCirc.run(torch.tensor(input_eps))[0]\n",
    "            gradient_result = (exp_value - forward_tensor[0][0].item())#/eps\n",
    "            gradient[k] = gradient_result\n",
    "            \n",
    "#         print(gradient)\n",
    "        result = torch.tensor([gradient])\n",
    "#         print(result)\n",
    "\n",
    "        return result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0122, -0.0254, -0.0168]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[np.pi/4, np.pi/4, np.pi/4]], requires_grad=True)\n",
    "# x = torch.tensor([[0.0, 0.0, 0.0]], requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "y1.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Quantum Circuit separately\n",
    "\n",
    "This example is simply to test the QC with a pytorch optimizer\n",
    "\n",
    "We define a cost function and a target expectation value (here -1). The cost is the square distance from the target value.\n",
    "\n",
    "`x` is the initialization of the parameters. Here again, this was hard coded such that every angle starts at $\\pi / 4$.\n",
    "\n",
    "The rest is standard pytorch optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 12.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2203f842898>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)\n",
    "    return torch.abs(qc(x) - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([[np.pi/4, np.pi/4, np.pi/4]], requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval.item())\n",
    "#     print(loss.item())\n",
    "\n",
    "plt.plot(loss_list)\n",
    "    \n",
    "# print(circuit(phi, theta))\n",
    "# print(cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST\n",
    "\n",
    "In this code we can not handle batches yet.\n",
    "This should be implemented as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 40\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size_train = 1\n",
    "batch_size_test = 1\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "labels = mnist_trainset.targets #get labels\n",
    "labels = labels.numpy()\n",
    "idx1 = np.where(labels == 0) #search all zeros\n",
    "idx2 = np.where(labels == 1) # search all ones\n",
    "idx = np.concatenate((idx1[0][0:20],idx2[0][0:20])) # concatenate their indices\n",
    "mnist_trainset.targets = labels[idx] \n",
    "mnist_trainset.data = mnist_trainset.data[idx]\n",
    "\n",
    "print(mnist_trainset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network with Q-node\n",
    "\n",
    "This NN is  2 layers of ConvNN and a fully connected layer, with a Q-Node as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "#         return F.softmax(x)\n",
    "        x = np.pi*F.tanh(x)\n",
    "        x = qc(x) # This is the q node\n",
    "        x = (x+1)/2 # Translate expectation values [-1,1] to labels [0,1]\n",
    "        x = torch.cat((x, 1-x), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "# optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "standard pytorch training loop.\n",
    "- Load data from train_loader. Which is this case a single example each step.\n",
    "- Forward pass through NN\n",
    "- Caluculate loss\n",
    "- Backprop and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edward\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00720000000000004, 0.01440000000000008, 0.010800000000000087]\n",
      "[0.007199999999999929, -0.014600000000000057, 0.0]\n",
      "[-0.007199999999999929, -0.0005999999999999894, -0.007199999999999929]\n",
      "[0.0007999999999999674, 0.007800000000000029, -0.010599999999999943]\n",
      "[0.030200000000000005, 0.023200000000000054, 0.03620000000000001]\n",
      "[0.02560000000000001, 0.011799999999999977, 0.015399999999999914]\n",
      "[0.0006000000000000449, 0.007599999999999996, 0.004800000000000082]\n",
      "[0.00660000000000005, 0.0022000000000000908, -0.006399999999999961]\n",
      "[0.024799999999999933, 0.018000000000000016, 0.016000000000000014]\n",
      "[-0.0010000000000000564, 0.014999999999999958, 0.006599999999999939]\n",
      "[0.02699999999999997, 0.03420000000000001, -0.008600000000000052]\n",
      "[0.024799999999999933, 0.013600000000000001, 0.029799999999999993]\n",
      "[-0.0005999999999999894, 0.017400000000000027, 0.022999999999999965]\n",
      "[0.00500000000000006, 0.0014000000000000679, 0.0]\n",
      "[0.012800000000000089, 0.023200000000000054, 0.020800000000000096]\n",
      "[0.011199999999999932, 0.015400000000000025, 0.012599999999999945]\n",
      "[0.028200000000000003, 0.023200000000000054, 0.020000000000000018]\n",
      "[0.025200000000000056, 0.032799999999999996, 0.030399999999999983]\n",
      "[-0.0023999999999999577, -0.00039999999999995595, 0.0023999999999999577]\n",
      "[0.003400000000000014, 0.002999999999999947, 0.017799999999999983]\n",
      "[-0.018400000000000027, -0.0052000000000000934, 0.007199999999999929]\n",
      "[0.014400000000000024, 0.010599999999999998, 0.016600000000000004]\n",
      "[0.01940000000000003, 0.00280000000000008, 0.03820000000000001]\n",
      "[0.011799999999999922, -0.003000000000000058, 0.005799999999999916]\n",
      "[0.0009999999999999454, 0.019999999999999962, 0.01799999999999996]\n",
      "[0.01419999999999999, 0.012799999999999978, 0.012999999999999956]\n",
      "[0.0023999999999999577, -0.0024000000000000132, 0.015800000000000036]\n",
      "[0.005799999999999972, -0.008600000000000108, 0.012599999999999945]\n",
      "[0.013999999999999901, -0.014000000000000012, -0.01640000000000008]\n",
      "[-0.0010000000000000564, -0.009000000000000064, 0.008399999999999963]\n",
      "[0.026000000000000023, 0.026599999999999957, 0.008199999999999985]\n",
      "[0.0398, 0.028799999999999937, 0.03639999999999999]\n",
      "[0.006400000000000017, 0.0032000000000000917, 0.008599999999999997]\n",
      "[0.011400000000000077, -0.013999999999999957, -0.0045999999999999375]\n",
      "[-0.010799999999999976, -0.023599999999999954, 0.009799999999999975]\n",
      "[0.004799999999999971, 0.0043999999999999595, 0.009800000000000031]\n",
      "[0.025199999999999945, 0.014399999999999968, 0.028799999999999937]\n",
      "[-0.008000000000000007, -0.021200000000000052, 0.0011999999999999234]\n",
      "[0.029399999999999926, 0.017399999999999916, 0.023199999999999943]\n",
      "[-0.011800000000000033, -0.008599999999999941, -0.0018000000000000238]\n",
      "-0.7027\n",
      "[-0.00720000000000004, 0.005199999999999927, -0.013600000000000056]\n",
      "[0.012399999999999967, -0.0041999999999999815, 0.016599999999999948]\n",
      "[-0.0011999999999999234, 0.00280000000000008, 0.003599999999999992]\n",
      "[-0.005200000000000038, -0.0020000000000000018, -0.01639999999999997]\n",
      "[-0.004799999999999971, -0.0043999999999999595, -0.018600000000000005]\n",
      "[-0.0005999999999999339, -0.009800000000000031, -0.008199999999999985]\n",
      "[-0.0005999999999999894, 0.0043999999999999595, 0.006799999999999917]\n",
      "[0.022399999999999975, 0.01699999999999996, 0.012999999999999956]\n",
      "[0.012799999999999978, -0.010199999999999987, 0.006799999999999973]\n",
      "[0.018600000000000005, 0.04600000000000004, 0.020199999999999996]\n",
      "[0.0033999999999999586, -0.006800000000000084, 0.00919999999999993]\n",
      "[-0.01919999999999994, -0.016600000000000004, -0.013399999999999912]\n",
      "[0.006599999999999939, 0.02119999999999994, 0.00019999999999997797]\n",
      "[0.007400000000000018, 0.009000000000000064, 0.0016000000000000458]\n",
      "[0.016599999999999948, 0.006199999999999983, 0.013599999999999834]\n",
      "[0.012599999999999945, -0.010199999999999987, -0.010399999999999965]\n",
      "[0.024999999999999967, 0.03620000000000001, 0.00019999999999997797]\n",
      "[0.010000000000000009, 0.0038000000000000256, 0.021200000000000052]\n",
      "[0.015799999999999925, 0.03579999999999994, 0.011599999999999944]\n",
      "[0.016000000000000014, -0.006199999999999983, 0.0]\n",
      "[-0.025399999999999978, -0.005199999999999927, 0.0010000000000000564]\n",
      "[0.007000000000000062, -0.006799999999999917, 0.016400000000000026]\n",
      "[0.0041999999999999815, 0.007999999999999952, -0.014000000000000012]\n",
      "[0.008199999999999985, -0.00820000000000004, 0.012399999999999967]\n",
      "[0.03179999999999983, 0.032399999999999984, 0.02159999999999984]\n",
      "[0.015400000000000025, -0.00940000000000002, 0.01679999999999998]\n",
      "[0.02420000000000011, 0.006000000000000005, 0.028800000000000103]\n",
      "[0.01200000000000001, 0.0005999999999999894, 0.010000000000000009]\n",
      "[0.010000000000000009, 0.010400000000000076, 0.01920000000000005]\n",
      "[-0.01419999999999999, -0.00919999999999993, -0.0020000000000000018]\n",
      "[0.011800000000000033, 0.003400000000000014, 0.007800000000000029]\n",
      "[-0.002999999999999947, -0.0007999999999999674, 0.007600000000000051]\n",
      "[-0.012399999999999967, 0.02200000000000002, 0.0034000000000000696]\n",
      "[0.0040000000000000036, 0.011400000000000021, 0.008000000000000007]\n",
      "[0.0010000000000000564, -0.0007999999999999674, 0.021600000000000064]\n",
      "[-0.0126, 0.0013999999999999013, 0.013999999999999957]\n",
      "[-0.0041999999999999815, -0.009999999999999953, 0.009000000000000064]\n",
      "[0.015800000000000036, -0.002799999999999969, -0.0021999999999999797]\n",
      "[-0.0014000000000000123, -0.002999999999999947, 0.003000000000000058]\n",
      "[0.01679999999999998, 0.00040000000000001146, 0.032399999999999984]\n",
      "-0.38349999999999995\n",
      "[0.013399999999999912, 0.012799999999999978, 0.019999999999999907]\n",
      "[0.009000000000000008, 0.012600000000000056, 0.017400000000000027]\n",
      "[0.029000000000000026, 0.020399999999999974, 0.0116]\n",
      "[-0.0017999999999999683, 0.006599999999999939, -0.009999999999999953]\n",
      "[0.02400000000000002, 0.02699999999999997, 0.015599999999999947]\n",
      "[0.030200000000000005, 0.022599999999999953, 0.010399999999999965]\n",
      "[-0.0010000000000000564, 0.005400000000000016, 0.017400000000000027]\n",
      "[0.016000000000000014, 0.028799999999999937, 0.01859999999999995]\n",
      "[-0.014000000000000012, -0.003399999999999903, 0.00720000000000004]\n",
      "[0.007200000000000095, 0.0036000000000000476, 0.01920000000000005]\n",
      "[0.0030000000000001137, 0.010600000000000165, 0.005800000000000027]\n",
      "[0.0024000000000000132, -0.014000000000000012, 0.011599999999999944]\n",
      "[0.004599999999999993, 0.005800000000000027, 0.024999999999999967]\n",
      "[0.023799999999999988, 0.026999999999999913, 0.01419999999999999]\n",
      "[0.004400000000000015, 0.012999999999999956, 0.0040000000000000036]\n",
      "[-0.002799999999999969, 0.007000000000000062, 0.013600000000000001]\n",
      "[0.01739999999999997, 0.025799999999999934, 0.0007999999999999674]\n",
      "[0.008599999999999997, -0.006199999999999983, -0.00599999999999995]\n",
      "[-0.00539999999999996, 0.004800000000000082, 0.013000000000000067]\n",
      "[0.0262, 0.005800000000000027, 0.003200000000000036]\n",
      "[0.014000000000000012, 0.018199999999999994, 0.0132000000000001]\n",
      "[0.01919999999999994, 0.02560000000000001, 0.0398]\n",
      "[0.01640000000000008, 0.01940000000000003, 0.015600000000000003]\n",
      "[0.023400000000000032, 0.01679999999999998, 0.01940000000000003]\n",
      "[0.027199999999999946, 0.01679999999999998, 0.01959999999999995]\n",
      "[0.009400000000000075, -0.012199999999999989, 0.006400000000000017]\n",
      "[0.008400000000000019, 0.007800000000000029, 0.013400000000000023]\n",
      "[-0.000200000000000089, 0.00039999999999995595, 0.0005999999999999894]\n",
      "[0.019399999999999973, 0.0033999999999999586, 0.006799999999999973]\n",
      "[0.009399999999999964, -0.007599999999999996, -0.0017999999999999683]\n",
      "[-0.017799999999999983, -0.003000000000000058, -0.0015999999999999903]\n",
      "[0.009599999999999942, 0.020999999999999963, 0.022399999999999975]\n",
      "[0.008000000000000007, 0.01720000000000005, 0.011200000000000043]\n",
      "[0.014999999999999902, -0.006800000000000084, 0.01599999999999996]\n",
      "[0.01479999999999998, 0.0034000000000000696, 0.01679999999999998]\n",
      "[-0.026800000000000046, -0.011000000000000065, -0.01920000000000005]\n",
      "[0.008799999999999975, 0.026599999999999957, 0.006399999999999961]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-ec2b1ff35d76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         print(output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#         print(output[0][1].item(), target.item())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "#         loss = F.cross_entropy(output, target)\n",
    "#         print(output)\n",
    "#         print(output[0][1].item(), target.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss.append(loss.item())\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of NN\n",
    "\n",
    "The outcome is not always the same because the prediction is probabilistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "number = 0\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    number +=1\n",
    "    output = network(data)\n",
    "    output = (output>0.5).float()\n",
    "    accuracy += (output[0][1].item() == target[0].item())*1\n",
    "    \n",
    "print(\"Accuracy is: {}\".format(accuracy/number))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
