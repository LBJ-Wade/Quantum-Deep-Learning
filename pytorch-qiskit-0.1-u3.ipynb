{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumRegister,QuantumCircuit,ClassicalRegister,execute\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import Aer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to translate Q-Circuit parameters from pytorch back to QISKIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QiskitCircuit()\n",
    "\n",
    "Parameters have to be defined according to the circuit. In this case we have a unitary U3 with 3 parameters, which we call Theta, Phi and Lambda.\n",
    "The paramter `shots` always has to be defined. It gives the number of measurements done on the simulator or on the hardware to do the averages for the expectation values.\n",
    "\n",
    "### create_circuit()\n",
    "Define a quantum cirquit in QISKIT language\n",
    "\n",
    "### N_qubit_expectation_Z()\n",
    "This is a function that allows to take the measurements and translate them to Z-expectation values for every single qubit.\n",
    "\n",
    "### bind( parameters )\n",
    "Takes the Neural Network parameters and puts them into a format that can be fed into the QIKSIT unitaries.\n",
    "\n",
    "To generalze this code we would have to write a function that replaces the line `self.circuit.data[2][0]._params`.\n",
    "Because the `self.circuit.data` is a list of all the gates  of the circuit. And the indices direct to the correct gate, where the parameters have to go.\n",
    "\n",
    "At some point we would need a better scheme here.\n",
    "\n",
    "### run( parameters )\n",
    "This function puts the circuit with the given parameters on a quantum simulater or hardware and returns the measurements of every qubit in Z-basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:09:30.598730Z",
     "start_time": "2019-10-01T16:09:30.567861Z"
    }
   },
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self,shots):\n",
    "        self.theta = Parameter('Theta')\n",
    "        self.phi = Parameter('Phi')\n",
    "        self.lam = Parameter('Lambda')\n",
    "        self.shots = shots\n",
    "        \n",
    "        def create_circuit():\n",
    "            qr = QuantumRegister(1,'q')\n",
    "            cr = ClassicalRegister(1,'c')\n",
    "            ckt = QuantumCircuit(qr,cr)\n",
    "            ckt.h(qr[0])\n",
    "            ckt.barrier()\n",
    "            ckt.u3(self.theta,self.phi,self.lam,qr[0])\n",
    "            ckt.barrier()\n",
    "            ckt.measure(qr,cr)\n",
    "            return ckt\n",
    "        \n",
    "        self.circuit = create_circuit()\n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects    \n",
    "    \n",
    "    def bind(self, parameters):\n",
    "        [self.theta,self.phi,self.lam] = to_numbers(parameters)\n",
    "        self.circuit.data[2][0]._params = to_numbers(parameters)\n",
    "    \n",
    "    def run(self, i):\n",
    "        self.bind(i)\n",
    "        \n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        job_sim = execute(self.circuit,backend,shots=self.shots)\n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchCircuit()\n",
    "\n",
    "A pytorch layer always has two functions. One for the forward pass and one for the backward pass. The forward pass simply takes the Quantum Circuits variational parameters from the previous pytorch layer and runs the circuit on the defined hardware (defined in `QiskitCircuit.run()`) and returns the measurements from the quantum hardware.\n",
    "These measurements will be the inputs of the next pytorch layer.\n",
    "\n",
    "The backward pass returns the gradients of the quantum circuit. In this case here it is finite difference.\n",
    "\n",
    "the `forward_tensor` is saved from the forward pass. So we just have to do one evaluation of the Q-Circuit in the backpass for the finite difference.\n",
    "\n",
    "The `gradient` variable here is as well hard coded to 3 parameters. This should be updated in the future and made more general.\n",
    "\n",
    "The loop `for k in range(len(input_numbers)):` goes through all the parameters (in this case 3), and shifts them by a small $\\epsilon$. Then it runs the circuit and takes the diefferences of the ouput for the parameters $\\Theta$ and $\\Theta + \\epsilon$. This is the finite difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(shots=10000)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i[0])\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = 0.01\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors   \n",
    "        print('expected_value: ' + str(forward_tensor))\n",
    "        input_numbers = to_numbers(i[0])\n",
    "        gradient = [0,0,0]\n",
    "        \n",
    "        for k in range(len(input_numbers)):\n",
    "            input_eps = input_numbers\n",
    "            input_eps[k] = input_numbers[k] + eps\n",
    "\n",
    "            exp_value = ctx.QiskitCirc.run(torch.tensor(input_eps))[0]\n",
    "            result_eps = torch.tensor([exp_value])\n",
    "            gradient_result = (exp_value - forward_tensor[0][0].item())#/eps\n",
    "            gradient[k] = gradient_result\n",
    "            \n",
    "#         print(gradient)\n",
    "        result = torch.tensor([gradient])\n",
    "#         print(result)\n",
    "\n",
    "        return result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_value: tensor([[0.5026]], dtype=torch.float64, grad_fn=<TorchCircuitBackward>)\n",
      "tensor([[-0.0066, -0.0038, -0.0228]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[np.pi/4, np.pi/4, np.pi/4]], requires_grad=True)\n",
    "# x = torch.tensor([[0.0, 0.0, 0.0]], requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "y1.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Quantum Circuit separately\n",
    "\n",
    "This example is simply to test the QC with a pytorch optimizer\n",
    "\n",
    "We define a cost function and a target expectation value (here -1). The cost is the square distance from the target value.\n",
    "\n",
    "`x` is the initialization of the parameters. Here again, this was hard coded such that every angle starts at $\\pi / 4$.\n",
    "\n",
    "The rest is standard pytorch optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                | 2/100 [00:00<00:08, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7854, 0.7854, 0.7854]], requires_grad=True)\n",
      "tensor([[0.8854, 0.8854, 0.8854]], requires_grad=True)\n",
      "tensor([[0.9562, 0.8539, 0.8624]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                              | 4/100 [00:00<00:08, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0388, 0.8558, 0.8992]], requires_grad=True)\n",
      "tensor([[1.0177, 0.8442, 0.9265]], requires_grad=True)\n",
      "tensor([[1.0050, 0.8124, 0.9398]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▌                                                                           | 8/100 [00:00<00:07, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0433, 0.8130, 0.9930]], requires_grad=True)\n",
      "tensor([[1.0776, 0.8324, 1.0518]], requires_grad=True)\n",
      "tensor([[1.0886, 0.8390, 1.1092]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████                                                                         | 10/100 [00:00<00:07, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0856, 0.8301, 1.1312]], requires_grad=True)\n",
      "tensor([[1.0666, 0.8045, 1.1395]], requires_grad=True)\n",
      "tensor([[1.0322, 0.7797, 1.1676]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▎                                                                     | 14/100 [00:01<00:07, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0067, 0.7442, 1.1991]], requires_grad=True)\n",
      "tensor([[0.9675, 0.6992, 1.2233]], requires_grad=True)\n",
      "tensor([[0.9289, 0.6642, 1.2533]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▉                                                                    | 16/100 [00:01<00:07, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8924, 0.6221, 1.2949]], requires_grad=True)\n",
      "tensor([[0.8683, 0.5949, 1.3512]], requires_grad=True)\n",
      "tensor([[0.8367, 0.5621, 1.3875]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▏                                                                | 20/100 [00:01<00:06, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8176, 0.5385, 1.4393]], requires_grad=True)\n",
      "tensor([[0.7894, 0.5092, 1.4821]], requires_grad=True)\n",
      "tensor([[0.7614, 0.4711, 1.5274]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▊                                                               | 22/100 [00:01<00:06, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7285, 0.4278, 1.5566]], requires_grad=True)\n",
      "tensor([[0.6954, 0.3897, 1.5822]], requires_grad=True)\n",
      "tensor([[0.6606, 0.3500, 1.6124]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████                                                            | 26/100 [00:02<00:06, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6237, 0.3129, 1.6433]], requires_grad=True)\n",
      "tensor([[0.5896, 0.2729, 1.6727]], requires_grad=True)\n",
      "tensor([[0.5577, 0.2339, 1.6979]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▋                                                          | 28/100 [00:02<00:06, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5327, 0.2229, 1.7355]], requires_grad=True)\n",
      "tensor([[0.5217, 0.2156, 1.7675]], requires_grad=True)\n",
      "tensor([[0.5107, 0.2057, 1.8027]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████▉                                                       | 32/100 [00:02<00:05, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5018, 0.2160, 1.8226]], requires_grad=True)\n",
      "tensor([[0.5069, 0.2335, 1.8572]], requires_grad=True)\n",
      "tensor([[0.4993, 0.2348, 1.8724]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▌                                                     | 34/100 [00:02<00:05, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5003, 0.2467, 1.8950]], requires_grad=True)\n",
      "tensor([[0.5016, 0.2616, 1.9223]], requires_grad=True)\n",
      "tensor([[0.4923, 0.2727, 1.9489]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████▊                                                  | 38/100 [00:03<00:05, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4781, 0.2788, 1.9717]], requires_grad=True)\n",
      "tensor([[0.4669, 0.2940, 2.0040]], requires_grad=True)\n",
      "tensor([[0.4604, 0.3086, 2.0314]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▍                                                | 40/100 [00:03<00:05, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4593, 0.3187, 2.0540]], requires_grad=True)\n",
      "tensor([[0.4555, 0.3203, 2.0756]], requires_grad=True)\n",
      "tensor([[0.4636, 0.3257, 2.1048]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████▋                                             | 44/100 [00:03<00:04, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4716, 0.3380, 2.1371]], requires_grad=True)\n",
      "tensor([[0.4816, 0.3445, 2.1619]], requires_grad=True)\n",
      "tensor([[0.4856, 0.3485, 2.1773]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▎                                           | 46/100 [00:03<00:04, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4858, 0.3523, 2.1837]], requires_grad=True)\n",
      "tensor([[0.4943, 0.3741, 2.1982]], requires_grad=True)\n",
      "tensor([[0.5093, 0.3959, 2.2129]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████▌                                        | 50/100 [00:04<00:04, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5192, 0.4168, 2.2318]], requires_grad=True)\n",
      "tensor([[0.5266, 0.4314, 2.2557]], requires_grad=True)\n",
      "tensor([[0.5422, 0.4575, 2.2917]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████                                       | 52/100 [00:04<00:03, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5590, 0.4809, 2.3283]], requires_grad=True)\n",
      "tensor([[0.5728, 0.4940, 2.3588]], requires_grad=True)\n",
      "tensor([[0.5936, 0.5061, 2.3929]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████▎                                   | 56/100 [00:04<00:03, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6094, 0.5046, 2.4332]], requires_grad=True)\n",
      "tensor([[0.6361, 0.5117, 2.4890]], requires_grad=True)\n",
      "tensor([[0.6656, 0.5261, 2.5421]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████▉                                  | 58/100 [00:04<00:03, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6913, 0.5408, 2.5912]], requires_grad=True)\n",
      "tensor([[0.7248, 0.5620, 2.6460]], requires_grad=True)\n",
      "tensor([[0.7583, 0.5842, 2.7043]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████▏                              | 62/100 [00:05<00:03, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7899, 0.6045, 2.7580]], requires_grad=True)\n",
      "tensor([[0.8180, 0.6213, 2.8096]], requires_grad=True)\n",
      "tensor([[0.8429, 0.6345, 2.8564]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▊                             | 64/100 [00:05<00:03, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8689, 0.6462, 2.9017]], requires_grad=True)\n",
      "tensor([[0.8938, 0.6568, 2.9434]], requires_grad=True)\n",
      "tensor([[0.9178, 0.6664, 2.9804]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████                          | 68/100 [00:05<00:02, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9411, 0.6768, 3.0168]], requires_grad=True)\n",
      "tensor([[0.9620, 0.6863, 3.0481]], requires_grad=True)\n",
      "tensor([[0.9828, 0.6949, 3.0771]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▋                        | 70/100 [00:05<00:02, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0035, 0.7047, 3.1063]], requires_grad=True)\n",
      "tensor([[1.0222, 0.7144, 3.1322]], requires_grad=True)\n",
      "tensor([[1.0395, 0.7231, 3.1560]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████▉                     | 74/100 [00:06<00:02, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0556, 0.7310, 3.1781]], requires_grad=True)\n",
      "tensor([[1.0693, 0.7383, 3.1983]], requires_grad=True)\n",
      "tensor([[1.0818, 0.7461, 3.2169]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████▌                   | 76/100 [00:06<00:02, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0936, 0.7538, 3.2336]], requires_grad=True)\n",
      "tensor([[1.1047, 0.7606, 3.2483]], requires_grad=True)\n",
      "tensor([[1.1152, 0.7673, 3.2625]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████▊                | 80/100 [00:06<00:01, 11.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1249, 0.7736, 3.2750]], requires_grad=True)\n",
      "tensor([[1.1346, 0.7793, 3.2869]], requires_grad=True)\n",
      "tensor([[1.1442, 0.7847, 3.2978]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████▍              | 82/100 [00:06<00:01, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1530, 0.7900, 3.3083]], requires_grad=True)\n",
      "tensor([[1.1610, 0.7955, 3.3179]], requires_grad=True)\n",
      "tensor([[1.1682, 0.8003, 3.3258]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████▋           | 86/100 [00:07<00:01, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1753, 0.8060, 3.3336]], requires_grad=True)\n",
      "tensor([[1.1818, 0.8111, 3.3409]], requires_grad=True)\n",
      "tensor([[1.1882, 0.8158, 3.3476]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████▎         | 88/100 [00:07<00:01, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1939, 0.8203, 3.3539]], requires_grad=True)\n",
      "tensor([[1.1994, 0.8243, 3.3596]], requires_grad=True)\n",
      "tensor([[1.2049, 0.8291, 3.3651]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████▌      | 92/100 [00:07<00:00, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2100, 0.8343, 3.3708]], requires_grad=True)\n",
      "tensor([[1.2145, 0.8387, 3.3759]], requires_grad=True)\n",
      "tensor([[1.2187, 0.8434, 3.3808]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████▏    | 94/100 [00:07<00:00, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2224, 0.8472, 3.3848]], requires_grad=True)\n",
      "tensor([[1.2258, 0.8506, 3.3883]], requires_grad=True)\n",
      "tensor([[1.2296, 0.8541, 3.3917]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████▍ | 98/100 [00:08<00:00, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2336, 0.8580, 3.3945]], requires_grad=True)\n",
      "tensor([[1.2371, 0.8608, 3.3968]], requires_grad=True)\n",
      "tensor([[1.2406, 0.8637, 3.3987]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2437, 0.8667, 3.4004]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2203f28ec50>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)\n",
    "    return torch.abs(qc(x) - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([[np.pi/4, np.pi/4, np.pi/4]], requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval.item())\n",
    "#     print(loss.item())\n",
    "\n",
    "plt.plot(loss_list)\n",
    "    \n",
    "# print(circuit(phi, theta))\n",
    "# print(cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST\n",
    "\n",
    "In this code we can not handle batches yet.\n",
    "This should be implemented as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size_train = 1\n",
    "batch_size_test = 1\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "labels = mnist_trainset.targets #get labels\n",
    "labels = labels.numpy()\n",
    "idx1 = np.where(labels == 0) #search all zeros\n",
    "idx2 = np.where(labels == 1) # search all ones\n",
    "idx = np.concatenate((idx1[0][0:20],idx2[0][0:20])) # concatenate their indices\n",
    "mnist_trainset.targets = labels[idx] \n",
    "mnist_trainset.data = mnist_trainset.data[idx]\n",
    "\n",
    "print(mnist_trainset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network with Q-node\n",
    "\n",
    "This NN is  2 layers of ConvNN and a fully connected layer, with a Q-Node as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "#         return F.softmax(x)\n",
    "        x = np.pi*F.tanh(x)\n",
    "        x = qc(x) # This is the q node\n",
    "        x = (x+1)/2 # Translate expectation values [-1,1] to labels [0,1]\n",
    "        x = torch.cat((x, 1-x), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "# optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "standard pytorch training loop.\n",
    "- Load data from train_loader. Which is this case a single example each step.\n",
    "- Forward pass through NN\n",
    "- Caluculate loss\n",
    "- Backprop and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "#         loss = F.cross_entropy(output, target)\n",
    "#         print(output)\n",
    "#         print(output[0][1].item(), target.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss.append(loss.item())\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of NN\n",
    "\n",
    "The outcome is not always the same because the prediction is probabilistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "number = 0\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    number +=1\n",
    "    output = network(data)\n",
    "    output = (output>0.5).float()\n",
    "    accuracy += (output[0][1].item() == target[0].item())*1\n",
    "    \n",
    "print(\"Accuracy is: {}\".format(accuracy/number))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
